;Module for trainee_template.
;Contains methods to derive features or feature values as defined by feature attributes.
(null

	;Derived during train features should have a feature attribute of 'auto_derive_on_train', an asoc defining how to derive the feature with the
	; following attributes:
	;
	;	derive_type: string attribute defining the type of derivation, one of 'custom', 'start', 'end'.  Each derive_type has its own attribute set.
	;
	;		'derive_type' : "custom" -
	;			This feature is derived using the specified 'code'. For each series, where each series is defined by "series_id_features",
	;			the rows are processed in order, after being sorted by "ordered_by_features". If series is not specified, processes the entire
	;			dataset. Referencing data in rows uses 0-based indexing, where the current row index is 0, the previous row's is 1, etc.
	;			Specified code may do simple logic and numeric operations on feature values referenced via feature name and row offset.
	;			Examples:
	;				"#x 1" - Use the value for feature 'x' from the previously processed row (offset of 1, one lag value).
	;				"(- #y 0 #x 1)" - Feature 'y' value from current (offset 0) row  minus feature 'x' value from previous (offest 1) row.
	;		'code': string, Code describing how feature could be derived. Example: "(- #y 0 #x 1)"
	;		'series_id_features' : (optional) list of feature name(s) of series for which to derive this feature. A series is the conjunction of all
	;			the features specified by this attribute.
	;		'ordered_by_features' : (optional) list of fature name(s) by which to order the series specified by "series_id_features". Series values
	;			are order by the order of feature names specified by this attribute.
	;
	;
	;		'derive_type' : "progress" -
	;			This will create two continuous features of: .series_progress with values ranging from 0 to 1.0 for each case in the series
	;			and '.series_progress_delta' which is the delta value of the progress for each case. Used to determine when to stop series synth.
	;
	;		'series_id_features' : list of feature name(s) of series for which to derive this feature. A series is the conjunction of all
	;			the features specified by this attribute.
	;

	;At the end of train, derive features using the existing model, provided a list of features to derive. Creates and populates the specified
	;features to the model.
	;
	;parameters:
	; features: list of features the dataset was trained with originally
	; derived_features: list of features to derive, in the specified order.
	; case_ids: list of case ids for which to derive features
	#DeriveTrainFeatures
	(declare
		(assoc
			features (list)
			derived_features (list)
			case_ids (null)

			;not a parameter, map of case id -> set of derive_imputed features that will be accumulated for all the features
			;that are either imputed or derived from imputed features during this derivation flow and will be used
			;to check that values derived using these imputed values are within bounds.
			;At worst will grow to have all the cases in the model as its keys with each having the full list of feature names,
			;but that would only happen if every case had every feature imputed or derived from other imputed features.
			cases_derive_imputed_map (assoc)
		)

		(declare (assoc
			lag_features
				(filter
					(lambda (and
						(= "lag"  (get featureAttributes (list (current_value 1) "ts_type")) )
						(= "custom" (get featureAttributes (list (current_value 1) "auto_derive_on_train" "derive_type")) )
					))
					derived_features
				)
		))

		;derive all the lag features in one pass
		(call DeriveLagFeatures (assoc
			features features
			lag_features lag_features
		))

		;derive all the non-lag features below:
		(assign (assoc
			derived_features (filter (lambda (not (contains_value lag_features (current_value)))) derived_features)
		))

		(map
			(lambda (let
				(assoc
					feature (current_value 1)
					feature_attribute_map (get featureAttributes (list (current_value 2) "auto_derive_on_train"))
				)

				(if
					;code-based derived feature
					(= "custom" (get feature_attribute_map "derive_type"))
					(call DeriveCustomFeatureFromCode (assoc
						features features
						feature feature
						raw_code_string (get feature_attribute_map "code")
						series_id_features (get feature_attribute_map "series_id_features")
						series_ordered_by_features (get feature_attribute_map "ordered_by_features")
					))

					;create .series_progress and .series_progress_delta features
					(= "progress" (get feature_attribute_map "derive_type"))
					(call CreateSeriesProgressFeatures (assoc
						feature feature
						series_id_features (get feature_attribute_map "series_id_features")
					))

					;else do nothing, invalid feature specified
				)
			))
			derived_features
		)

		;update all cases whose values were imputed with the imputed metadata for future re-imputation
		(if (size cases_derive_imputed_map)
			(map
				(lambda (let
					(assoc
						case_id (current_index 1)
						imputed_features (indices (current_value 1))
					)
					(call StoreCaseValues (assoc
						label_name internalLabelImputed
						case_values_map (associate case_id imputed_features)
					))
				))
				cases_derive_imputed_map
			)
		)
	)

	;Derive feature value for the last row in series_data.
	; returns true and updates series_data in place if derived value within allowed bounds.
	; returns false without updating series_data if out derived value of bounds or it references na an invalid row offset.
	; returns (null) without updating series_data if a time feature exceeds its feature max boundary
	;
	;parameters:
	; derived_feature: feature name for which to derive value
	; feature_index_map: map of feature -> index of column in series_data corresponding to the feature
	; series_data: list of lists (a matrix) of series values, where the last list (row) is the one being updated
	; last_series_index: index of the last row in series_data
	#DeriveSeriesValue
	(declare
		(assoc
			derived_feature (null)
			feature_index_map (assoc)
			last_series_index 0
		)

		(if (= (null) derived_feature)
			(conclude (false))
		)

		;pull the max row lag for this derived_feature
		(declare (assoc max_row_lag  (get featureAttributes (list derived_feature "max_row_lag")) ))

		;if max value > last_series_index, this feature needs to be generated because it references a row offset
		;that isn't in this series, return false because this value can't be derived
		(if (> max_row_lag last_series_index)
			(conclude (false))
		)

		(declare (assoc
			new_feature_transform_processed (get featureCustomDerivedMethods (list derived_feature "series_react"))
		))

		(declare (assoc
			derived_feature_value
				(get_value
					(call_sandboxed new_feature_transform_processed (assoc
						series_data series_data
						series_row_index last_series_index
						feature_index_map feature_index_map
						featureDateTimeMap featureDateTimeMap
						ConvertDateToEpoch ConvertDateToEpoch
					) (* (size series_data) sandboxedComputeLimit) sandboxedMemoryLimit)
				)
		))

		;replace .nan with (null).  .nan are possible for initial cases in a series since they don't have any lags
		(if (= .nan derived_feature_value)
			(assign (assoc derived_feature_value (null)))
		)

		(declare (assoc
			bounds_map
				;if specific bounds were passed in, use those, else use globally specified feature bounds
				(if (contains_index feature_bounds_map derived_feature)
					(get feature_bounds_map derived_feature)

					(get featureBoundsMap derived_feature)
				)
			valid_value (true)
			is_datetime (contains_index featureDateTimeMap derived_feature)

		))

		;check bounds if they are specified
		(if (size bounds_map)
			(seq
				;invalid if generated a null and nulls are not allowed
				(if (and (= (null) derived_feature_value) (= (get bounds_map "allow_null") (false)))
					(conclude (assign (assoc valid_value (false))))

					;else this is a nominal that has an allowed list, check if it's in the list
					(contains_index bounds_map "allowed")
					(conclude (assign (assoc valid_value (contains_value (get bounds_map "allowed") derived_feature_value) )))
				)

				(let
					(assoc
						cycle_length (get cyclicFeaturesMap derived_feature)
						boundaries_tuple (null)
						boundary_min (null)
						boundary_max (null)
					)

					(assign (assoc
						boundaries_tuple
							(call ConstrainBoundariesForFeature (assoc
								bounds_map bounds_map
								feature derived_feature
								is_datetime is_datetime
								cycle_length cycle_length
							))
					))

					(assign (assoc
						boundary_min (first boundaries_tuple)
						boundary_max (last boundaries_tuple)
					))

					(assign (assoc
						valid_value
							(if (and cycle_length (>= boundary_min boundary_max))
								;for cyclic, exclusionary bounds mean the value has to be less than max or more than min
								(or (<= derived_feature_value boundary_max) (>= derived_feature_value boundary_min))

								;normal bounds check, if bound specified, value must be either more than min or less than max, respectively
								(and
									(or (= (null) boundary_min) (>= derived_feature_value boundary_min))
									(or (= (null) boundary_max) (<= derived_feature_value boundary_max))
								)
							)
					))

					(if (get featureAttributes (list derived_feature "time_series" "time_feature"))
						;if time feature exceeds the feature boundary max, stop generating the series by setting valid_value to 0
						;instead of (false), as long as other rows exist (this isn't the first row being generated)
						(if (and (not valid_value) (> derived_feature_value boundary_max) (> (size series_data) 1))
							(assign (assoc valid_value (null)))
						)
					)
				)
			)
		)

		;failed bounds check, return the invalid value
		(if (not valid_value)
			(conclude valid_value)
		)

		;convert epoch value back to string date or round it as necessary
		(if (!= (null) derived_feature_value)
			(if is_datetime
				(assign (assoc
					derived_feature_value
						(format
							derived_feature_value
							"number"
							(get featureDateTimeMap (list derived_feature "date_time_format"))
							(null)
							(assoc "locale" (get featureDateTimeMap (list derived_feature "locale")))
						)
				))

				(contains_index featureRoundingMap derived_feature)
				(seq
					(assign (assoc
						derived_feature_value
							;generate a statement in the format of (round <value> <significant_digits> <decimal_points>)
							(apply "round" (append derived_feature_value (get featureRoundingMap derived_feature)) )
					))

					(if (contains_index cyclicFeaturesMap derived_feature)
						(assign (assoc
							derived_feature_value (mod derived_feature_value (get cyclicFeaturesMap derived_feature))
						))
					)
				)
			)
		)

		;edit series_data in place, updating the last row, the column matching the derived_feature with the derived_feature_value
		(assign "series_data" (list last_series_index (get feature_index_map derived_feature)) derived_feature_value)

		;return true upon completion
		(true)
	)

	;helper method to derive all the lag features for all the series in one pass
	;parameters:
	; features: list of features the dataset was trained with originally
	; lag_features: list of lag features that need to be derived
	#DeriveLagFeatures
	(declare
		(assoc
			features (list)
			lag_features (list)
		)

		(declare (assoc
			series_id_features (get featureAttributes (list (first lag_features) "auto_derive_on_train" "series_id_features"))
			series_ordered_by_features (get featureAttributes (list (first lag_features) "auto_derive_on_train" "ordered_by_features"))
		))
		(declare (assoc
			;list of features that are necessary to be able to derive the specified lag features, i.e., the original non-lagged features
			necessary_features
				(append
					series_ordered_by_features
					(apply "append"
						(map
							(lambda (let
								(assoc raw_code_string (get featureAttributes (list (current_value 2) "auto_derive_on_train" "code")) )
								(indices (get_all_labels (parse raw_code_string)))
							))
							lag_features
						)
					)
				)
			feature_lists_to_impute_map (assoc)
			ts_series_length_limit (retrieve_from_entity "tsSeriesLimitLength")

			;impute all lag features except:
			;  lags for nominals (because they aren't needed for derivation since 'delta' or 'rate' doesn't apply to nominals)
			;  lags for features that are of type 'lag' only (i.e., impute derived lags of delta or rate features)
			;  time feature lag
			must_impute_features_set
				(zip (filter
					(lambda
						(and
							(not (or
								(= "nominal" (get featureAttributes (list (current_value 1) "type")) )
								(= "lag" (get featureAttributes (list (current_value 1) "parent_type")))
							))
							(!= (current_value) (concat "." tsTimeFeature "_lag_1") )
						)
					)
					lag_features
				))
		))

		;process each series individually
		;pull all the values for the necessary_features, sort them, and then derive this feature based on the specified code
		(map
			(lambda (let
				;(current_value) is in the format of (list (query_equals "series_feature_name" value) ... ) for all series_feature_name
				(assoc series_case_ids (contained_entities (current_value 1)) )

				;now that we know how long each new series is, ensure that ts_series_length_limit is e*(longest series)
				(if (> (* 2.718281828459 (size series_case_ids)) ts_series_length_limit)
					(assign (assoc ts_series_length_limit (* 2.718281828459 (size series_case_ids)) ))
				)

				(declare (assoc
					;series_data is all the necessary_features's values along with the case_id appended as the last column
					series_data
						(map
							(lambda (append (retrieve_from_entity (current_value) necessary_features) (current_value)))
							series_case_ids
						)
				))

				;sort the series data according to the specified features if ordering has been provided
				(if (size series_ordered_by_features)
					(assign (assoc
						series_data
							(call MultiSortList (assoc
								data series_data
								column_order_indices (range 0 (size series_ordered_by_features))
							))
					))
				)

				;store the case ids in the new sorted order of series_data
				(assign (assoc
					series_case_ids
						(map
							(lambda (last (current_value)))
							series_data
						)
				))

				;remove the case_id column from series_data
				(assign (assoc
					series_data
						(map
							(lambda (trunc (current_value)))
							series_data
						)
				))

				;overwrite series data with the new generated series values
				(assign (assoc
					series_data
						(call AddDerivedIndependentCodeFeatures (assoc
							derived_features lag_features
							features necessary_features
							series_data series_data
						))
				))

				;since all lag features are being created in bulk, we only need to check if one exists
				;to decide whether they all exist or none exist
				(declare (assoc first_lag_feature (first lag_features) ))

				;insert all the values into cases and output list of features to impute if any
				;accumulate a map of: case -> list of features to impute
				(accum (assoc
					feature_lists_to_impute_map
						;filter out all cases that don't need to be imputed
						(filter (map
							(lambda (let
								(assoc case_id (current_index 1) )
								(if (contains_label case_id first_lag_feature)
									(assign_to_entities
										case_id
										(zip lag_features (current_value))
									)
									;else these labels don't exist yet, need to append them to the entity
									(accum_entity_roots
										case_id
										(zip_labels lag_features (current_value))
									)
								)

								;if this case has any nulls, output the features that'll need to be imputed
								(if (contains_value (current_value) (null))
									(let
										(assoc
											features_to_impute
												(indices (filter
													(lambda
														(and
															(= (null) (current_value))
															(contains_index must_impute_features_set (current_index))
														)
													)
													(zip lag_features (current_value 1))
												))
										)
										;output features to impute if there are any, else output null so this case can be filtered out
										(if (!= 0 (size features_to_impute))
											features_to_impute
										)
									)
								)
							))
							(zip series_case_ids series_data)
						))
				))
			))

			;generates a list of queries for each unique series id (where each series id may be a conjuction of several features)
			(call GenerateUniqueSeriesQueries (assoc series_id_features series_id_features ))
		)
		;if ts_series_length_limit has been been updated to a larger value in the loop above, update the model with this new value
		(if (> ts_series_length_limit tsSeriesLimitLength)
			(assign_to_entities (assoc tsSeriesLimitLength ts_series_length_limit ))
		)

		(if (size feature_lists_to_impute_map)
			(seq
				;keep only those features that need to be imputed (not allowed to be null)
				(assign (assoc
					feature_lists_to_impute_map
						(map
							(lambda
								(filter
									(lambda (= (false) (get featureBoundsMap (list (current_value 1) "allow_null"))) )
									(current_value)
								)
							)
							feature_lists_to_impute_map
						)
				))

				;Analyze if necessary before imputing
				(call !AnalyzePreDerivationImpute)

				;iterate over all the cases to impute values for each case
				(map
					(lambda (let
						(assoc
							case_id (current_index 1)
							features_to_impute (current_value 1)
							context_values (retrieve_from_entity (current_index 1) features)
						)

						;iterate over all the features and impute each feature
						(map
							(lambda (let
								(assoc
									feature (current_value 1)
									react_value (null)
								)

								(assign (assoc
									react_value
										(call ReactDiscriminative (assoc
											context_features features
											context_values context_values
											action_features (list feature)
											;ignore the case for which we are doing the imputation since its feature value is null
											ignore_case case_id
											;don't encode the input because it's being passed in directly from the case
											skip_encoding (true)
											;don't decode because the output will be stored as-is right afterwards
											skip_decoding (true)
											return_action_values_only (true)
											allow_nulls (false)
										))
								))

								;update null value in the case with the reacted value
								(call StoreCaseValues (assoc
									;map of case id -> value
									case_values_map (associate case_id (first react_value))
									label_name feature
									overwrite (true)
								))
							))
							features_to_impute
						)
					))
					feature_lists_to_impute_map
				)
			)
		)
	)
)
