;Module for trainee_template.
;Contains helper methods for series reacting.
(null

	;Run react_series in a batch, output a list of outputs from each individual react_series.
	;
	;parameters:  same as #react_series, unless listed here
	;  num_reacts: number of react_series to do in a batch.
	;  rand_seed:  optional, see #react for description.  if specified must be length of num_reacts.
	;  series_context_values: optional, 3d-list of values, context value for each feature for each row of a series.
	;		If specified, num_reacts and max_series_lengths are ignored.
	;  series_context_features: optional, features corresponding to series_context_values
	;
	;	 All of the following parameters, if specified, must be either length of 1 or num_reacts.
	;
	;  initial_values - list of lists. see #react_series for description.
	;  series_stop_maps - list of assocs. see #react_series for description.
	;  max_series_lengths - list of values. see #react_series for description.
	;  context_values - list of lists.  see #react for description.
	;  action_values - list of lists.  see #react for description.
	;  case_indices - list of lists.  see #react for description.
	;  continue_series_values - list of lists. see #react_series for description.
	#BatchReactSeries
    (declare
        (assoc
            ;if any of these are length of 1, the index will be 0 to pull the values and apply to all reacts
            single_context (= 1 (size context_values))
            single_action (= 1 (size action_values))
            single_session (= 1 (size case_indices))
            single_initial (= 1 (size initial_values))
            single_stop_map (= 1 (size series_stop_maps))
            single_max_length (= 1 (size max_series_lengths))
			single_continue_series (= 1 (size continue_series_values))
            num_reacts 1

            has_series_context_values (false)
        )

        ;these lists must be either a list of lists or null; if it's an empty list, treat it as null
        (if (= (list) context_values) (assign (assoc context_values (null))) )
        (if (= (list) action_values) (assign (assoc action_values (null))) )
        (if (= (list) initial_values) (assign (assoc initial_values (null))) )
        (if (= (list) series_stop_maps) (assign (assoc series_stop_maps (null))) )

        (if (size series_context_values)
            (assign (assoc
                num_reacts (size series_context_values)
                has_series_context_values (true)
            ))
        )

        (if (= 0 (size output_features))
            ;TODO: 15300 feed into react_group() and output results if details are provided
            (conclude
				(assoc
					"payload"
						(assoc
							"action_features" (list)
							"react_results" (list)
						)
				)
            )
        )

		(declare (assoc
			warnings (assoc)
			output_influential_cases (get details "influential_cases")
			output_cap (get details "categorical_action_probabilities")
		))

		(declare (assoc
			series_output
				||(range
					(lambda (let
						(assoc
							initial_index (if single_initial 0 (current_index 1))
							stop_map_index (if single_stop_map 0 (current_index 1))
							max_length_index (if single_max_length 0 (current_index 1))
							context_index (if single_context 0 (current_index 1))
							action_index (if single_action 0 (current_index 1))
							session_index (if single_session 0 (current_index 1))
							react_rand_seed (if rand_seed (get rand_seed (current_index 1)))
							continue_index (if single_continue_series 0 (current_index 1))
							react_session (null)
							react_session_training_index (null)
							react_series_context_values (if has_series_context_values (get series_context_values (current_index 1)) (list))
						)

 						;get the corresponding parameters by the index, values will be null if not specified, but must be defaulted to an empty list/assoc
						(declare (assoc
							react_context_values (if context_values (get context_values context_index) (list))
							react_action_values (if action_values (get action_values action_index) (list))
							react_initial_values (if initial_values (get initial_values initial_index) (list))
							react_series_stop_map (if series_stop_maps (get series_stop_maps stop_map_index) (assoc))
							react_continue_values (if continue_series_values (get continue_series_values continue_index) (null))

							;max series is allowed to be null
							react_max_series_length (get max_series_lengths max_length_index)
						))

						;if one of these is provided, both of them must be
						(if case_indices
							(assign (assoc react_case_index (get case_indices session_index) ))
						)

						;Note: will need to pull this entire map out and store into its own variable to pull individual ReactSeries
						; keys (i.e,. "series") once details are added to ReactSeries output
						(get
							(call ReactSeries (assoc
								initial_values react_initial_values
								series_stop_map react_series_stop_map
								max_series_length react_max_series_length
								context_values react_context_values
								action_values react_action_values
								case_indices react_case_index
								rand_seed react_rand_seed
								series_context_values react_series_context_values
								output_new_series_ids output_new_series_ids
								output_features output_features
								continue_series continue_series
								continue_series_features continue_series_features
								continue_series_values react_continue_values

								initial_features initial_features
								context_features context_features
								series_context_features series_context_features
								action_features action_features
								derived_action_features derived_action_features
								derived_context_features derived_context_features
								details details
								extra_audit_features extra_audit_features
								case_access_count_label case_access_count_label
								ignore_case ignore_case
								substitute_output substitute_output
								input_is_substituted input_is_substituted
								use_case_weights use_case_weights
								weight_feature weight_feature
								leave_case_out leave_case_out

								desired_conviction desired_conviction
								use_regional_model_residuals use_regional_model_residuals
								feature_bounds_map feature_bounds_map
								ordered_by_specified_features ordered_by_specified_features
								exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
								generate_new_cases generate_new_cases
								preserve_feature_values preserve_feature_values
								new_case_threshold new_case_threshold
							))
							(list "payload")
						)
					))
					0 (- num_reacts 1) 1
				)
		))

		(assoc
			"payload"
				(append
					(assoc
						;output features are all the combined action features
						"action_features" output_features
						"series" (map (lambda (get (current_value) "series")) series_output)
					)
					(if output_influential_cases
						(assoc "influential_cases" (map (lambda (get (current_value) "influential_cases")) series_output))
						(assoc)
					)
					(if output_cap
						(assoc
							"categorical_action_probabilities" (map (lambda (get (current_value) "categorical_action_probabilities")) series_output)
							"aggregated_categorical_action_probabilities" (map (lambda (get (current_value) "aggregated_categorical_action_probabilities")) series_output)
						)
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
    )

	;React in series until a series_stop_map condition has been met, outputs an assoc of series.
	;
	;parameters:
	;	see comment block for #react_series in howso.amlg for details
	#ReactSeries
	(seq

		(if (= 0 (size output_features))
			;TODO: 15300 feed into react_group() and output results if details are provided
			(conclude (assoc "payload" (assoc "series" (list))) )
		)

		(declare (assoc
			;map of the originally provided context, containing all the features and nulls for values that haven't been derived or generated yet
			original_context_map
				(append
					(zip derived_context_features)
					(zip derived_action_features)
					(if (size action_values)
						(zip action_features action_values)
						(zip action_features)
					)
					(zip context_features context_values)
					(if (size series_context_values)
						(zip series_context_features (first series_context_values))
						(assoc)
					)
				)
			series_has_terminators (get tsModelFeaturesMap "series_has_terminators")
			stop_on_terminator (get tsModelFeaturesMap "stop_on_terminator")
		))

		;defaults to "no" if unspecified
		(if (= (null) generate_new_cases)
			(assign (assoc generate_new_cases "no"))
		)

		(declare (assoc
			;all the features used in the series
			features (indices original_context_map)
			;matrix of values, here each row is ordered in the same order as features
			series_data (list)
			;data to store each new row
			new_row (list)
			;flag set to true when series is done generating
			done (false)
			;assoc of of all features -> feature values for the current series case
			current_case_map (null)
			;all features that are used as contexts
			all_context_features (append context_features derived_context_features series_context_features)
			;context features used for each series ract, usually same as all_context_features except for the initial react
			react_context_features (list)
			;store output of react
			react_output (null)
			;0-based index of last row in series_data, start with -1 because it's accumulated at the start of the loop
			last_series_index -1
			first_generated_row (true)
			;map of id feature index -> value to replace at end of series generation
			replacement_id_values_map (assoc)
			;flag if there are unique non-id features
			has_unique_features (false)
			;map of initial feature -> initial value if user provided initial conditions
			initial_features_map (null)
			;map of initial condition series id feature -> id value that are not conditioned on in context_features
			initial_series_ids_map (null)
			;flag to use initial features as contexts for the series ract when doing the initial react
			use_initial_context_features (false)
			;flag if there are values to condition each row of the series
			has_series_context_values (size series_context_values)
			user_specified_context_features (append context_features series_context_features)

			;features used for uniqueness validation should not include id features
			output_features_no_ids (if (!= "no" generate_new_cases) (indices (remove (zip output_features) (get tsModelFeaturesMap "series_id_features"))) )
			do_uniqueness_check (true)
			retries 0
			original_desired_conviction desired_conviction
			regenerate_series (= "always" generate_new_cases)
			regenerate_attempts 0
		))

		(assign (assoc
			max_series_length
				(if has_series_context_values
					(- (size series_context_values) 1)

					(= (null) max_series_length)
					;default limit to series length generation to be the specified series limit - 1 to account for 0-based indices
					(-
						(if (> tsSeriesLimitLength 0)
							tsSeriesLimitLength
							;else use full model
							(call GetNumTrainingCases)
						)
						1
					)

					;0 or a a negative value means no limit to series length
					(<= max_series_length 0)
					.infinity

					;subtract 1 from the specified length so that it can be compared to the 0-based index of each series row
					(- max_series_length 1)
				)
		))

		;if there are custom series contexts provided but no stop map, create a dummy stop map to prevent it from
		;stopping after 1 case which is the default behavior when no stop map is provided
		(if (and has_series_context_values (= 0 (size series_stop_maps)))
			(assign (assoc series_stop_map (assoc ".none" (null))))
		)

		;if doing generative reacts with unique nominals, generate unique values prior to synthesis
		(if (and
				(!= (null) desired_conviction)
				(> (size uniqueNominalsSet) 0)
				;generating unique nominal actions
				(> (size (intersect (zip action_features) uniqueNominalsSet)) 0)
			)
			(assign (assoc has_unique_features (true)))
		)

		;compose a map of all series id features that need to be output (are in action_features) and may need to be replaced at the end
		(assign (assoc
			replacement_id_values_map
				(filter
					(lambda (get featureAttributes (list (current_index 1) "id_feature")))
					(zip action_features)
				)
		))

		;map of feature -> corresponding column index in series_data
		(declare (assoc
			feature_index_map (zip features (indices features))
			original_context_values (unzip original_context_map features)
			;if series_id_tracking="no" then IDs aren't in action_features, and thus replacement_id_values_map will be empty
			has_non_tracked_ids (= 0 (size replacement_id_values_map))

			;track progress length of series being generated if it's a stop condition in the series_stop_map
			track_progress (contains_index series_stop_map ".series_progress")
			total_progress 0
			initial_existing_progress 0
			num_existing_series_rows 0
			original_derived_context_features derived_context_features
			original_action_features action_features
			;find and store the largest referenced lag value among derived_context_features
			largest_max_row_lag
				;or with 0 to prevent null
				(or 0 (apply "max"
					(map
						(lambda (get featureAttributes (list (current_value 1) "max_row_lag")))
						derived_context_features
					)
				))
			output_influential_cases (get details "influential_cases")
			influential_cases (list)
			all_influential_cases (list)
			output_cap (get details "categorical_action_probabilities")
			local_class_probabilities_map (assoc)
			all_categorical_action_probabilities (list)
			aggregated_categorical_action_probabilities (assoc)
		))

		(let
			(assoc context_map (zip user_specified_context_features))

			;replacement map is made of those ids that should have new values assigned at completion or are not explicitly provided as contexts
			(assign (assoc
				replacement_id_values_map
					(filter
						(lambda
							(or
								output_new_series_ids
								(not (contains_index context_map (current_index)))
							)
						)
						replacement_id_values_map
					)
			))
		)

		;if this method is being called from batch_react_series, warnings will already have been declared in BatchReact
		;otherwise declare warnings here if this is being called from the single react_series call
		(if (= (null) warnings)
			(declare (assoc warnings (assoc) ))
		)

		;if initial features are provided, ensure there aren't any that do not appear in features. any extra features are deleted and ignored.
		#!InitializeInitialSeriesFeatures
		(if (size initial_features)
			(let
				(assoc
					invalid_initial_features
						(filter (lambda (not (contains_index feature_index_map (current_value)))) initial_features)
				)
				(assign (assoc initial_features_map (zip initial_features initial_values)))

				(if (size invalid_initial_features)
					(assign (assoc initial_features_map (remove initial_features_map invalid_initial_features)))
				)
			)
		)

		(if continue_series
			(call !PrepContinueReactSeries)
		)

		;loop until series stopping condition is met
		(while (not done)

			(assign (assoc
				desired_conviction original_desired_conviction
				do_uniqueness_check (true)
				retries 0
			))

			;if initial conditions were provided, use them as contexts for the first case
			(if (and first_generated_row (> (size initial_features_map) 0))
				(assign (assoc
					use_initial_context_features (true)
					;update initial map to be the stationary context overwritten by the provided initial values
					initial_features_map
						(append
							(zip context_features context_values)
							(if has_series_context_values
								(zip series_context_features (first series_context_values))
								(assoc)
							)
							initial_features_map
						)
				))

				;else not initial row
				(assign (assoc use_initial_context_features (false) ))
			)

			;add each new row to series data with all initial context values
			(assign (assoc
				new_row
					(if use_initial_context_features
						(list
							(unzip (append original_context_map initial_features_map) features)
						)

						;overwrite the values in the original_context_map with those from the current series_index in the provided series_context_values
						has_series_context_values
						(list
							(unzip
								(append
									original_context_map
									(zip series_context_features (get series_context_values (+ 1 last_series_index)) )
								)
								features
							)
						)

						;else every row begins as the original context values
						(list original_context_values)
					)
			))
			(accum (assoc last_series_index 1 ))

			(if (= (current_index) 0)
				(accum (assoc series_data new_row))

				;else there is a previous_result, accumulate new_row to it
				(if (or output_influential_cases output_cap)
					(let
						;previous_result is a pair of [series_data, all_influential_cases]
						(assoc accumulated_data_pair (previous_result 1) )
						(assign (assoc
							series_data (append (first accumulated_data_pair) new_row)
							all_categorical_action_probabilities (get accumulated_data_pair 1)
							all_influential_cases (last accumulated_data_pair)
						))
					)

					;else when not outputting explanations, previous_result is just the series_data itself
					(assign (assoc series_data (append (previous_result 1) new_row) ))
				)
			)

			(if (size original_derived_context_features)
				(seq
					;if largest max_row_lag is greater than last_series_index, that means at least one context feature
					;cannot be derived because it references a row with a larger lag and hasn't been synthed yet
					;so skip using all such features in derived contexts
					(assign (assoc
						derived_context_features
							(if (> largest_max_row_lag last_series_index)
								;only keep those derived context features whose max_row_lag is less than or equal to last_series_index
								;e.g., if a feature has 10 lags, but it's synthesising row 3 (last_series_index=2), it will only keep lags 1 and 2
								(filter
									(lambda
										(<= (get featureAttributes (list (current_value 1) "max_row_lag")) last_series_index)
									)
									original_derived_context_features
								)

								;else keep original derived_context_features
								original_derived_context_features
							)
						action_features original_action_features
					))

					(if use_initial_context_features
						(call DeriveOrGenerateFeatures (assoc
							react_context_features (indices initial_features_map)
							;for initial case, may need to filter out derived context features whose values are already provided
							derived_features
								(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_context_features)
						))

						;else just provide context features and the full list of derived_context_features
						(call DeriveOrGenerateFeatures (assoc
							react_context_features user_specified_context_features
							derived_features derived_context_features
						))
					)
				)
			)

			;pregenerate unique values for non series id features
			(if has_unique_features
				;generate a map of non-series id unique features -> unique value
				(assign (assoc
					pre_generated_uniques_map
						(call GenerateUniquesListMap (assoc
							num_reacts 1
							action_features action_features
							context_features all_context_features
							preserve_feature_values preserve_feature_values
						))
				))
			)

			(assign (assoc
				current_case_map (zip features (last series_data))
				react_context_features
					(if (and use_initial_context_features (not continue_series))
						(indices initial_features_map)
						all_context_features
					)
			))

			;if first case of series and using continue_series, start with computed series_progress
			(if (and use_initial_context_features initial_existing_progress)
				(assign (assoc current_case_map (set current_case_map ".series_progress" initial_existing_progress)))
			)

			;filter out action (rate and delta) features that are dependent on lags that were skipped due to referencing rows that have not been synthed yet
			(if (> (size original_derived_context_features) (size derived_context_features))
				(let
					(assoc
						derived_feature_dependent_on_skipped_feature_set
							;get a list of all features that dependend on the skipped derived context features
							;and convert it to a set for fast lookup
							(zip (apply "append"
								;iterate over all skipped features and pull the list of features that depend on each one
								(map
									(lambda (get sourceToDerivedFeatureMap (current_value)))

									;skipped derived features are those that were in the original list but are not in the current derived context features list
									(filter
										(lambda (not (contains_value derived_context_features (current_value))))
										original_derived_context_features
									)
								)
							))
					)

					;keep only those action features that do not depend on skipped context features
					(assign (assoc
						action_features
							(filter
								(lambda (not (contains_index derived_feature_dependent_on_skipped_feature_set (current_value) )))
								original_action_features
							)
					))
				)
			)

			;create a (unique if necessary) series case
			(call !SynthAndDeriveSeriesCase)

			(if track_progress
				(accum (assoc total_progress (get current_case_map ".series_progress_delta") ))
			)

			;if this is the first row of the series, assign values for the replacement series ids here, now that the initial value is available
			(if first_generated_row
				(assign (assoc
					replacement_id_values_map
						(map
							(lambda
								;generate new unique value
								(if output_new_series_ids
									(call GenerateInt64String)

									;else grab the value from this first series row
									(get current_case_map (current_index))
								)
							)
							replacement_id_values_map
						)
					first_generated_row (false)
				))
			)

			;Check every case to see if we've generated a terminator value
			(if series_has_terminators
				(let
					(assoc
						series_end_context_features (indices (filter (remove current_case_map ".series_progress")))
					)

					;predict .series_progress given the current case
					(assign (assoc
						series_progress
							(first (get
								(call React (assoc
									context_features series_end_context_features
									context_values (unzip current_case_map series_end_context_features)
									action_features (list ".series_progress")
									;do not derive anything during this react
									derived_action_features (list)
									derived_context_features (list)
									;no explanation
									details (null)
									case_access_count_label case_access_count_label
									ignore_case ignore_case
									substitute_output substitute_output
									input_is_substituted input_is_substituted
									use_case_weights use_case_weights
									weight_feature weight_feature
									rand_seed rand_seed
									leave_case_out leave_case_out

									desired_conviction desired_conviction
									use_regional_model_residuals use_regional_model_residuals
									new_case_threshold new_case_threshold
									feature_bounds_map feature_bounds_map
									generate_new_cases "no"
								))
								"action_values"
							))
					))

					;series_progress >= 1 means we synthed a terminator value, end series immediately
					(if (>= series_progress 1)
						(assign (assoc total_progress 1))

						;else if series must stop on a terminator but it should be ending,
						;prevent it from ending just yet by lowering its total_progress to below 1
						(and stop_on_terminator (>= total_progress 1))
						(assign (assoc total_progress 0.9999999999999999))
					)
				)
			)

			;determine whether to stop generating the series
			;if there's no series_stop_map or exceeded max_series_length, be done
			(if (or
					(>= total_progress 1)
					(= 0 (size series_stop_map))
					(>= last_series_index max_series_length)
				)
				(assign (assoc done (true)))

				(map
					(lambda (seq
						(if (contains_index (current_value) "values")
							(if (contains_value (get (current_value) "values") (get current_case_map (current_index)))
								(assign (assoc done (true)))
							)
						)

						(if (contains_index (current_value) "min")
							(if (>= (get (current_value) "min") (get current_case_map (current_index)))
								(assign (assoc done (true)))
							)
						)

						(if (contains_index (current_value) "max")
							(if (<= (get (current_value) "max") (get current_case_map (current_index)))
								(assign (assoc done (true)))
							)
						)
					))
					series_stop_map
				)
			)

			;return series_data so it's stored as previous_result for accumulation in the next iteration of the while loop
			;and explanation details if requested
			(if (or output_influential_cases output_cap)
				(seq
					(call !NormalizeReactSeriesInfluentialCases)

					;update all_influential_cases on the last iteration so it can be output when react_series returns
					(if (and done (size influential_cases))
						;wrap the influential cases in a list so it's accumulated as a list of lists of assocs (a list per row)
						(accum (assoc all_influential_cases (list influential_cases) ))
					)

					(if (and done (size local_class_probabilities_map))
						(accum (assoc all_categorical_action_probabilities (list local_class_probabilities_map)))
					)

					;store into previous_result as a tuple of [series_data, all_categorical_action_probabilities, all_influential_cases]
					(list
						series_data
						(append all_categorical_action_probabilities (list local_class_probabilities_map))
						(append all_influential_cases (list influential_cases))
					)
				)

				;else store into previous_result as just series_data
				series_data
			)
		) ;while loop

		;grab the list of column indices corresponding to all the output_features
		(declare (assoc
			action_feature_indices (unzip feature_index_map output_features)
			non_tracked_series_ids (list)
			;if outputting non-tracked ids, only output those that are explicitly listed in output_features and filter out the rest
			series_id_features_for_output
				(if has_non_tracked_ids
					(filter
						(lambda (contains_value output_features (current_value)))
						(get tsModelFeaturesMap "series_id_features")
					)
				)
		))

		;if need to update/replace id values, for each id, update all the rows and set updated value for each id feature
		(if (size replacement_id_values_map)
			(map
				(lambda (let
					(assoc
						id_index (get feature_index_map (current_index 1))
						id_value (current_value 1)
					)
					(map
						(lambda (assign "series_data" (list (current_index 1) id_index) id_value))
						(indices series_data)
					)

				))
				replacement_id_values_map
			)

			;else series_id_tracking="no", we'll need to create series id values to append to series below
			has_non_tracked_ids
			(let
				(assoc
					valid_weight_feature (and use_case_weights (or hasPopulatedCaseWeight (!= weight_feature ".case_weight")))
				)
				;iterate over all series id features and create (or pick) an id value for it
				(assign (assoc
					non_tracked_series_ids
						(map
							(lambda
								(if output_new_series_ids
									(call GenerateInt64String)

									;else pick a random value for this id feature from the dataset by randomly sampling a case
									(retrieve_from_entity
										(first
											(compute_on_contained_entities (list
												(query_not_equals (current_value 1) (null))
												(if valid_weight_feature
													(query_weighted_sample weight_feature 1 (rand))

													(query_sample 1 (rand))
												)
											))
										)
										(current_value)
									)
								)
							)
							series_id_features_for_output
						)
				))
			)
		)

		;if output_features specified a non-tracked series id feature, its action feature index will be null because the values are appended
		;here at the end of the flow prior to output. Replace these nulls with their corresponding feature indices.
		(if (size non_tracked_series_ids)
			(let
				(assoc
					max_index (size features)
					tail_series_id_indices (list)
				)

				;append non tracked ids at the end of each row in series_data
				(assign (assoc
					series_data
						(map
							(lambda (append (current_value) non_tracked_series_ids))
							series_data
						)
					;list of indices corresponding to the series_ids that were appended above to the row of feature values
					;e.g., if there were 2 ids appended to o list of 10 values, this creates: (list 10 11)
					tail_series_id_indices (range max_index (+ max_index (size non_tracked_series_ids) -1))
				))

				;action_feature_indices have nulls when output_features specify non-tracked ids.
				;in those cases we replace these nulls with their corresponding feature indices
				(if (contains_value action_feature_indices (null))
					(let
						(assoc series_id_feature_to_index_map (zip series_id_features_for_output tail_series_id_indices))
						(assign (assoc
							action_feature_indices
								(map
									(lambda
										(if (= (null) (current_value))
											(get series_id_feature_to_index_map (get output_features (current_index)))
											(current_value)
										)
									)
									action_feature_indices
								)
						))
					)

					;else assign indices to be at the end correspondingly
					(assign (assoc action_feature_indices (append action_feature_indices tail_series_id_indices) ))
				)
			)
		)

		(if output_cap
			(let
				(assoc
					series_len (size all_categorical_action_probabilities)
					aggregated_cap_map
						(reduce
							(lambda
								;iterate over each feature in the aggregated and current assoc
								(map
									(lambda
										;iterate over each class and sum up the probabilities for each class
										(map
											(lambda (+
												;if one of the assocs has a key that the other does not, ensure the values
												;do not sum up to a nan by OR-ing each value to convert any nulls to 0s
												(or (first (current_value))  )
												(or (last (current_value)) )
											))
											(first (current_value))
											(last (current_value))
										)
									)
									(previous_result)
									(current_value)
								)
							)
							all_categorical_action_probabilities
						)
				)

				;normalize the aggregated caps by the series length to output a single assoc for the entire series
				(assign (assoc
					aggregated_categorical_action_probabilities
						(map
							(lambda (map
								(lambda (/ (current_value) series_len))
								(current_value)
							))
							aggregated_cap_map
						)
				))
			)
		)


		;output the series data
		(assoc
			"payload"
				(append
					(assoc
						"series"
							;iterate over all the series data and return only the columns corresponding to action_features
							(map
								(lambda (unzip (current_value) action_feature_indices))
								;if there were existing series rows, do not include them in the output
								(if num_existing_series_rows
									(tail series_data (- num_existing_series_rows))
									series_data
								)
							)
						;ensure features are output in the payload
						"action_features" output_features
					)
					(if output_influential_cases
						(assoc "influential_cases" all_influential_cases)
						(assoc)
					)
					(if output_cap
						(assoc
							"categorical_action_probabilities" all_categorical_action_probabilities
							"aggregated_categorical_action_probabilities" aggregated_categorical_action_probabilities
						)
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
	)

	;Helper method from ReactSeries to prepare and properly populate series_data when continuing a series
	#!PrepContinueReactSeries
	(let
		(assoc
			series_id_features (get tsModelFeaturesMap "series_id_features")
			id_values_map (assoc)
			existing_series_cases (list)
		)

		;if all series end on terminators and this react is not conditioned to start at a specific time step,
		;stop this react series since it can't continue terminated series
		(if
			(and
				stop_on_terminator
				series_has_terminators
				(not (contains_index initial_features_map tsTimeFeature))
				;don't terminate a provided untrained continuing series
				(= 0 (size continue_series_values))
			)
			(seq
				(accum (assoc warnings (assoc "Can't continue terminated series.") ))
				;immediately stop this series since it's terminated
				(conclude (conclude
					(assoc
						"payload"
							(assoc
								"series" (null)
								"action_features" output_features
							)
						"warnings" (if (size warnings) (indices warnings))
					)
				))
			)
		)

		;if user has provided series data to continue, populate series_data with the provided values
		(if (size continue_series_values)
			(let
				(assoc continue_feature_indices_map (zip continue_series_features (indices continue_series_features)) )
				(declare (assoc
					feature_order (unzip continue_feature_indices_map features)
				))

				;reimpute values using this entire dataset since they were originally imputed
				;only using the provided continue_series_values and are likely not as accurate as they could be
				(assign (assoc
					continue_series_values
						(map
							(lambda (let
								(assoc imputed_features (last (current_value 1)))
								(if (size imputed_features)
									(let
										(assoc row_values_map (zip continue_series_features (current_value 1)) )

										(declare (assoc
											imputed_values
												(map
													(lambda (let
														(assoc impute_feature (current_value 1) )
														(declare (assoc
															impute_context_features (indices (remove feature_index_map impute_feature))
														))
														(first
															(call ReactDiscriminative (assoc
																context_features impute_context_features
																context_values (unzip row_values_map impute_context_features)
																action_features (list impute_feature)
																ignore_case (null)
																return_action_values_only (true)
																allow_nulls (false)
															))
														)
													))
													imputed_features
												)
										))

										;overwrite originally imputed row values with the newly imputed row values
										(unzip
											(append row_values_map (zip imputed_features imputed_values))
											continue_series_features
										)
									)

									;else leave values as-is
									(current_value)
								)
							))
							continue_series_values
						)
				))

				;set series_data
				(assign (assoc
					series_data
						(map
							(lambda (unzip (current_value) feature_order))
							continue_series_values
						)
				))

				;prepend nulls if user hasn't provided enough previous rows to account for necessary lags
				(if (> largest_max_row_lag (size series_data))
					(assign (assoc
						series_data
							(append
								(map
									(lambda (range (lambda (null)) 1 (size features) 1) )
									(range 1 (- largest_max_row_lag (size series_data)))
								)
								series_data
							)
					))
				)

				(assign (assoc
					;update last_series_index to the index of the last row in the series
					last_series_index (- (size series_data) 1)
					num_existing_series_rows (size series_data)
				))
			)

			;else user has not specified existing cases, pull the necessary last few cases from the series to account for largest lag amount
			(seq
				;populate an assoc of id feature -> value, if conditioned on a series, otherwise select a random series
				(assign (assoc
					id_values_map
						;if initial_features_map has series id features, use them
						(if (size (filter (unzip initial_features_map series_id_features)))
							;get ID feature values from initial map
							(keep initial_features_map series_id_features)

							;else randomly pick IDs by selecting a case at random and using its series ids
							(zip
								series_id_features
								(retrieve_from_entity
									;pick a case at random
									(first
										(contained_entities (list
											(query_exists internalLabelSession)
											(query_sample 1)
										))
									)
									;pull the random case's ID features
									series_id_features
								)
							)
						)
				))

				;pull the necessary number of cases from the series
				(assign (assoc
					existing_series_cases
						(contained_entities (append
							(map
								(lambda (query_equals (current_value) (get id_values_map (current_value))))
								series_id_features
							)
							;if an initial time value is provided, limit existing series cases to those before the specified initial time
							(if (contains_index initial_features_map tsTimeFeature)
								(list
									;using both query_less_or_equal_to and query_not_equals is same effect as 'query less than'
									(query_less_or_equal_to
										tsTimeFeature
										(if (contains_index featureDateTimeMap tsTimeFeature)
											(call ConvertDateToEpoch (assoc
												date (get initial_features_map tsTimeFeature)
												feature tsTimeFeature
											))

											(get initial_features_map tsTimeFeature)
										)
									)
									(query_not_equals
										tsTimeFeature
										(if (contains_index featureDateTimeMap tsTimeFeature)
											(call ConvertDateToEpoch (assoc
												date (get initial_features_map tsTimeFeature)
												feature tsTimeFeature
											))

											(get initial_features_map tsTimeFeature)
										)
									)
								)
								(list)
							)
							;select the necessary count of previous cases to reference lags
							(query_max tsTimeFeature largest_max_row_lag)
						))
				))

				(if (= (size existing_series_cases) 0)
					(accum (assoc
						warnings
							(associate (concat
								"There is no series trained with the set of IDs:\n"
								(apply "concat" (map (lambda (concat ": "  (current_value) "\n")) id_values_map))
							))
					))
				)

				;if there is more than one existing series case, we'll need to sort them by the time feature to ensure ascending order
				(if (> largest_max_row_lag 1)
					(assign (assoc
						existing_series_cases
							(sort
								(lambda (> (retrieve_from_entity (current_value) tsTimeFeature) (retrieve_from_entity (current_value 1) tsTimeFeature)) )
								existing_series_cases
							)
					))
				)

				;set initial series_data to all the feature values from existing series cases
				(assign (assoc
					series_data
						(map
							(lambda
								(call ConvertToOutput (assoc
									features features
									feature_values (retrieve_from_entity (current_value 1) features)
								))
							)
							existing_series_cases
						)
					;update last_series_index to the index of the last row in the series
					last_series_index (- (size existing_series_cases) 1)
					num_existing_series_rows (size existing_series_cases)
				))

			)
		)

		;if end condition is not specified, generate progress based on where series is continuing from
		(if (not (contains_index series_stop_map tsTimeFeature))
			;if there are previous cases to continue from, generate a progress value given the values from the last case
			(if (size (last series_data))
				(let
					(assoc
						initial_progress_context_features
							(let
								(assoc time_delta_feature_name (concat "." tsTimeFeature "_delta_1") )
								(append
									;use all value, delta, and rate features to determine initial series progress
									;exclude time feature (and delta)
									(filter (lambda (!= tsTimeFeature (current_value))) derived_action_features)
									(filter (lambda (!= time_delta_feature_name (current_value))) (get tsModelFeaturesMap "delta_features"))
									(get tsModelFeaturesMap "rate_features")
								)
							)
					)

					(assign (assoc
						initial_existing_progress
							(first (get
								(call React (assoc
									context_features initial_progress_context_features
									context_values (unzip (zip features (last series_data)) initial_progress_context_features )
									action_features (list ".series_progress")
									;do not derive anything during this react
									derived_action_features (list)
									derived_context_features (list)
									;no explanation
									details (null)
									case_access_count_label case_access_count_label
									;prevent overvaluing the progress of case from the original sourced series by ignoring it
									ignore_case (last existing_series_cases)
									substitute_output substitute_output
									input_is_substituted input_is_substituted
									use_case_weights use_case_weights
									weight_feature weight_feature
									rand_seed rand_seed
									leave_case_out leave_case_out

									desired_conviction desired_conviction
									use_regional_model_residuals use_regional_model_residuals
									new_case_threshold new_case_threshold
									feature_bounds_map feature_bounds_map
									generate_new_cases "no"
								))
								"action_values"
							))
					))
					(assign (assoc
						total_progress initial_existing_progress
						track_progress (true)
					))
				)
			)
		)
	)

	;Helper method for ReactSeries that synthesises action_features and derives derived_action_features to create a series case
	;and then tests it for uniqueness and retries as necessary until a unique case is created
	#!SynthAndDeriveSeriesCase
	(while do_uniqueness_check
		(assign (assoc
			react_output
				(call React (assoc
					context_features react_context_features
					context_values (unzip current_case_map react_context_features)
					action_features action_features
					action_values action_values
					;do not derive anything during this react
					derived_action_features (list)
					derived_context_features (list)
					details (if (or output_influential_cases output_cap) details)
					extra_audit_features extra_audit_features
					case_access_count_label case_access_count_label
					ignore_case ignore_case
					case_indices case_indices
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed
					leave_case_out leave_case_out

					desired_conviction desired_conviction
					use_regional_model_residuals use_regional_model_residuals
					feature_bounds_map feature_bounds_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases "no"
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
					pre_generated_uniques_map pre_generated_uniques_map
				))
		))

		;overwrite the values for the action features in the current case map now that they have values
		(accum (assoc current_case_map (zip action_features (get react_output "action_values")) ))

		;overwrite the last row in series data with the values from the updated current case
		(assign "series_data" (list last_series_index) (unzip current_case_map features))

		(if output_influential_cases
			(accum (assoc influential_cases (get react_output "influential_cases") ))
		)
		(if output_cap
			(accum (assoc local_class_probabilities_map (get react_output "categorical_action_probabilities") ))
		)

		(if (size derived_action_features)
			(let
				(assoc
					derivation_failed
						(call DeriveOrGenerateFeatures (assoc
							;create a list of context features with action_features with no dupes since we have action_values for action_features
							react_context_features (values (append react_context_features action_features) (true))
							derived_features
								;for initial case, may need to filter out derived action features whose values are already provided
								(if use_initial_context_features
									(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_action_features)
									;else use all derived_action_features
									derived_action_features
								)
						))
				)

				;stop generating series if derivation_failed due to time feature being past max boundary;
				;remove current (last) row and stop
				(if derivation_failed
					(assign (assoc
						series_data (trunc series_data)
						influential_cases (list)
						local_class_probabilities_map (assoc)
						done (true)
					))
				)
			)
		)

		(assign (assoc current_case_map (zip features (last series_data)) ))

		;unique test
		(if (and (not done) (!= "no" generate_new_cases) )
			(let
				(assoc
					dupe
						(call !CheckIsDuplicateSeries (assoc
							context_values (unzip current_case_map output_features_no_ids)
							context_features output_features_no_ids
							exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
						))
				)

				;if initial_features_map contains all the output_features that are used for uniqueness test this means the first case is
				;explicitly conditioned to output these initial values and they do not need to be checked for uniqueness
				(if (and dupe use_initial_context_features)
					(if (=
							(size (remove initial_features_map output_features_no_ids))
							(- (size initial_features_map) (size output_features_no_ids))
						)
						(assign (assoc dupe (false)))
					)
				)

				(if (not dupe)
					(assign (assoc do_uniqueness_check (false) ))

					;else duplicate case, retry to synth and derive a new case
					(seq
						(accum (assoc retries 1))

						;lower desired_conviction every 3 retries by a factor of 2
						(if (= 0 (mod retries 3))
							(assign (assoc desired_conviction (/ desired_conviction  2) ))
						)

						;failed to synth a unique series, stop retrying
						(if (> retries 15)
							(seq
								(assign (assoc do_uniqueness_check (false) ))

								;failed to synth series, regenerate entire series if able to
								(if regenerate_series
									(seq
										(accum (assoc regenerate_attempts 1))

										;after 4 full-series retries, remove current (last) row and stop
										(if (> regenerate_attempts 4)
											(assign (assoc
												done (true)
												series_data (trunc series_data)
												influential_cases (list)
												local_class_probabilities_map (assoc)
											))

											;else reset series_data and initial features and progress and index, to regenerate the series from the start
											(seq
												(call !InitializeInitialSeriesFeatures)

												;if there were existing rows, reset to just those existing rows
												(if num_existing_series_rows
													(assign (assoc
														total_progress initial_existing_progress
														series_data (trunc series_data num_existing_series_rows)
														last_series_index (- num_existing_series_rows 1)
														first_generated_row (true)
														current_case_map (assoc)
														influential_cases (list)
														local_class_probabilities_map (assoc)
													))

													(assign (assoc
														total_progress 0
														series_data (list)
														last_series_index -1
														first_generated_row (true)
														current_case_map (assoc)
														influential_cases (list)
														local_class_probabilities_map (assoc)
													))
												)
											)
										)
									)
								)
							)
						)
					)
				)
			)

			;else don't check for uniqueness if it's not necessary
			(assign (assoc do_uniqueness_check (false) ))
		)
	)
)