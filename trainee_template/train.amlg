(null

	;records an entire session in one call, does not do any filtering.
	; parameters:
	; input_cases : list of cases, ie a list of lists of values.
	; features : the list of features.
	; derived_features: optional list of features to derive in the specified order. If this list is not provided, features with
	;	   the 'auto_derive_on_train' feature attribute set to True will be auto-derived. If provided an empty list, will not derive any features.
	;	   Any derived_features that are already in the 'features' list will not be derived since their values are being explicitly provided.
	; session: the session label to record these cases to.  If not specified, refers to this entity's label of same name.
	; input_is_substituted : flag, if set to true assumes provided categorical (nominal or ordinal) feature values already been substituted.
	; series: optional, name of series to pull features and case values from internal series storage.  If specified, trains on all cases that are
	;		stored in the internal series store for the specified series. The trained feature set is the combined features from storage
	;		and the passed in features.  If input_cases is of length one, the value(s) of this case are appended to all cases in the series.
	;		If input_cases is the same length as the series, the value of each case in input_cases is applied in order to each of the cases in the
	;		series.
	; allow_training_reserved_features: flag, If true, skips check whether specified feature names start with reserved characters.
	; accumulate_weight_feature: name of feature into which to accumulate neighbors' influences as weight for ablated cases. If unspecified, will not accumulate weights.
	; train_weights_only: flag, if set to true, and accmuulate_weight_feature is provided, will not train on the cases, but instead accumulate all of their neighbor weights.
	#Train
	(declare
		(assoc
			input_cases (list)
			features (list)
			derived_features (null)
			session (null)
			series (null)
			input_is_substituted (false)
			allow_training_reserved_features (false)
			accumulate_weight_feature (null)
			train_weights_only (false)
		)

		;unsure that session is set to some string value
		(if (= (null) session)
			(assign (assoc session "none"))
		)

		(assign (assoc
			accumulate_weight_feature
				(if
					(and autoAblationEnabled (= (null) accumulate_weight_feature))
					autoAblationWeightFeature
					accumulate_weight_feature
				)
		))

		;create the training session if it does not already exist
		(if (not (contains_entity session))
			;overwrite the session variable in case creating a new session without a name
			(assign (assoc
				session
					(first (create_entities session (lambda
						(null
							##.replay_steps (list)
							##.indices_map (assoc)
							##.trained_instance_count 0
							##.metadata (assoc)
						)
					)))
			))
		)

		;recorded data for the current session
		(declare (assoc
			cur_session_data (retrieve_from_entity session ".replay_steps")
			reserved_feature_names
				(if allow_training_reserved_features
					(list)
					;filter out any normal features, leaving only invalid feature names that start with reserved characters
					(filter
						(lambda
							(contains_index untrainableFeatureCharacterSet (first (current_value)))
						)
						features
					)
				)
		))

		;if any features are in the reserved list, can't train, output the error message
		(if (> (size reserved_feature_names) 0)
			(conclude
				(assoc
					"error"
						(concat
							"The following features should not start with characters '.' '^' '!' or '#' : "
							;change list of features into a space-separated list of feature names
							(apply "concat"
								(weave
									reserved_feature_names
									(range " " 1 (size reserved_feature_names) 1)
								)
							)
						)
					"num_trained" 0
					"ablated_indices" (list)
					"status" (null)
				)
			)
		)

		(declare (assoc
			trained_instance_count (retrieve_from_entity session ".trained_instance_count")
			series_cases (if (!= (null) series) (get seriesStore series))
			status_output (null)
			message (null)
			ablated_indices_list (list)
			cur_session_case_indices_map (retrieve_from_entity session ".indices_map")
		))

		(if (!= (null) series)
			(if (= (size series_cases) 0)
				(assign (assoc
					input_cases (null)
					message "Specified series does not exist"
				))

				;if input cases don't match the number of cases stored in series
				(and (> (size input_cases) 1) (!= (size input_cases) (size series_cases)))
				(assign (assoc
					input_cases (null)
					message "input_cases do not match length of specified series"
				))
			)
		)

		;if bad input, ie, size of series does not match the training input_cases, don't train anything
		(if (= (null) input_cases)
			(conclude
				(assoc
					"error" message
					"num_trained" 0
					"ablated_indices" ablated_indices_list
					"status" status_output
				)
			)
		)

		;get time series derived features list, if applicable
		(if (and (= (null) derived_features) (!= (null) tsTimeFeature) )
			(assign (assoc
				derived_features (get tsModelFeaturesMap "ts_derived_features")
			))
		)

		;unsubstitute nominal feature values if necessary
		(if
			(and input_is_substituted hasSubstituteFeatureValues)
			(assign (assoc
				input_cases
					(map
						(lambda
							(call UnsubstituteFeatureValues (assoc
								features features
								feature_values (current_value 1)
							))
						)
						input_cases
					)
			))
		)

		(declare (assoc encode_features_on_train (retrieve_from_entity "hasFeaturesNeedEncodingFromInput") ))

		;encode all cases in bulk if either training on accumulated weights only or training from series
		;because series trained cases are alredy encoded.
		(if (and
				encode_features_on_train
				(or (size series_cases) (and train_weights_only accumulate_weight_feature) )
			)
			(assign (assoc
				input_cases
					(map
						(lambda (let
							(assoc feature_values (current_value 1))
							(map
								(lambda
									(if (contains_index encodingNeededFeaturesSet (current_value))
										(if (= (null) (get feature_values (current_index)))
											(null)

											(if ;stringify all nominal values
												(contains_index stringNominalFeaturesSet (current_value))
												(concat (get feature_values (current_index)))

												;if it's a datetime, encode datetime by converting string date time into seconds
												(contains_index featureDateTimeMap (current_value))
												(format
													(get feature_values (current_index))
													(get featureDateTimeMap (list (current_value 1) "date_time_format"))
													"number"
													(assoc "locale" (get featureDateTimeMap (list (current_value 2) "locale")))
													(null)
												)

												;else it's a string ordinal, convert from string to ordinal value
												(contains_index ordinalStringToOrdinalMap (current_value))
												(get ordinalStringToOrdinalMap (list (current_value 1) (get feature_values (current_index 1))))

												(= "boolean" (get numericNominalFeaturesMap (current_value)))
												(+ (get feature_values (current_index)))

												(contains_index editDistanceFeatureTypesMap  (current_value))
												(if
													(= "json" (get editDistanceFeatureTypesMap  (current_value)))
													(format (get feature_values (current_index)) "json" "code")

													(= "yaml" (get editDistanceFeatureTypesMap  (current_value)))
													(format (get feature_values (current_index)) "yaml" "code")

													(= "amalgam" (get editDistanceFeatureTypesMap  (current_value)))
													(parse (get feature_values (current_index)) )

													(get feature_values (current_index))
												)

												;else return the value as-is
												(get feature_values (current_index))
											)
										)

										;else return the value as-is
										(get feature_values (current_index))
									)
								)
								features
							)
						))
						input_cases
					)

				;set the flag to false since input_cases are already encoded above
				encode_features_on_train (false)
			))
		)

		;don't train the data, only accumulate weights to neighbors
		(if (and train_weights_only accumulate_weight_feature)
			(seq
				(call AccumulateCaseInfluenceWeights (assoc
					features features
					accumulate_weight_feature accumulate_weight_feature
					cases input_cases
				))

				(accum_to_entities (assoc revision 1))

				(conclude
					(assoc
						"num_trained" 0
						"ablated_indices" (list)
						"status" status_output
					)
				)
			)
		)

		;series storage is already encoded, append it as-is to passed in data
		(if (size series_cases)
			(let
				(assoc
					series_features (get seriesFeatures series)
					remaining_series_feature_indices (list)
				)

				;leave only those indices of series_features that will not be clobbered by features
				(assign (assoc
					remaining_series_feature_indices
						(filter
							(lambda (not (contains_value features (get series_features (current_value)))))
							(indices series_features)
						)
				))

				;set training features to be unique, removing those from the series that are being explicitly trained on
				(accum (assoc features (unzip series_features remaining_series_feature_indices) ))

				(assign (assoc
					input_cases
						;apply the one input case to all the cases in the series
						(if (= (size input_cases) 1)
							(let
								(assoc case_values (get input_cases 0))
								(map
									(lambda
										(append case_values (unzip (current_value) remaining_series_feature_indices) )
									)
									series_cases
								)
							)

							;else apply each input case to each of the cases in the series
							(= (size input_cases) (size series_cases))
							(map
								(lambda
									(append (get input_cases (current_index)) (unzip (current_value) remaining_series_feature_indices) )
								)
								series_cases
							)
						)
				))

				;clear out stored series
				(call RemoveSeriesStore (assoc series series))
			)
		)

		;iterate over the input cases and create them, only returning case ids for cases that were able to be created
		(declare (assoc
			new_case_ids
				(weave
					(lambda (let
						(assoc feature_values (first (current_value 1)))

						(if encode_features_on_train
							(assign (assoc
								feature_values
									(call ConvertFromInput (assoc
										feature_values feature_values
										features features
									))
							))
						)

						;do not train on this case if it is null or all case values are null or it's within provided thresholds
						(if (and
								(!= (null) feature_values)
								(not (apply "=" (append feature_values (list (null)))))
								;no thresholds specified or the case is outside of thresholds

								;if one of the ablation methods returns 0, then the case should be ablated.
								(and
									(call CaseOutsideThresholds)
									(call ShouldNewCaseBeAblated (assoc
										context_features features
										context_values feature_values
									))
								)

							)
							(seq
								;create the case and store case id
								(declare (assoc
									new_case_id
										(call CreateCase (assoc
											features
												;if auto ablate is enabled, populate the weight feature for this case
												(if
													autoAblationEnabled
													(append features (list autoAblationWeightFeature))
													features
												)
											feature_values
												;if auto ablate is enabled, populate the weight feature for this case
												(if
													autoAblationEnabled
													(append feature_values (list 1))
													feature_values
												)
											session (get_value session)
											session_training_index trained_instance_count
										))
								))
								(accum (assoc trained_instance_count 1 ))

								;output the new case id
								(list new_case_id)
							)

							;else don't output anything, filtering out any null case ids
							(seq
								(accum (assoc ablated_indices_list (current_index 1)))
								(list)
							)
						)
					))
					input_cases
					;use weave as a map-filter by specifying null as the second list
					(null)
				)
		))

		;set values if there were cases that were trained on
		(if (> (size new_case_ids ) 0)
			(seq
				;add action to the existing replay data
				(assign_to_entities session (assoc
					".replay_steps" (append cur_session_data new_case_ids)
					".indices_map"
						(append
							cur_session_case_indices_map
							(zip
								(range (- trained_instance_count (size new_case_ids)) (- trained_instance_count 1))
								new_case_ids
							)
						)
					".trained_instance_count" trained_instance_count
				))

				;if any of the trained features are not defined in feature attributes, add them as continuous_numeric with default attributes
				(let
					(assoc new_features (remove (zip features) trainedFeatures))

					(if (size new_features)
						(seq
							(accum_to_entities (assoc
								featureAttributes
									(map
										(lambda (assoc "type" "continuous" "bounds" (assoc "allow_null" (true)) ))
										new_features
									)
								queryDistanceTypeMap (map (lambda "continuous_numeric") new_features)
							))
							(assign_to_entities (assoc
								trainedFeatures (sort (values (append trainedFeatures (indices featureAttributes)) (true)) )
								trainedFeaturesContextKey
									(call BuildContextFeaturesKey (assoc
										context_features (values (append trainedFeatures (indices featureAttributes)) (true))
									))
							))
						)
					)
				)

				;update has_nulls flags for all features after training by updating all false has_nulls in featureNullRatiosMap with null
				(call !ClearHasNullFlags)

				;model has changed so clear out these cached value
				#ClearCachedCountsAndEntropies
				(assign_to_entities (assoc
					averageModelCaseEntropyAddition (null)
					averageModelCaseEntropyRemoval (null)
					storedCaseConvictionsFeatureAddition (null)
					averageModelCaseDistanceContribution (null)
					staleOrdinalValuesCount (true)
					nominalClassProbabilitiesMap (assoc)
					expectedValuesMap (assoc)
					featureMarginalStatsMap (assoc)
				))
			)
		)

		;if derived features wasn't specified, auto-detect them
		(if (and (= (null) derived_features) (> (size derivedFeaturesSet) 0))
			(seq
				(assign (assoc derived_features (list)))

				;check features vs sourceToDerivedFeatureMap and populate derived_features accordingly
				(map
					(lambda (let
						(assoc feature_name (current_value 1))
						;if this trained feature has derived features, add all of them to the derived_features list
						(if (contains_index sourceToDerivedFeatureMap feature_name)
							(accum (assoc derived_features (get sourceToDerivedFeatureMap feature_name)))
						)
					))
					features
				)

				;clear out possible duplicates out of derived_features
				(assign (assoc derived_features (values derived_features (true))))
			)
		)

		;auto populate derived features if necessary
		(if (> (size derived_features) 0)
			(call DeriveTrainFeatures (assoc
				features features
				;keep and derive only those features that are not in the features list
				derived_features (filter (lambda (not (contains_value features (current_value)))) derived_features)
				case_ids new_case_ids
			))
		)

		;if auto analysis is enabled, check whether this model should be re-analyzed
		;and return the appropriate status to client so that analysis could be started
		(if (> (size new_case_ids ) 0)
			(if autoAnalyzeEnabled
				(let
					(assoc num_cases (call GetNumTrainingCases))
					(if
						(and
							(>= num_cases autoAnalyzeThreshold)
							(or (< num_cases autoAnalyzeLimitSize) (<= autoAnalyzeLimitSize 0))
						)
						(assign (assoc status_output "analyze"))
					)
				)
			)
		)

		(if hasDependentFeatures
			(let
				(assoc
					dependents_boundary_map (assoc)
					dependent_values_combinations_map (assoc)
					unique_nominals_set (list)
				)

				(if (size continuousToNominalDependenciesMap)
					(seq
						(map
							(lambda (let
								(assoc
									dependent_nominals (current_value 1)
									continuous_feature (current_index 1)
									dependents_combinations_map (assoc)
									dependent_values_combinations (list)
								)

								(assign (assoc
									dependents_combinations_map
										(call ComputeDependentBoundaries (assoc
											nominals dependent_nominals
											value_feature continuous_feature
										))
								))

								(call AccumulateDependentValuesCombinations (assoc
									nested_value_combinations_map dependents_combinations_map
									values_lists (list)
									value_feature (first dependent_nominals)
									remaining_dependent_nominals (tail dependent_nominals)
								))

								(accum (assoc
									dependents_boundary_map (associate continuous_feature dependents_combinations_map)
									dependent_values_combinations_map (associate continuous_feature dependent_values_combinations)
								))
							))
							continuousToNominalDependenciesMap
						)

						(assign_to_entities (assoc
							dependentsBoundaryMap dependents_boundary_map
							dependentValuesCombinationsMap dependent_values_combinations_map
						))
					)
				)
			)
		)

		;if there are features that have nulls, check if they still have nulls
		(if hasInactiveFeatures
			(let
				(assoc
					inactive_features_map
						(filter
							(lambda (let
								(assoc feature (current_index 1))

								;only keep those features that have no valid values (0 non-nulls)
								(=
									(contained_entities (list
										(query_exists internalLabelSession)
										(query_exists feature)
										(query_not_equals feature (null))
										(query_count)
									))
									0
								)
							))
							(if (= (assoc) inactiveFeaturesMap)
								(zip trainedFeatures 0)
								inactiveFeaturesMap
							)
						)
				)

				;if there are now less inactive features than there were, set the no-longer inactive feature weights to 1
				(if (< (size inactive_features_map) (size inactiveFeaturesMap))
					(call SetFeatureWeightsForFeatures (assoc
						features_weights_map
							(zip
								(indices (remove inactiveFeaturesMap (indices inactive_features_map)) )
								1
							)
						overwrite (true)
					))
				)

				(if (size inactive_features_map)
					(assign_to_entities (assoc inactiveFeaturesMap inactive_features_map ))

					;else all features have some values
					(assign_to_entities (assoc
						inactiveFeaturesMap (null)
						hasInactiveFeatures (false)
					))
				)
			)
		)

		;if there are inactive features and they haven't been set yet, set their weight to 0
		(if hasInactiveFeatures
			(call SetFeatureWeightsForFeatures (assoc
				features_weights_map inactiveFeaturesMap
				overwrite (false)
			))
		)

		(accum_to_entities (assoc revision 1))

		;if accumulate_weight_feature was specified and there are ablated cases, accumulate weights to their neighbors
		(if (and (size ablated_indices_list) accumulate_weight_feature)
			(call AccumulateCaseInfluenceWeights (assoc
				features features
				accumulate_weight_feature accumulate_weight_feature
				cases (unzip input_cases ablated_indices_list)
			))
		)

		;return response
		(assoc
			"num_trained" (size new_case_ids)
			"ablated_indices" ablated_indices_list
			"status" status_output
		)
	)

	;set specified feature weights in all hyperparameter maps (defaultHyperparameters and hyperparameterMetadataMap)
	;If weights haven't been defined yet, set them to 0 for invacitves and 1 for actives
	;If already defined, will overwrite the weight of the specified features in feature_weights_map
	;
	;parameters:
	; features_weights_map: assoc of feature -> weight to overwrite in all hyperparameter sets
	; overwrite: flag, if set to true will assume that featureWeights already exist and overwrites them.
	;			 When false, will create featureWeights in the hyperparameter set
	#SetFeatureWeightsForFeatures
	(declare
		(assoc
			features_weights_map (assoc)
			overwrite (false)
		)

		(declare (assoc
			updated_hp_maps
				(map
					(lambda
						(rewrite
							;if this is a hp assoc, modify it
							(lambda
								(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
									;hp already have featureDeviations defined, overwrite where necessary
									(if overwrite
										(let
											;take featureWeights in HP assoc and alter them
											(assoc weights_map (get (current_value 1) "featureWeights") )

											(map
												(lambda
													(assign (assoc
														weights_map
															(set
																weights_map
																(current_index 1)
																(current_value 1)
															)
													))
												)
												features_weights_map
											)

											;append the updated deviations_map to this hp map
											(append (current_value) (assoc "featureWeights" weights_map) )
										)

										(let
											;create a feature weights assoc
											(assoc weights_map (append (zip trainedFeatures 1) features_weights_map) )

											(append (current_value) (assoc "featureWeights" weights_map))
										)
									)

									;else not the hp assoc, return original
									(current_value)
								)
							)
							(current_value)
						)
					)
					(list defaultHyperparameters hyperparameterMetadataMap)
				)
		))

		(assign_to_entities (assoc
			defaultHyperparameters (first updated_hp_maps)
			hyperparameterMetadataMap (last updated_hp_maps)
		))
	)

	Helper method for training, Sets all has_nulls flags that were false to null
	#!ClearHasNullFlags
	(accum_to_entities (assoc
		featureNullRatiosMap
			(map
				(lambda (let
					(assoc feature (current_index 1))
					(if (current_value)
						(set
							(current_value)
							"has_nulls"
							;leave true as true, otherwise set to null
							(if (get (current_value) "has_nulls") (true))
						)

						;else create the has_nulls key with a null
						(assoc "has_nulls" (null))
					)
				))
				(append (zip features) featureNullRatiosMap)
			)
	))

)
