;Howso API Labels:
;
;	"clean_data"
;	"clear_conviction_thresholds"
;	"compute_conviction_of_features"
;	"batch_react_group"
;	"create_trainee"
;	"delete"
;	"get_loaded_trainees"
;	"get_num_training_cases"
;   "edit_cases"
;	"get_sessions"
;	"get_session_metadata"
;	"set_session_metadata"
;	"get_session_indices"
;	'get_session_training_indices"
;	"impute"
;	"load"
;	"train"
;	"react"
;	"react_series"
;	"batch_react"
;	"append_to_series_store"
;	"remove_series_store"
;	"remove_session"
;	"get_cases"
;	"save"
;	"copy"
;	"set_conviction_upper_threshold"
;	"set_conviction_lower_threshold"
;	"set_feature_attributes"
;	"get_feature_attributes"
;	"get_metadata"
;	"set_metadata"
;	"set_substitute_feature_values"
;	"get_substitute_feature_values"
;	"react_into_features"
;	"retrieve_extreme_cases_for_feature"
;	"auto_analyze"
;	"analyze"
;	"set_random_seed"
;	"get_internal_parameters"
;	"set_internal_parameters"
;	"set_auto_analyze_params"
;	"move_cases"
;	"reset_parameter_defaults"
;	"get_trainee_version"
;	"remove_feature"
;	"add_feature"
;	"react_into_trainee"
;	"get_feature_residuals"
;	"get_feature_mda"
;	"get_feature_contributions"
;	"get_prediction_stats"
;	"get_marginal_stats"
;	"pairwise_distances"
;	"distances"
;	"set_min_ablatement_model_size"
;	"set_influence_weight_threshold"
;	"export_trainee"
;	"upgrade_trainee"
;	"get_api"
;	"get_revision"
;	"evaluate"
;
; Style notes:
; all methods are assumed to have null values as defaults for parameters
; any methods that need non-null default parameters are inside (declare) blocks, where the non-null defaults are explicitly defined
; "methods" should be #lower_case_snake_case in howso.amlg, #UpperCaseCamelCase in trainee_template
; 			internal helper methods should be private, #!snake_case in howso.amlg or #!UpperCaseCamelCase in trainee_template.amlg
; "attributes" of the model should be lowerCaseCamelCase
; parameters and "local variables" should be lower_case_snake_case
; parameters/variables and attributes that are sets or assocs should end with "_map" or "Map" respectively for readability (or _set and Set)

;performs the training and management of trainees
(null

	;concatenated version
	#version (get (load (concat filepath "version.json")) "version")
	#major_version 0
	#minor_version 0
	#point_version 0

	;returns version stored in trainee
	#get_trainee_version
		(concat
			(retrieve_from_entity trainee "majorVersion") "."
			(retrieve_from_entity trainee "minorVersion") "."
			(retrieve_from_entity trainee "pointVersion")
		)


	;creates a new instance of a trainee as specified by the entity label "trainee"
	;parameters:
	;	filepath: path to the file (optional)
	#create_trainee
		(seq
			(declare (assoc
				result (load_entity (concat filepath !trainee_template_filename "." !file_extension) trainee (false) (false))
			))

			(if (!= (null) result)
				(call_entity trainee "Initialize")
			)

			(if debug_print
				(call !parse_debug_print)
			)

			(if result
				(call !return (assoc payload (assoc "name" result) ))

				(call !return (assoc errors (list "Failed to create trainee: ensure a valid filepath.")))
			)
		)


	;return the list of loaded trainees
	#get_loaded_trainees
		(call !return (assoc
			payload
				(filter
					(lambda (!= !breeder_manifest (current_value)))
					(contained_entities)
				)
		))


	;Attempts to load a trainee with the following optional parameters.
	;If a parameter is not specified, it will look to this entity's own label of the same name.
	;If the saved instance does not exist the existing trainee will remain unmodified and the function will return null.
	;assumes loaded trainee filenames need to be escaped
	;returns the trainee name if successful, null if not
	;
	;parameters:
	; filepath: base path to load from
	; filename: name to load (without extension)
	; trainee: name to refer to this instance by
	; separate_files: flag, default to false. if set to true will load each case from its individual file
	#load
		(seq
			(declare (assoc
				loaded_trainee
					(if (and separate_files (= "amlg" !file_extension))
						(let (assoc temptrainee "_temptrainee")
							;attempt to load the entity to a temporary label
							(load_entity (concat filepath filename "." !file_extension) temptrainee (true))
							;if the trainee was loaded
							(if (contains_entity temptrainee)
								(seq
									;destroy the previously existing trainee
									(destroy_entities trainee)
									;move the trainee under the temporary label to the trainee label;
									(move_entities temptrainee trainee)
									;return the name of the trainee to indicate a successful load attempt
									trainee
								)
								;else return null
								(null)
							)
						)

						;else load one flattened entity trainee and parse it out by 'call'ing its code to create all the contained entities
						(let
							(assoc temptrainee (call (load (concat filepath filename "." !file_extension))) )

							(if (and (!= (null) temptrainee) (contains_entity temptrainee))
								(seq
									;destroy the previously existing trainee
									(destroy_entities trainee)

									;move the trainee under the temporary label to the trainee label;
									(move_entities temptrainee trainee)

									;return the name of the trainee to indicate a successful load attempt
									trainee
								)
								;else return null
								(null)
							)
						)
					)
			))

			(if loaded_trainee
				(call !return (assoc payload (assoc "name" loaded_trainee) ))

				(call !return (assoc errors (list (concat "Failed to load trainee " filename))  ))
			)
		)


	;Saves a trainee with the following optional parameters.  If a parameter is not specified, it will look to this entity's own label of the same name.
	;escapes trainee filenames on save
	; filepath: base path to store to
	; filename: name to store (without extension)
	; trainee: trainee instance name to store
	; separate_files: flag, default to false. if set to true will save each case as an individual file
	;returns true on success, false on failure
	#save
		(let
			(assoc
				success
					(if (and separate_files (= "amlg" !file_extension))
						(store_entity (concat filepath filename "." !file_extension) trainee (true))

						(store (concat filepath filename "." !file_extension) (flatten_entity trainee (false)) )
					)
			)

			(declare (assoc
				trainee_version
					(concat
						(retrieve_from_entity trainee "majorVersion") "."
						(retrieve_from_entity trainee "minorVersion") "."
						(retrieve_from_entity trainee "pointVersion")
					)
				amlg_version (system "version")
			))

			(if success
				(seq
					;outputs a txt file along the saved trainee containing trainee and amalgam versions
					(store
						(concat filepath filename "Version.txt")
						(concat "trainee:" trainee_version "\namalgam:" amlg_version)
					)
					(call !return)
				)

				(call !return (assoc errors (list (concat "Failed to save trainee as " filename)) ))
			)
		)


	;Destroyes the instance of the trainee specified by the parameter "trainee".  If trainee is not specified, it will look to this entity's own label of the same name.
	#delete
		(seq
			(destroy_entities trainee)
			(call !return)
		)


	;creates a copy of a trainee and returns the name of the copied trainee on success, 0 on fail (if target_trainee already exists)
	;parameters:
	; trainee: trainee instance to copy
	; target_trainee: trainee name of copy
	#copy
		(if (not (contains_entity target_trainee))
			(call !return (assoc
				payload (assoc "name" (first (clone_entities trainee target_trainee)) )
			))

			;else error
			(call !return (assoc errors (list (concat "Failed to copy: " target_trainee " trainee already exists.")) ))
		)


	;Cleans up trainee data, removing unused sessions, cases or actions missing data, etc. given the following optional parameters.  If a parameter is not specified, it will look to this entity's own label of the same name.  See label for parameter details.
	;parameters:
	; trainee: trainee instance
	; context_features: list of context features
	; action_features: list of action features
	; remove_duplicates: optional flag, if set to true will remove duplicate cases (cases with identical values)
	#clean_data
		(seq
			;removes entities that aren't cases or sessions
			(call_entity trainee "RemoveIrrelevantEntities")

			;removes any cases that don't have both the specified context and action features
			(call_entity trainee "RemoveIncompleteCases" (assoc context_features context_features action_features action_features))

			;removes any replay steps that are non-existent cases
			(call_entity trainee "RemoveInvalidReplaySteps")

			;removes duplicate (identical) cases
			(if remove_duplicates
				(call_entity trainee "MergeDuplicateCases" (assoc features (append context_features action_features)))
			)

			;removes cases with null or invalid sessions
			(call_entity trainee "RemoveCasesWithoutSessionReferences")

			;removes empty sessions
			(call_entity trainee "RemoveUnreferencedSessions")

			(accum_to_entities trainee (assoc revision 1))

			;return true that completed
			(call !return)
		)


	;returns a list of all of the training sessions for trainee, assoc of id->session, and whatever other attributes specified.
	;
	;parameters:
	; attributes: optional list of metadata attributes to return from the session.
	#get_sessions
		(call !return (assoc
			payload (call_entity trainee "GetSessions" (assoc attributes attributes))
		))


	;returns all the metadata for a specified session
	#get_session_metadata
		 (if (not (contains_entity (list trainee session)))
		 	(call !return (assoc errors (list (concat "Session " session " does not exist for trainee " trainee "."))))

			(call !return (assoc
				payload (retrieve_from_entity (list trainee session) ".metadata")
			))
		 )


	;set session metadata for a specified session.
	;
	;parameters:
	; session: id of session to modify.
	; metadata: any arbitrary metadata.
	#set_session_metadata
		(seq
		 	(call_entity trainee "SetSessionMetadata" (assoc
				session session
				metadata metadata
			 ))
			(call !return)
		)


	;return list of all session indices for a specified session.
	;session indeces are 0-based index of number of the case for the session used for replays; may change if cases are removed
	;parameters:
	; session : id of session
	#get_session_indices
		(call !return (assoc
			payload (call_entity trainee "GetSessionIndices" (assoc session session))
		))


	;return list of all session training indices for a specified session.
	;session training indices are 0-based index of the case, ordered by training during the session; is not changed
	;parameters:
	; session : id of session
	#get_session_training_indices
		(call !return (assoc
			payload (call_entity trainee "GetSessionTrainingIndices" (assoc session session))
		))


	;removes replay specified by session and any supporting data
	;
	; parameters:
	; trainee: trainee from which to remove the session
	; session: session to remove
	#remove_session
		(seq
			(call_entity trainee "RemoveReplaySession" (assoc session session))
			(call !return)
		)


	;removes the specified feature on all cases for a trainee that match the specified condition
	;if conditions are not specified, removes feature for all cases and from the model, if condition is an empty assoc, leaves the feature metadata in the model.
	;
	;parameters:
	; feature: name of feature to remove
	; condition: assoc of feature->value(s).
	;	  no value = must have feature
	;	- for continuous or numeric ordinal features:
	;	  one value = must equal exactly the value or be close to it for fuzzy match
	;	  values = inclusive between
	;	- for nominal or string ordinal features:
	;	  n values = must match any of these values exactly
	; session: the session id when this call is being made, used for auditing.
	; condition_session: optional, if specified, ignores condition and instead operates on all cases that were trained with this session id.
	#remove_feature
		(declare
			(assoc
				condition (null)
				feature ""
				session "none"
			)

			(call_entity trainee "RemoveFeature" (assoc
				condition condition
				feature feature
				session session
				condition_session condition_session
			))

			(call !return)
		)


	;Adds the specified feature on all cases for a trainee that match the specified condition. overwrites features that
	;If condition are not specified, adds feature for all cases and to the model.  If condition is an empty assoc, will not modify feature metadata in the model.
	;If feature attributes are passed in, will also set the model's featurue attributes.
	;
	;parameters:
	; feature: name of feature to odd
	; feature_value: optional value for the feature
	; ovewrite: flag, whether to overwrite values for features that already exist
	; condition: assoc of feature->value(s).
	;	  no value = must have feature
	;	- for continuous or numeric ordinal features:
	;	  one value = must equal exactly the value or be close to it for fuzzy match
	;	  values = inclusive between
	;	- for nominal or string ordinal features:
	;	  n values = must match any of these values exactly
	; session: the session id when this call is being made, used for auditing.
	; condition_session: optional, if specified, ignores condition and instead operates on all cases that were trained with this session id.
	; feature_attributes: optional, dict of feature specific attributes for this feature. If unspecified and conditions are not specified, will assume feature type as 'continuous'.
	#add_feature
		(declare
			(assoc
				feature ""
				condition (null)
				overwrite 1
				session "none"
				feature_attributes (null)
			)

			(declare (assoc
				output
					(call_entity trainee "AddFeature" (assoc
						feature feature
						feature_value feature_value
						condition condition
						overwrite overwrite
						session session
						condition_session condition_session
						feature_attributes feature_attributes
					))
			))

			(if (= (true) output)
				(call !return)

				(call !return (assoc errors (list output)  ))
			)
		)


	;returns the total number of training cases for trainee -- if data is properly cleaned up, should be the same for contexts and actions
	#get_num_training_cases
		(call !return (assoc
			payload (assoc "count" (call_entity trainee "GetNumTrainingCases") )
		))


	;Edit feature values for the specified cases.
	;Cases are specified by either case_indices or by the condition. If neither is provided, edits all cases.
	;returns assoc with "count"
	;
	;parameters:
	; features: list of names of feature to edit
	; feature_values: list of values corresponding to features
	; case_indices: optional, list of pair (list) of session id and index, where index is the original 0-based session_training_index of the case as
	; 		it was trained. If specified, ignores condition and condition_session
	; condition_session: optional, if specified ignores condition and operates on cases for the specified session id
	; condition: assoc of feature->value(s)
	;		no value = must have feature
	;   	- for continuous or numeric ordinal features:
	;			one value = must equal exactly the value or be close to it for fuzzy match
	;			two values = inclusive between
	;   	- for nominal or string ordinal features:
	;			n values = must match any of these values exactly
	; num_cases: optional, limit on the number of cases to edit; If set to zero there will be no limit.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	; precision: optional string,  default is 'exact', used only with 'condition' parameter, will find exact matches if 'exact' and similar cases if 'similar'.
	; session: the session id when this call is being made
	#edit_cases
		(declare
			(assoc
				features (list)
				feature_values (list)
				case_indices (list)
				condition (assoc)
				condition_session (null)
				num_cases (null)
				precision "exact"
				session "none"
			)

			(declare (assoc
				output
					(call_entity trainee "EditCases" (assoc
						features features
						feature_values feature_values
						case_indices case_indices
						condition condition
						condition_session condition_session
						num_cases num_cases
						precision precision
						session session
					))
			))

			(if output
				(call !return (assoc payload output))

				(call !return (assoc errors (list "Failed to edit cases: ensure features do not start with an invalid character.")  ))
			)
		)


	; set the conviction threshold to (null), used by outside interfaces
	#clear_conviction_thresholds
		(seq
			(assign_to_entities trainee (assoc convictionLowerThreshold (null) convictionUpperThreshold (null)))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;set the thresholds on the trainee
	; parameters:
	; conviction_lower_threshold : optional lower bond, cases below this won't be trained on
	; conviction_upper_threshold : optional upper bound, cases above this won't be trained on
	#set_conviction_lower_threshold
		(seq
			(assign_to_entities trainee (assoc convictionLowerThreshold conviction_lower_threshold))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	#set_conviction_upper_threshold
		(seq
			(assign_to_entities trainee (assoc convictionUpperThreshold conviction_upper_threshold))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;set metadata for model
	; parameters:
	; metadata: arbitary metadata to store in a trainee
	#set_metadata
		(seq
			(assign_to_entities trainee (assoc metaData metadata))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;get metadata for model
	#get_metadata
		(call !return (assoc payload (retrieve_from_entity trainee "metaData") ))


	;retrieve the top or bottom number of cases for a specified feature, sorted top to bottom for top, and bottom to top for bottom
	;parameters:
	; sort_feature: the feature for which to sort the cases by
	; num: number of cases to return, positive value will return the top (largest value), negative will return smallest
	; features : the features for which values should be returned
	#retrieve_extreme_cases_for_feature
		(call !return (assoc
			payload
				(call_entity trainee "RetrieveExtremeCasesForFeature" (assoc
					sort_feature sort_feature
					num num
					features features
				))
		))


	;Train the passed in cases, filtering out cases that match optionally passed in ablation parameters
	; returns a response object in the following format:
	;	(associate
	;		"success" (true)/(false)
	;		"num_trained" num_trained_cases
	;		"ablated_indices" (list of ablated case indices)
	;		"status" "status output message"
	;		"message" "if failed to succeed, the error/reason message will be here"
	;	)
	; 	list of 'status' values:
	;		(null) - default output, no status output
	;		"analyze" - if auto analysis is enabled and the model has grown large enough to be analyzed again
	;
	; parameters:
	; input_cases : list of cases, ie a list of lists of values.
	; features : the list of features.
	; derived_features: optional list of features to derive in the specified order. If this list is not provided, features with
	;	   the 'auto_derive_on_train' feature attribute set to True will be auto-derived. If provided an empty list, will not derive any features.
	;	   Any derived_features that are already in the 'features' list will not be derived since their values are being explicitly provided.
	; session: the session label to record these cases to.  If not specified, refers to this entity's label of same name.
	; trainee : the trainee model.
	; input_is_substituted : flag, if set to true assumes provided categorical (nominal or ordinal) feature values already been substituted.
	; ablatement_params: assoc of feature -> threshold_type
	; 	threshold_type is one of:
	;		['exact'] - don't train if prediction matches exactly
	;		['tolerance', MIN, MAX] - don't train if prediction >= (case value - MIN) and prediction <= (case value + MAX)
	;		['relative', PERCENT] - don't train if abs(prediction - case value) / prediction <= PERCENT
	;		['residual'] - don't train if if abs(prediction - case value) <= feature residual
	; series: optional, name of series to pull features and case values from internal series storage.  If specified, trains on all cases that are
	;		stored in the internal series store for the specified series and session. The trained feature set is the combined features from storage
	;		and the passed in features.  If input_cases is of length one, the value(s) of this case are appended to all cases in the series.
	;		If input_cases is the same length as the series, the value of each case in input_cases is applied in order to each of the cases in the
	;		series.
	; accumulate_weight_feature: name of feature into which to accumulate neighbors' influences as weight for ablated cases. If unspecified, will not accumulate weights.
	; train_weights_only: flag, if set to true, and accumulate_weight_feature is provided, will not train on the cases, but instead accumulate all of their neighbor weights.
	#train
		(declare
			(assoc
				input_cases (list)
				features (list)
				input_is_substituted (false)
				derived_features (null)
				accumulate_weight_feature (null)
				train_weights_only (false)
			)

			(if (contains_entity trainee)
				(let
					(assoc
						train_response
							(call_entity trainee "Train" (assoc
								input_cases input_cases
								features features
								derived_features derived_features
								session session
								ablatement_params ablatement_params
								series series
								input_is_substituted input_is_substituted
								accumulate_weight_feature accumulate_weight_feature
								train_weights_only train_weights_only
							))
					)

					(if (contains_index train_response "error")
						(call !return (assoc
							errors (list (get train_response "error"))
							payload (remove train_response "error")
						))

						; else no error, just return the response in the payload
						(call !return (assoc payload train_response))
					)
				)

				;return that it didn't work -- no trainee
				(call !return (assoc
					errors (list (concat "Failed to train: trainee " trainee " does not exist.") )
					payload
						(assoc
							"num_trained" 0
							"ablated_indices" (list)
							"status" (null)
						)
				))
			)
		)


	;sets the model to auto-analyze by tracking its size and notifying the clients in train responses when it should be analyzed
	;parameters:
	; auto_analyze_enabled: flag, default is false. when true, returns when it's time for model to be analyzed again.
	; analyze_threshold: optional, stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
	; analyze_growth_factor: the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
	;						default of two orders of magnitude using the universal scaling factor e
	; auto_analyze_limit_size: the size of of the model at which to stop doing auto-analysis. Value of 0 means no limit.
	;
	; optionally, if parameters that are specified for analyze are passed in, they will be stored and used during auto-analysis
	#set_auto_analyze_params
		(declare
			(assoc
				auto_analyze_enabled (false)
				analyze_threshold 100
				analyze_growth_factor 7.389056
				auto_analyze_limit_size 200000
			)

			(call_entity trainee "SetAutoAnalyzeParams" (assoc
				auto_analyze_enabled auto_analyze_enabled
				analyze_threshold analyze_threshold
				analyze_growth_factor analyze_growth_factor
				auto_analyze_limit_size auto_analyze_limit_size
			))

			(if (!= (null) context_features)
				(assign_to_entities trainee (assoc
					savedAnalyzeParameterMap
						(assoc
							"context_features" context_features
							"action_features" action_features
							"k_folds" k_folds
							"k_folds_by_indices" k_folds_by_indices
							"bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
							"bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
							"bypass_calculate_feature_weights" bypass_calculate_feature_weights
							"use_deviations"  use_deviations
							"num_samples" num_samples
							"k_values" k_values
							"p_values" p_values
							"dt_values" dt_values
							"analyze_level" analyze_level
							"targeted_model" targeted_model
							"num_analysis_samples" num_analysis_samples
							"analysis_sub_model_size" analysis_sub_model_size
							"inverse_residuals_as_weights" inverse_residuals_as_weights
							"weight_feature" weight_feature
							"use_case_weights" use_case_weights
						)
				))
			)

			;return that this has completed
			(call !return)
		)


	;imputes the trained model, filling in all the (null) feature values
	; parameters:
	; features : optional, list of features to use for imputation. if unspecified will use all the features in the dataset
	; features_to_impute : optional, list of features to impute. if unspecified will use features
	; trainee : the trainee model
	; session: the session id for this impute
	; batch_size : a positive integer, specifying how many rows to fill before recomputing conviction. default is 1 which should return the
	;				best accuracy since it'll recompute it everytime.  Higher values should improve performance but may decrease accuracy of results
	#impute
		(declare
			(assoc
				features (list)
				features_to_impute (list)
				batch_size 1
				session "none"
			)

			(if (not (contains_entity trainee))
				(conclude
					(call !return (assoc errors (list (concat "Failed to impute: no trainee " trainee)) ))
				)
			)

			(declare (assoc
				success
					(call_entity trainee "Impute" (assoc
						features features
						features_to_impute features_to_impute
						session session
						batch_size batch_size
					))
			))

			(if success
				(call !return)

				(call !return (assoc errors (list "Failed to impute: nothing to impute.")))
			)
		)


	;clear values that were imputed during a specified session, but won't clear values that were manually set by user after the impute
	;
	;parameters:
	; session: session id of this action
	; impute_session: session id  of the impute for which to clear the data
	#clear_imputed_session
		(seq
			(call_entity trainee "ClearImputedSession" (assoc
				session session
				impute_session impute_session
			))
			(call !return)
		)


	;returns all the ordered cases from the specified session from the specified trainee
	;parameters:
	; features: list of features to retrieve
	; indicate_imputed: if set to 1 will return the audit data of which features for each row were imputed (auto-filled)
	; session: optional session from which to get cases
	; case_indices: optional, list of pair (list) of session id and index, where index is the original 0-based session_training_index of the
	;		case as it was trained. If specified with session, ignores session.
	; condition: optional a query condition describing the cases to return
	; num_cases: optional, limit on the number of cases to retrieve; If set to zero there will be no limit.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	; precision: optional string. default is 'exact', used only with 'condition' parameter, will find exact matches if 'exact' and similar cases if 'similar'.
	#get_cases
		(declare
			(assoc
				features (list)
				indicate_imputed 0
				num_cases (null)
				precision "exact"
			)
			(if indicate_imputed
				(accum (assoc features ".imputed"))
			)

			(call !return (assoc
				payload
					(call_entity trainee "RetrieveAllCases" (assoc
						features features
						case_indices case_indices
						session session
						condition condition
						num_cases num_cases
						precision precision
					))
			))
		)


	;React to a provided context. If desired_conviction is provided, it does a generative react.
	;
	;Output:
	; Default output of this method is a react object in the format of
	; { 'action_values' : [ all_action_values ], 'action_features' : [ all_action_features ] }, where all_action_values is a list of all action
	; values, reacted/generated and derived, in the same order as all_action_features, e.g., [2, "a", .75384] to match ['width','name','height']
	; If details is specified, the react object will contain appropriate additonal explanation properties and values,
	; 	Explanation example: { 'action_values': [2, "a", .75384], 'action_features' : ['width','name','height'], 'residual_conviction': 1.3,
	;		'influential_cases' : etc... }
	;	See API docs for documentation of all output properties
	;
	;Parameters:
	; desired_conviction : default is None, will run a Discriminative react. If specified does Generative-React.
	;					For Generative React, value of desired avg conviction of generated cases, in the range of (0,infinity] with 1 as standard
	;					larger values will increase the variance (or creativity) of the generated case from the existing model
	;					smaller values will decrease the variance (or creativity) of the generated case from the existing model
	; details: if set to an assoc with corresponding flags set, then it will modify the return type and return the requested audit info
	; context_features: list of context features. For generative react, features used to condition the generated case
	; context_values: list of context values, For generative react, values used to condition the generated case
	; action_features: full list of features to output values for the case
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	; use_case_weights: optional, flag, if set to true will scale influence weights by each case's weight_feature weight.
	;				   If a weight is missing, uses 1 as the weight.
	; rand_seed: optional, the random seed to use for the react.
	; derived_context_features: list of context features whose values should be computed from the provided contexts in the specified order.
	;					Must be different than context_features.
	; derived_action_features: list of action features whose values should be computed from the resulting action prior to output, in the specified
	;					order. Must be a subset of action_features.
	;					Note: both of these derived feature lists rely on the features' "derived_feature_code" attribute to compute the values.
	;					If 'derived_feature_code' attribute is undefined or references non-0 feature indices, the derived value will be null.
	; post_process_features: list of feature names that will be made available during the execution of post_process feature attributes
	; post_process_values: list of values corresponding to post_process_features that will be made available during the execution fo post_process feature attributes
	; case_indices: optional pair (list) of session id and index, where index is the original 0-based session_training_index of the case as it was
	;			trained into the session. If this case does not exist, discriminative react outputs null, generative react ignores it.
	; preserve_feature_values : optional, list of features that will preserve their values from the case specified by case_indices, appending and
	;			overwriting the specified context and context features as necessary.  For generative reacts, if case_indices isn't specified,
	;			will preserve feature values of a random case.
	; leave_case_out: flag, if set to true and specified along with case_indices, will set ignore_case to the one specified by case_indices.
	; input_is_substituted : flag, if set to true assumes provided categorical (nominal or ordinal) feature values already been substituted.
	; substitute_output : flag, default is true, only applicable if a substitution value map has been set. If set to false, will not substitute categorical feature values.
	; into_series_store: optional series id, if specified will store an internal record of all reacts for that series
	;
	;Discriminative-React-specific Parameters:
	; action_values: values of action features. If specified will bypass react and only do the explanation if details is set
	; extra_audit_features: list of additional features to return with audit data
	; ignore_case: case_id, if set will query for K+1 cases and ignore the perfect matching case during the reaction
	; allow_nulls : flag, if set to true will allow return of null values if there are nulls in the local model for the action features. Applicable
	;			only to discriminative reacts.
	;
	;Generative-React-specific Parameters:
	; use_regional_model_residuals: flag, if false uses model feature residuals, if true recalculates regional model residuals. Default is true.
	; feature_bounds_map: optional assoc of :
	;				{ feature : { "min": a, "max": b, "allow_null": false/true } }
	;				to ensure that specified features' generated values stay in bounds
	;				for nominal features instead of min/max it's a set of allowed values, ie:
	;				{ feature: { "allowed" : [ "value1", "value2" ... ] }, "allow_null": false/true }
	;			   allow_null - default is true, if true nulls may be generated per their distribution in the data
	; generate_new_cases : optional,  acceptable values are:
	;				null or 'no' : output any generated case
	;				'always' : only output original cases, outputs null for all feature values if unable to generate a new case
	;				'attempt' : output any generated case only if generation fails all initial attempts to output original cases
	; exclude_novel_nominals_from_uniqueness_check: optional, default false. If true will exclude sensitive features whose values will be
	;			replaced after synthesis from uniqueness check.
	; ordered_by_specified_features : flag, if true order of generated feature values will match the order of features
	; new_case_threshold : optional, distance to determine privacy cutoff. Used to query the local minimum distance used in the distance ratio
	; 		accepted values:
	; 			'max': the maximum local distance
	; 			'min': the minimum local distance
	; 	    	'most_similar': the closest distance of the most similar case
	; 			null: the minimum local distance
	#react
		(declare
			(assoc
				context_features (list)
				context_values (list)
				action_features (list)
				action_values (list)
				derived_action_features (list)
				derived_context_features (list)
				post_process_features (list)
				post_process_values (list)
				extra_audit_features (list)
				use_case_weights (false)
				weight_feature ".case_weight"
				allow_nulls (false)

				;generate react specific parameters:
				use_regional_model_residuals (true)
				feature_bounds_map (assoc)
				preserve_feature_values (list)
				substitute_output (true)
				input_is_substituted (false)
				new_case_threshold "min"
			)

			;if both action_features and derived_action_features are specified,
			;ensure that derived_action_features are a subset of action_features, then separate the two into distinct lists
			#!ValidateDerivedActionFeaturesIsSubset
			(if (and (size action_features) (size derived_action_features))
				;if derived_action_features isn't a subset of action_features, error out
				(if (> (size (remove (zip derived_action_features) action_features)) 0)
					(conclude
						(call !return (assoc errors (list "Specified 'derived_action_features' must be a subset of 'action_features'.") ))
					)

					;else separate  derived_action_features from action_features
					(assign (assoc
						action_features (filter (lambda (not (contains_value derived_action_features (current_value)))) action_features)
					))
				)
			)

			(call !return
				(call_entity trainee "SingleReact" (assoc
					context_features context_features
					context_values context_values
					action_features action_features
					action_values action_values
					derived_action_features derived_action_features
					derived_context_features derived_context_features
					post_process_features post_process_features
					post_process_values post_process_values
					details details
					extra_audit_features extra_audit_features
					ignore_case ignore_case
					case_indices case_indices
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed
					leave_case_out leave_case_out
					allow_nulls allow_nulls

					desired_conviction desired_conviction
					use_regional_model_residuals use_regional_model_residuals
					feature_bounds_map feature_bounds_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases generate_new_cases
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
					into_series_store into_series_store
				))
			)
		)


	;Run reacts in a batch
	; output an assoc react key -> list of corresponding values from each individual react.
	; example output for 2 reacts:
	; (assoc
	; 	"action_values" (list (list 1 2) (list 3 4))
	;	"action_features" (list "foo" "bar")
	;	"context_values" (list (list 4 5 6) (list 3 3 3))
	;	"distance_contribution" (list 4.5 3.2)
	; )
	;parameters:  same as #react, unless listed here
	;  context_values - list of lists.  see #react for description.
	;  action_values - list of lists.  see #react for description.
	;  post_process_values - list of lists. see #react for description
	;  case_indices - list of lists.  see #react for description.
	;  rand_seed - optional, see #react for description.
	;  num_cases_to_generate - optional, total number of cases to generate for generative reacts.
	#batch_react
		(declare
			(assoc
				;default values for reacts
				context_features (list)
				action_features (list)
				derived_context_features (list)
				derived_action_features (list)
				post_process_features (list)
				extra_audit_features (list)
				use_case_weights (false)
				weight_feature ".case_weight"
				allow_nulls (false)

				;generate react specific parameters:
				use_regional_model_residuals (true)
				feature_bounds_map (assoc)
				preserve_feature_values (list)
				substitute_output (true)
				input_is_substituted (false)
				new_case_threshold "min"
			)

			;determine number of reacts to batch
			(declare (assoc
				num_reacts
					(max
						1
						(if (!= (null) desired_conviction)
							num_cases_to_generate

							(!= (null) context_values)
							(size context_values)

							(!= (null) case_indices)
							(size case_indices)
						)
					)
			))

			;validate parameters
			(declare (assoc invalid_react_parameters (false)))

			(call !validate_batch_react_parameter (assoc param context_values))
			(call !validate_batch_react_parameter (assoc param case_indices))
			(call !validate_batch_react_parameter (assoc param action_values))
			(call !validate_batch_react_parameter (assoc param post_process_values))

			(if (and
					(!= (null) rand_seed)
					(!= num_reacts (size rand_seed))
				)
				(assign (assoc invalid_react_parameters (true)))
			)

			(if invalid_react_parameters
				(conclude
					(call !return (assoc errors (list "Failed to react: invalid react parameters.") ))
				)
			)

			(call !ValidateDerivedActionFeaturesIsSubset)

			(call !return
				(call_entity trainee "BatchReact" (assoc
					context_features context_features
					context_values context_values
					action_features action_features
					action_values action_values
					derived_action_features derived_action_features
					derived_context_features derived_context_features
					post_process_features post_process_features
					post_process_values post_process_values
					details details
					extra_audit_features extra_audit_features
					ignore_case ignore_case
					case_indices case_indices
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed
					leave_case_out leave_case_out
					num_reacts num_reacts
					allow_nulls allow_nulls

					desired_conviction desired_conviction
					use_regional_model_residuals use_regional_model_residuals
					feature_bounds_map feature_bounds_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases generate_new_cases
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
					into_series_store into_series_store
				))
			)
		)


	;React in a series until a series_stop_map condition is met. Aggregates rows of data corresponding to the specified context, action,
	;derived_context and derived_action features, utilizing previous rows to derive values as necessary. Outputs an assoc of "action_features" and
	;corresponding "series" where "series" is the completed 'matrix' for the corresponding action_features and derived_action_features.
	;
	;parameters: same as #react, except no 'into_series_store' parameter, react_series - specific parameters are listed here:
	; initial_features : optional list of features to condition just the first case in a series, overwrites context_features and
	;		derived_context_features for that first case. All specified initial features must be in one of: context_features, action_features,
	;		derived_context_features or derived_action_features. If provided a value that isn't in one of those lists, it will be ignored.
	; initial_values : optional list of values corresponding to the initial_features, used to condition just the first case in a series.
	; series_stop_map: assoc of feature -> stop conditions:
	;		for continuous features:  { feature:  { "min" : val,  "max": val } } - stops series when feature value exceeds max or is smaller than min
	;		for nominal features:  { feature:  { "values" : ['val1', 'val2' ]} }  - stops series when feature value matches any of the values listed
	;       specifying ".series_progress" with a value between 0 and 1.0 corresponding to percent completion e.g., { ".series_progress" : .95 } -
	;			stops series when it progresses at or beyond 95%.
	; max_series_length: optional, maximum size a series is allowed to be.  Default is 3 * model_size, a 0 or less is no limit.
	; derived_context_features: list of context features whose values should be computed from the entire series in the specified order.
	;		Must be different than context_features.
	; derived_action_features: list of action features whose values should be computed from the resulting last row in series, in the specified
	;		order. Must be a subset of action_features.
	;		Note: both of these derived feature lists rely on the features' "derived_feature_code" attribute to compute the values.
	;		If 'derived_feature_code' attribute is undefined or references non-existing feature indices, the derived value will be null.
	; output_new_series_ids: optional flag, default to True. If true, series ids are replaced with unique values on output.
	;		If False, will maintain or replace ids with existing trained values, but also allows output of series with duplicate existing ids. 
	; series_id_tracking : optional string, default "fixed".  Controls how closely generated series should follow existing series (plural).
	;		Choices are: "fixed", "dynamic" or "no". If "fixed", tracks the particular relevant series ID. If "dynamic", tracks the particular
	;		relevant series ID, but is allowed to change the series ID that it tracks based on its current context. If "no", does not track any particular series ID.
	; series_context_values: optional, 2d-list of values, context value for each feature for each row of the series.
	;		If specified, max_series_length is ignored.
	; series_context_features: optional, features corresponding to series_context_values
	; init_time_steps: optional, list of time step values at which to begin synthesis, applicable only for time series
	; final_time_steps:  optional, list time step values at which to end synthesis, applicable only for time series
	; continue_series: optional, flag. Default is false.  When true will attempt to continue existing series instead of starting new series.
	;		If initial_values provide series IDs, it will continue those explicitly specified IDs, otherwise it will randomly select series to continue.
	;		Note: terminated series with terminators cannot be continued and will result in null output.
	; continue_series_values: optional, list of lists of values, when specified will continue this specific untrained series as defined by these values.
	; 		continue_series flag will be ignored and treated as true if this value is specified.
	; continue_series_features: optional, list of features corresponding to the values in each row of continue_series_values.
	; 		This value is ignored if continue_series_values is not specified.
	#react_series
		(declare
			(assoc
				initial_features (list)
				initial_values (list)
				series_stop_map (assoc)
				output_new_series_ids (true)
				series_id_tracking "fixed"
				continue_series (false)
				continue_series_features (null)
				continue_series_values (null)

				context_features (list)
				context_values (list)
				action_features (list)
				action_values (list)
				derived_action_features (list)
				derived_context_features (list)
				series_context_features (list)
				series_context_values (list)
				extra_audit_features (list)
				use_case_weights (false)
				weight_feature ".case_weight"

				;generate react specific parameters:
				use_regional_model_residuals (true)
				feature_bounds_map (assoc)
				preserve_feature_values (list)
				new_case_threshold "min"
				substitute_output (true)
				input_is_substituted (false)
			)

			(declare (assoc invalid_react_parameters (null)))

			(if series_stop_map
				(assign (assoc
					invalid_react_parameters
						(call_entity trainee "ValidateSeriesStopMaps" (assoc
							series_stop_maps (list series_stop_map)
							feature_bounds_map feature_bounds_map
						))
				))
			)

			(if invalid_react_parameters
				(conclude
					(call !return (assoc
						errors (list (concat "Failed to react_series: invalid stopping condition specified for " invalid_react_parameters) )
					))
				)
			)

			;Don't allow duplicates/overlap of context features by checking if all the context features appended
			;together are more than just the uniques between them
			(if (>
					(size (append initial_features context_features series_context_features))
					(size (values (append initial_features context_features series_context_features) (true) ))
				)
				(conclude
					(call !return (assoc
						errors (list "There must not be overlap between features specified in initial_features, context_features, and/or series_context_features.")
					))
				)
			)

			(declare (assoc
				time_series_prep_map
					;prep time series parameters if it's a time series model
					(if (retrieve_from_entity trainee "tsTimeFeature")
						(call_entity trainee "PrepTimeSeriesFeatures" (assoc
							init_time_steps init_time_steps
							final_time_steps final_time_steps
							;wrap initial_values and series_stop_maps in lists since that's the format PrepTimeSeriesFeatures expects
							initial_values (if (size initial_values) (list initial_values) (list) )
							series_stop_maps (if (size series_stop_map) (list series_stop_map) )
							continue_series_values (if (size continue_series_values) (list continue_series_values) )
							continue_series_features continue_series_features
							;singular series
							n_samples 1
							context_features context_features
							series_context_features series_context_features
							initial_features initial_features
							derived_context_features derived_context_features
							derived_action_features derived_action_features
							single_series (true)
							output_new_series_ids output_new_series_ids
							series_id_tracking series_id_tracking
						))
					)
				output_features action_features
			))

			(call !ValidateDerivedActionFeaturesIsSubset)

			;if the preparation output is an assoc of variables, overwrite local parameters with these resulting values
			(if (= (assoc) (get_type time_series_prep_map))
				(assign time_series_prep_map)

				;if it's a string, return it as an error
				(= "" (get_type time_series_prep_map))
				(conclude (call !return (assoc errors (list time_series_prep_map))) )
			)

			;if user passed in a series for continuing, create a temporary trainee to derive all the necessary values (lags, deltas, etc.)
			;and then overwrite the passed continue_series_values with the additonal derived feature values
			(if (size continue_series_values)
				(seq
					(if (= 0 (size continue_series_features))
						(conclude (conclude
							(call !return (assoc
								errors (list "continue_series_values is provided without continue_series_features, please specify continue_series_features")
							))
						))
					)

					(declare (assoc trainee_clone (first (create_entities (null))) ))

					;create a shollow copy (no contained entities, just the trainee data)
					(assign_entity_roots trainee_clone (retrieve_entity_root trainee) )

					;train and derive all the lags and other features as necessary
					(call_entity trainee_clone "Train" (assoc
						input_cases continue_series_values
						features continue_series_features
						session "temp"
						input_is_substituted input_is_substituted
					))

					;include imputed features at the end
					(assign (assoc
						continue_series_features
							(append (retrieve_from_entity trainee_clone "defaultFeatures") (retrieve_from_entity trainee_clone "internalLabelImputed"))
					))

					(assign (assoc
						;explicitly set the continue_series flag to true since values are provided
						continue_series (true)
						continue_series_values
							(get
								(call_entity trainee_clone "RetrieveAllCases" (assoc
									features continue_series_features
									session "temp"
								))
								"cases"
							)
					))

					(declare (assoc
						time_feature_index
							(get
								(zip continue_series_features (indices continue_series_features))
								(retrieve_from_entity trainee "tsTimeFeature")
							)
					))

					;sort the passed in data by the time feature to ensure its order
					(assign (assoc
						continue_series_values
							(call_entity trainee_clone "MultiSortList" (assoc
								data continue_series_values
								column_order_indices (list time_feature_index)
							))
					))

					(destroy_entities trainee_clone)
				)
			)

			(call !return
				(call_entity trainee "ReactSeries" (assoc
					initial_features initial_features
					initial_values initial_values
					series_stop_map series_stop_maps
					max_series_length max_series_length
					output_new_series_ids output_new_series_ids
					output_features output_features
					continue_series continue_series
					continue_series_features continue_series_features
					continue_series_values continue_series_values

					context_features context_features
					context_values context_values
					action_features action_features
					action_values action_values
					derived_action_features derived_action_features
					derived_context_features derived_context_features
					series_context_features series_context_features
					series_context_values series_context_values
					details details
					extra_audit_features extra_audit_features
					ignore_case ignore_case
					case_indices case_indices
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed
					leave_case_out leave_case_out

					desired_conviction desired_conviction
					use_regional_model_residuals use_regional_model_residuals
					feature_bounds_map feature_bounds_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases generate_new_cases
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
				))
			)
		)


	;Run react_series in a batch, output a list of outputs from each individual react_series.
	;
	;parameters:  same as #react_series, unless listed here
	; rand_seed - optional, see #react for description.
	; series_context_values: optional, 3d-list of values, context value for each feature for each row of a series.
	;		If specified max_series_lengths are ignored.
	; init_time_steps: optional, time step value at which to begin synthesis, applicable only for time series.
	; final_time_steps: optional, time step value at which to end synthesis, applicable only for time series.
	; num_series_to_generate: optional, total number of series to generate, for generative reacts.
	;
	;	 All of the following parameters, if specified, must be either length of 1 or equal to the length of
	;	context_values/case_indices for discriminative reacts, and num_series_to_generate for generative reacts.
	;
	; initial_values - list of lists. see #react_series for description.
	; series_stop_maps - list of assocs. see #react_series for description.
	; max_series_lengths - list of values. see #react_series for description.
	; action_values - list of lists.  see #react for description.
	; continue_series_values - list of lists. see #react_series for description.
	#batch_react_series
		(declare
			(assoc
				initial_features (list)
				initial_values (list)
				series_stop_maps (list)
				max_series_lengths (null)
				output_new_series_ids (true)
				series_id_tracking "fixed"
				continue_series (false)
				continue_series_features (null)
				continue_series_values (null)

				context_features (list)
				action_features (list)
				derived_context_features (list)
				derived_action_features (list)
				series_context_features (list)
				series_context_values (list)
				extra_audit_features (list)
				use_case_weights (false)
				weight_feature ".case_weight"

				;generate react specific parameters:
				use_regional_model_residuals (true)
				feature_bounds_map (assoc)
				preserve_feature_values (list)
				new_case_threshold "min"
				substitute_output (true)
				input_is_substituted (false)
			)

			;determine number of reacts to batch
			(declare (assoc
				num_reacts
					(max
						1
						(if (!= (null) desired_conviction)
							num_series_to_generate

							(!= (null) context_values)
							(size context_values)

							(!= (null) case_indices)
							(size case_indices)

							(!= (list) initial_values)
							(size initial_values)

							(!= (null) continue_series_values)
							(size continue_series_values)
						)
					)
			))

			;validate parameters
			(declare (assoc invalid_react_parameters (false) ))

			(call !validate_batch_react_parameter (assoc param context_values))
			(call !validate_batch_react_parameter (assoc param case_indices))
			(call !validate_batch_react_parameter (assoc param action_values))

			(call !validate_batch_react_parameter (assoc param initial_values))
			(call !validate_batch_react_parameter (assoc param series_stop_maps))
			(call !validate_batch_react_parameter (assoc param max_series_lengths))

			(if (and
					(!= (null) rand_seed)
					(!= num_reacts (size rand_seed))
				)
				(assign (assoc invalid_react_parameters (true)))
			)

			(if invalid_react_parameters
				(conclude
					(call !return (assoc errors (list "Failed to react_series: invalid react parameters.") ))
				)
			)

			(if series_stop_maps
				(assign (assoc
					invalid_react_parameters
						(call_entity trainee "ValidateSeriesStopMaps" (assoc
							series_stop_maps series_stop_maps
							feature_bounds_map feature_bounds_map
						))
				))
			)

			(if invalid_react_parameters
				(conclude
					(call !return (assoc
						errors (list (concat "Failed to react_series: invalid stopping condition specified for " invalid_react_parameters) )
					))
				)
			)

			;Don't allow duplicates/overlap of context features by checking if all the context features appended
			;together are more than just the uniques between them
			(if (>
					(size (append initial_features context_features series_context_features))
					(size (values (append initial_features context_features series_context_features) (true) ))
				)
				(conclude
					(call !return (assoc
						errors (list "There must not be overlap between features specified in initial_features, context_features, and/or series_context_features.")
					))
				)
			)

			(declare (assoc
				time_series_prep_map
					;prep time series parameters if it's a time series model
					(if (retrieve_from_entity trainee "tsTimeFeature")
						(call_entity trainee "PrepTimeSeriesFeatures" (assoc
							init_time_steps init_time_steps
							final_time_steps final_time_steps
							n_samples num_reacts
							context_features context_features
							series_context_features series_context_features
							initial_features initial_features
							initial_values initial_values
							series_stop_maps series_stop_maps
							derived_context_features derived_context_features
							derived_action_features derived_action_features
							output_new_series_ids output_new_series_ids
							series_id_tracking series_id_tracking
							continue_series_features continue_series_features
							continue_series_values (if (size continue_series_values) continue_series_values)
						))
					)
				output_features action_features
			))

			(call !ValidateDerivedActionFeaturesIsSubset)

			;if the preparation output is an assoc of variables, overwrite local parameters with these resulting values
			(if (= (assoc) (get_type time_series_prep_map))
				(assign time_series_prep_map)

				;if it's a string, return it as an error
				(= "" (get_type time_series_prep_map))
				(conclude (call !return (assoc errors (list time_series_prep_map))) )
			)

			;if user passed in a series for continuing, create a temporary trainee to derive all the necessary values (lags, deltas, etc.)
			;and then overwrite the passed continue_series_values with the additonal derived feature values
			(if (size continue_series_values)
				(let
					(assoc
						original_continue_series_features continue_series_features
						imputed_list_feature (retrieve_from_entity trainee "internalLabelImputed")
						time_feature_index 0
						time_feature (retrieve_from_entity trainee "tsTimeFeature")
					)

					(if (= 0 (size continue_series_features))
						(conclude (conclude
							(call !return (assoc
								errors (list "continue_series_values is provided without continue_series_features, please specify continue_series_features")
							))
						))
					)

					(assign (assoc
						;explicitly set the continue_series flag to true since values are provided
						continue_series (true)
						continue_series_values
							(map
								(lambda (let
									(assoc continue_values (current_value 1) )
									(declare (assoc trainee_clone (first (create_entities (null))) ))

									;create a shallow copy (no contained entities, just the trainee data)
									(assign_entity_roots trainee_clone (retrieve_entity_root trainee) )

									;train and derive all the lags and other features as necessary
									(call_entity trainee_clone "Train" (assoc
										input_cases continue_values
										features original_continue_series_features
										session "temp"
										input_is_substituted input_is_substituted
									))

									(assign (assoc
										continue_series_features
											(append (retrieve_from_entity trainee_clone "defaultFeatures") imputed_list_feature)
									))

									(assign (assoc
										continue_values
											(get
												(call_entity trainee_clone "RetrieveAllCases" (assoc
													features continue_series_features
													session "temp"
												))
												"cases"
											)
										time_feature_index
											(get
												(zip continue_series_features (indices continue_series_features))
												time_feature
											)
									))

									;sort the passed in data by the time feature to ensure its order
									(assign (assoc
										continue_values
											(call_entity trainee_clone "MultiSortList" (assoc
												data continue_values
												column_order_indices (list time_feature_index)
											))
									))

									(destroy_entities trainee_clone)

									continue_values
								))
								continue_series_values
							)
					))
				)
			)

			(call !return
				(call_entity trainee "BatchReactSeries" (assoc
					initial_features initial_features
					initial_values initial_values
					series_stop_maps series_stop_maps
					max_series_lengths max_series_lengths
					output_new_series_ids output_new_series_ids
					series_id_tracking series_id_tracking
					output_features output_features
					continue_series continue_series
					continue_series_features continue_series_features
					continue_series_values continue_series_values

					context_features context_features
					context_values context_values
					action_features action_features
					action_values action_values
					derived_action_features derived_action_features
					derived_context_features derived_context_features
					series_context_features series_context_features
					series_context_values series_context_values
					details details
					extra_audit_features extra_audit_features
					ignore_case ignore_case
					case_indices case_indices
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed
					leave_case_out leave_case_out
					num_reacts num_reacts

					desired_conviction desired_conviction
					use_regional_model_residuals use_regional_model_residuals
					feature_bounds_map feature_bounds_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases generate_new_cases
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
				))
			)
		)


	;append cases to a series
	;
	;parameters:
	; series: series id, the key for storing series of react cases
	; context_features: list of context features for the corresponding context_values
	; context_values: list of lists. Case values corresponding to the context features to store into a series.
	#append_to_series_store
		(declare
			(assoc
				series (null)
				context_features (null)
				context_values (null)
			)

			(if (contains_value (list series context_features context_values) (null))
				(call !return (assoc
					errors (list "Must specify 'series', 'context_features' and 'context_values' to append to the series store.")
				))
			)

			(call_entity trainee "AppendToSeriesStore" (assoc
				context_features context_features
				context_values context_values
				series series
			))

			(call !return)
		)


	;clears stored series for a trainee
	;
	;parameters:
	; series: optional, series id to clear.
	#remove_series_store
		(seq
			(call_entity trainee "RemoveSeriesStore" (assoc series series))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;computes various data, such as familiarity convictions and distance contribution for each case in the model and stores them into specified features.
	;
	;parameters:
	; familiarity_conviction_addition : true or string, default is false. if true will use default value of "familiarity_conviction_addition" for feature name
	; familiarity_conviction_removal : true or string, default is false. if true will use default value of "familiarity_conviction_removal" for feature name
	; p_value_of_addition: true or string, default is false. if true will use default value of 'p_value_of_addition' for feature name
	; p_value_of_removal: true or string, default is false. if true will use default value of 'p_value_of_removal' for feature name
	; distance_contribution : true or string, if true will use default value of "distance_contribution" for feature name
	; similarity_conviction : true or string, if true will use default value of "similarity_conviction" for feature name
	; features: list of features for which to calculate conviction, will default to trainee's default features if unspecified
	; case_ids: optional, the list of case ids in the model for which to calculate convictions
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	; use_case_weights: optional, flag, if set to true will scale influence weights by each case's weight_feature weight.
	;				   If a weight is missing, uses 1 as the weight.
	#react_into_features
		(declare
			(assoc
				use_case_weights (false)
				weight_feature ".case_weight"
			)

			(declare (assoc
				warnings
					(call_entity trainee "ReactIntoFeatures" (assoc
						familiarity_conviction_addition familiarity_conviction_addition
						familiarity_conviction_removal familiarity_conviction_removal
						p_value_of_addition p_value_of_addition
						p_value_of_removal p_value_of_removal
						distance_contribution distance_contribution
						similarity_conviction similarity_conviction
						features features
						case_ids case_ids
						weight_feature weight_feature
						use_case_weights use_case_weights
					))
			))

			(call !return (assoc warnings (if (size warnings) (indices warnings)) ))
		)


	;computes the convictions of an average case for each given hypothetical set of cases specified
	; output an assoc react key -> list of corresponding values from each individual group.
	; example output for 2 groups:
	; (assoc
	; 	"base_model_average_distance_contribution" (list 4.0 4.1)
	;	"combined_model_average_distance_contribution" (list 4.05 3.9)
	;	"distance_contributions" (list 4.5 3.2)
	; )
	;
	;parameters:
	; trainee: the trainee model as the prior to measure the conviction from
	; features: list of label names
	; distance_contributions : calculate and output distance contribution ratios in the output assoc
	; familiarity_conviction_addition: default to true, calculate and output familiarity conviction of adding the specified new_cases in the output assoc
	; familiarity_conviction_removal: default to false, calculate and output familiarity conviction of removing the specified new_cases in the output assoc
	; kl_divergence_addition: default to false, calculate and output the KL divergence of adding the specified new_cases in the output assoc
	; kl_divergence_removal: default to false, calculate and output the KL divergence of removing the specified new_cases in the output assoc
	; p_value_of_addition: default is false. if true will output p value of addition
	; p_value_of_removal: default is false. if true will output p value of removal
	; new_cases: a list of lists of lists of values corresponding to a list of sets of feature values, where the values are ordered corresponding to
	;			the features
	; trainees_to_compare: (optional) lists of trainee models to compare to. If specified, ignores new_cases parameter.
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	; use_case_weights: optional, flag, if set to true will scale influence weights by each case's weight_feature weight.
	;				   If a weight is missing, uses 1 as the weight.
	#batch_react_group
		(declare
			(assoc
				features (list)
				new_cases (list)
				familiarity_conviction_addition (true)
				familiarity_conviction_removal (false)
				kl_divergence_addition (false)
				kl_divergence_removal (false)
				p_value_of_addition (false)
				p_value_of_removal (false)
				distance_contributions (false)
				use_case_weights (false)
				weight_feature ".case_weight"
			)

			(if (size trainees_to_compare)
				(let
					(assoc
						;iterate over trainees and do a ReactGroup on each set of cases from each trainee
						react_results
							(map
								(lambda (let
									(assoc
										new_cases
											(get
												(call_entity (current_value 1) "RetrieveAllCases" (assoc
													features features
												))
												"cases"
											)
										; create a copy of trainee, grab created entity id
										temp_trainee (first (clone_entities trainee))
										temp_output (null)
									)

									(assign (assoc
										temp_output
											(if (size new_cases)
												(call_entity temp_trainee "ReactGroup" (assoc
													features features
													new_cases new_cases
													familiarity_conviction_addition familiarity_conviction_addition
													familiarity_conviction_removal familiarity_conviction_removal
													kl_divergence_addition kl_divergence_addition
													kl_divergence_removal kl_divergence_removal
													p_value_of_addition p_value_of_addition
													p_value_of_removal p_value_of_removal
													distance_contributions distance_contributions
													use_case_weights use_case_weights
													weight_feature weight_feature
												))
											)
									))

									(destroy_entities temp_trainee)

									temp_output
								))
								trainees_to_compare
							)
					)

					(call !return (assoc
						payload
							;convert react_results to a dict of react key -> lists of values (one per trainee)
							(call_entity trainee "ConvertBatchReactGroupResultsToLists" (assoc
								react_results react_results
							))
					))
				)

				;else react to specified group of cases
				(call !return (assoc
					payload
						(call_entity trainee "BatchReactGroup" (assoc
							features features
							new_cases new_cases
							familiarity_conviction_addition familiarity_conviction_addition
							familiarity_conviction_removal familiarity_conviction_removal
							kl_divergence_addition kl_divergence_addition
							kl_divergence_removal kl_divergence_removal
							p_value_of_addition p_value_of_addition
							p_value_of_removal p_value_of_removal
							distance_contributions distance_contributions
							weight_feature weight_feature
							use_case_weights use_case_weights
						))
				))
			)
		)


	;computes the conviction for each feature and returns an assoc of feature -> conviction value for each type of conviction
	;
	;parameters:
	; trainee: the trainee model
	; features: list of all feature names
	; action_features: optional, list of action features to use as the baseline for conviction instead of the full model
	; familiarity_conviction_addition: deafult to true, calculate and output familiarity conviction of adding the specified features
	; familiarity_conviction_removal: default to false, calculate and output familiarity conviction of removing the specified features
	; use_case_weights: flag, if set to true will scale influence weights by each case's weight_feature weight
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	#compute_conviction_of_features
		(declare
			(assoc
				features (list)
				action_features (list)
				familiarity_conviction_addition (true)
				familiarity_conviction_removal (false)
				use_case_weights (false)
				weight_feature ".case_weight"
			)

			(call !return (assoc
				payload
					(append
						(if (or familiarity_conviction_addition familiarity_conviction_removal)
							(call_entity trainee "ComputeFeatureFamiliarityConviction" (assoc
								features features
								action_features action_features
								familiarity_conviction_addition familiarity_conviction_addition
								familiarity_conviction_removal familiarity_conviction_removal
								weight_feature weight_feature
								use_case_weights use_case_weights
							))
							(assoc)
						)
					)
			))
		)

	;set all features and their attributes for a trainee
	;
	;parameters:
	; features: assoc in the following example format
	;	{
	;		'sepal-width' : {		  #name of feature as the key, and feature attributes as value
	;			'type': 'continuous', #one of 'continuous', 'ordinal' or 'nominal'. default is 'continuous'
	;			'cycle_length': 7,	  #specify cycle length of cyclic feature, default is no cycle length
	;			'date_time_format': '%Y-%m-%d-%H.%M.%S', #date time format string, default is no date_time_format
	;			'locale': 'en_US',	  # locale for the date time, default is "en_US"
	;			'time_delta_format: 'seconds',  #format of the delta for times, default is "seconds". valid values are:
	;								  milliseconds, seconds, minutes, hours, days, weeks, years
	;			'significant_digits': 2,  #rounding to significant digits, default is no rounding
	;			'decimal_places': 1,  #rounding of decimal places, default is no rounding. If significant_digits is specified, then it rounds to the
	;								  #specified number of significant digits. If decimal_places is specified, then it ensures that output will be
	;								  #rounded at least to the number of decimal points past the integer as specified by decimal_places.
	;			'observational_error': .333,	  #observed error for feature, if known
	;			'data_type': 'number' # non-string nominals only, persists their original datatype on output. Valid values are 'number' for
	;								  # numeric nominals, and 'boolean' for boolean nominals
	;			'id_feature': True,   #flag specifying a feature should be used to compute case weights for id based privacy
	;			'unique': True		  #flag for nominal features if nominal feature has only unique values
	;			'dependent_features': [], #list of dependent features, directionality of depedency is not relevant. Should be used when there may
	;									#be multi-type value features that tightly depend on values based on other multi-type values features.
	;			'derived': False	  #flag if a feature is automatically derived from others.
	;								  # For full list of valid derived feature attributes refer the comments in the derive.amlg module.
	;		}
	;	}
	#set_feature_attributes
		(declare
			(assoc features (assoc) )
			(declare (assoc
				error_text (call_entity trainee "SetFeatureAttributes" (assoc features features))
			))

			(accum_to_entities trainee (assoc revision 1))
			(if error_text
				(call !return (assoc errors (list error_text)))

				(call !return)
			)
		)


	;gets all the full feature attributes for a specified trainee
	#get_feature_attributes
		(call !return (assoc
			payload (call_entity trainee "GetFeatureAttributes")
		))


	;sets substitution feature values used in case generation
	;
	;parameters:
	; substitution_value_map: assoc of feature -> assoc of value -> substitution.
	;	If this map is null, all substitutions will be disabled and cleared
	;	If any feature in the substitution_value_map has a missing or empty assoc of substitutions, substitution values will immeditally be generated
	#set_substitute_feature_values
		(seq
			(call_entity trainee "SetSubstituteFeatureValues" (assoc substitution_value_map substitution_value_map))
			(call !return)
		)


	;returns the substitution map
	#get_substitute_feature_values
		(call !return (assoc
			payload (call_entity trainee "GetSubstituteFeatureValues")
		))


	;automatically analyze the model using stored parameters from previous analyze calls
	#auto_analyze
		(let
			(assoc saved_analyze_parameters_map (retrieve_from_entity trainee "savedAnalyzeParameterMap"))

			;if this is called before regular analyze, analyze the model as targetless
			(if (= (null) saved_analyze_parameters_map)
				(call analyze (assoc
					trainee trainee
					context_features (retrieve_from_entity trainee "defaultFeatures")
					analyze_level 2
				))

				;else call analyze with stored parameters
				(seq
					;if analysis should recalculate residuals, clear them from cache so they'll be overwritten
					(if (or
							(> (get saved_analyze_parameters_map "analyze_level") 1)
							(= (false) (get saved_analyze_parameters_map "bypass_calculate_feature_residuals"))
						)
						;iterate over hyperparameter_map and clear out weights and deviations for all
						(call_entity trainee "UpdateHyperparameterMapFeatureParameter" (assoc
							targeted_model "all"
							attribute_map
								(assoc
									"featureWeights" (null)
									"useDeviations" (false)
									"featureDeviations" (null)
									"allFeatureResidualsCached" (false)
								)
							use_case_weights (= (true) (get saved_analyze_parameters_map "use_case_weights"))
							weight_feature (get saved_analyze_parameters_map "weight_feature")
						))
					)
					(call analyze (append
						saved_analyze_parameters_map (assoc "trainee" trainee)
					))
				)
			)
		)


	;Analyzes the data to compute the appropriate statistics, uncertainties, and select parameters as appropriate.
	;parameters:
	; context_features: list of context features to analyze for
	; action_features: list of action features to analyze for. applicable only to 'single_targeted' mode
	; k_folds: optional, (defaults to 6) number of cross validation folds to do. value of 1 does hold-one-out instead of k-fold
	; k_folds_by_indices : optional flag, default is false. if set to true will do k_folds ordered by session id indices, i.e., it'll hold out the
	;			first 1/6th of the trained cases, then the next 1/6th, etc. in the order they were trained.
	;			NOTE: if the dataset has been edited or has multiple trained sessions, the holdouts may be imbalanced due to multiple cases having
	;			the same session id index or missing session indices, therefore this flag should only be used internally for validation
	; bypass_hyperparameter_analysis : optional
	; bypass_calculate_feature_residuals : optional
	; bypass_calculate_feature_weights : optional
	; use_deviations: optional, default is null, will auto-determine whether to use deviations for LK metric in queries. When true forces the use
	;			of deviations , when false will not use deviations.
	; num_samples: used in calculating feature residuals
	; k_values: optional list used in hyperparameter search
	; p_values: optional list used in hyperparameter search
	; dt_values: optional list used in hyperparameter search
	; analyze_level: optional value, if specified will analyze for the following flows:
	;			1: predictions/accuracy (hyperparameters, by default does not analyze for p=0)
	;			2: data synth (level 1 + cache: global residuals)
	;			3: standard explanations (level 1 + cache: case prediction conviction)
	;			4: full analysis (levels 1,2,3 + cache: model feature prediction conviction)
	; targeted_model: enumeration, default is "single_targeted"
	;   "single_targeted" = analyze hyperparameters for the specified action_features
	;   "omni_targeted" = analyze hyperparameters for each action feature, using all other features as context_features. if action_features aren't specified, uses all context_features.
	;   "targetless" = analyze hyperparameters for all context features as possible action features, ignores action_features parameter
	; num_analysis_samples : optional. number of cases to sample during analysis. only applies for k_folds = 1
	; analysis_sub_model_size: optional. number of samples to use for analysis. the rest will be randomly held-out and not included in calculations
	; inverse_residuals_as_weights: optional, default is null, will be set to false for targeted and true for targetless
	;			when true will forcibly compute and use inverse of residuals as feature weights
	; use_case_weights: optional, default is false. when true will scale influence weights by each case's weight_feature weight
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	;
	; returns success when completed
	#analyze
		(declare
			(assoc
				context_features (list)
				action_features (list)
				k_folds 1
				weight_feature ".case_weight"
				use_case_weights (false)
				inverse_residuals_as_weights (null)
			)

			(if use_case_weights
				;CreateCaseWeights will find all cases missing weight_feature, then initialize
				;weight_feature with a value of 1.0 for each
				(call_entity trainee "CreateCaseWeights" (assoc
					feature_name weight_feature
				))
			)

			;if k_folds is not a number value, or it's less than 1, ensure that it's overwritten with the default value
			(if (or (not (= "number" (get_type_string k_folds))) (< k_folds 1))
				(assign (assoc k_folds 1))
			)

			(declare (assoc num_cases (call_entity trainee "GetNumTrainingCases")))

			;cap max k_folds to the number of cases in the model
			(if (> k_folds num_cases)
				(assign (assoc k_folds num_cases))
			)

			;save the parameters that analyze was called with
			(assign_to_entities trainee (assoc
				savedAnalyzeParameterMap
					(assoc
						"context_features" context_features
						 "action_features" action_features
						 "k_folds" k_folds
						 "k_folds_by_indices" k_folds_by_indices
						 "bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
						 "bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
						 "bypass_calculate_feature_weights" bypass_calculate_feature_weights
						 "use_deviations" use_deviations
						 "num_samples" num_samples
						 "k_values" k_values
						 "p_values" p_values
						 "dt_values" dt_values
						 "analyze_level" analyze_level
						 "targeted_model" targeted_model
						 "num_analysis_samples" num_analysis_samples
						 "analysis_sub_model_size" analysis_sub_model_size
						 "inverse_residuals_as_weights" inverse_residuals_as_weights
						 "use_case_weights" use_case_weights
						 "weight_feature" weight_feature
					)
			))

			;prediction/accuracy: hyperparameters only
			(if (= 1 analyze_level)
				(assign (assoc
					bypass_hyperparameter_analysis (false)
					bypass_calculate_feature_residuals (true)
					bypass_calculate_feature_weights (false)
				))

				;data synth, hyperparameters + model residuals
				(= 2 analyze_level)
				(assign (assoc
					bypass_hyperparameter_analysis (false)
					bypass_calculate_feature_residuals (false)
					bypass_calculate_feature_weights (true)
				))

				;explanations, hyperparameters + case prediction conviction
				(= 3 analyze_level)
				(assign (assoc
					bypass_hyperparameter_analysis (false)
					bypass_calculate_feature_residuals (true)
					bypass_calculate_feature_weights (false)
				))

				;full analysis: everything
				(= 4 analyze_level)
				(assign (assoc
					bypass_hyperparameter_analysis (false)
					bypass_calculate_feature_residuals (false)
					bypass_calculate_feature_weights (false)
				))
			)

			(declare (assoc holdout_entity_name (null) ))

			;if user specified how many samples to use for analysis, randomly hold out the rest
			(if (!= (null) analysis_sub_model_size)
				(let
					(assoc model_size (call_entity trainee "GetNumTrainingCases"))

					;analysis_sub_model_size must be at least 2 * number of k_folds otherwise there may be no cases in a fold
					(if (< analysis_sub_model_size (* 2 k_folds))
						(assign (assoc analysis_sub_model_size (* 2 k_folds)))
					)

					(if (> model_size analysis_sub_model_size)
						(assign (assoc
							holdout_entity_name (call_entity trainee "HoldOutRandomCases" (assoc num_samples (- model_size analysis_sub_model_size)))
						))
					)
				)
			)

			;if no action features were specified, and neither was targeted_model, set it to targetless
			(if (and
					(= 0 (size action_features))
					(or
						(= (null) targeted_model)
						(= "single_targeted" targeted_model)
					)
				)
				(assign (assoc targeted_model "targetless"))

				;else one or more action features specified but targeted_model wasn't, set it to single_targeted
				(and
					(>= 1 (size action_features))
					(= (null) targeted_model)
				)
				(assign (assoc targeted_model "single_targeted"))

				;if omni_targeted and didn't provide action_features, assume all features are action features
				(and
					(= "omni_targeted" targeted_model)
					(= 0 (size action_features))
				)
				(assign (assoc action_features context_features))

				;default is targetless if inputs are bad
				(not (contains_value (list "targetless" "single_targeted" "omni_targeted") targeted_model))
				(assign (assoc targeted_model "targetless"))
			)


			;if the bypass hyperparameter analysis flag is null or is false, analyze hyper parameters
			(if (not bypass_hyperparameter_analysis)
				(call_entity trainee "Analyze" (assoc
					context_features context_features
					action_features action_features
					k_folds k_folds
					k_values k_values
					p_values p_values
					dt_values dt_values
					use_deviations use_deviations
					k_folds_by_indices k_folds_by_indices
					targeted_model targeted_model
					num_analysis_samples num_analysis_samples
					inverse_residuals_as_weights inverse_residuals_as_weights
					residual_num_samples (if (> num_samples 0) num_samples 200)
					use_case_weights use_case_weights
					weight_feature weight_feature
				))
			)

			;only calculate feature residuals if they aren't being bypassed and haven't been calculated above
			(if (and
					(= (false) bypass_calculate_feature_residuals)
					(or bypass_hyperparameter_analysis (!= "targetless" targeted_model))
				)
				(let
					(assoc
						;remove possible duplicates from all_features while mantaining order of features
						all_features (values (append context_features action_features) (true))
					)

					;for targetless flows, there are no action features, so use ".targetless" as the hyperparameter action feature
					(if (= "targetless" targeted_model)
						(assign (assoc action_features (list ".targetless" )))
					)

					(map
						(lambda
							(call_entity trainee "CalculateAndStoreFeatureResiduals" (assoc
								features all_features
								;default the num_samples to 1000
								num_samples (if (> num_samples 0) num_samples 1000)
								robust_residuals (= "targetless" targeted_mode)
								;use the specific action feature's hyperparameters
								hyperparameter_feature (current_value 1)
								weight_feature weight_feature
								use_case_weights use_case_weights
							))
						)
						action_features
					)
				)
			)

			(if holdout_entity_name
				(call_entity trainee "RestoreHeldOutCases" (assoc holdout_entity_name holdout_entity_name))
			)

			(accum_to_entities trainee (assoc revision 1))

			(call !return)
		)


	;Compute and cache specified feature prediction statistics such as Mean Decrease in Accuracy (MDA), residuals (accuracy, Mean Absolute Error),
	; precision, recall, etc.
	;
	;parameters:
	; residuals: optional, none/true/false. For each context_feature, use the full set of all other context_features to
	;				 predict the feature.  When true, computes and caches MAE (mean absolute error), R^2, RMSE (root mean squared error), and
	;				Spearman Coefficient for continuous features, MAE, accuracy, precision and recall for nominal features.
	;				false removes cached values.
	; residuals_robust: optional, none/true/false. For each context_feature, computes and caches the same stats as residuals but using the robust
	;				(power set/permutations) set of all other context_features to predict the feature.  false removes cached values.
	;
	; contributions: optional, none/true/false.  For each context_feature, use the full set of all other context_features to compute the
	;				 mean absolute delta between prediction of action_feature with and without the context_feature in the model.  false removes cached values.
	; contributions_robust: optional, none/true/false. For each context_feature, use the robust (power set/permutation) set of all other context_features
	;				 to compute the mean absolute delta between prediction of action_feature with and without the context_feature in the model.
	;				false removes cached values.
	;
	; mda: optional, none/true/false. if true will compute Mean Decrease in Accuracy (MDA) for each context feature at predicting mda_action_features.
	;				Drop each feature and use the full set of remaining context features for each prediction.  false removes cached values.
	; mda_permutation: optional, none/true/false. Compute MDA by scrambling each feature and using the full set of remaining context features
	;				for each prediction.  false removes cached values.
	; mda_robust: optional, none/true/false. Compute MDA by dropping each feature and using the robust (power set/permutations) set of
	;				remaining context features for each prediction.  false removes cached values.
	; mda_robust_permutation: optional, none/true/false. Compute MDA by scrambling  each feature and using the robust (power set/permutations)
	;				set of remaining context features for each prediction.  false removes cached values.
	; action_feature: optional, target feature for which to do computations. Default is whatever the model was analyzed for, i.e.,
	;				  action feature for MDA and contributions, or ".targetless" if analyzed for targetless.
	;				  This parameter is required for any MDA or contributions computation.
	;
	; context_features: optional list of features to use as contexts for computations. default is all features if unspecified.
	; num_samples: optional. Total sample size of model to use (using sampling with replacement) for all non-robust computation.
	;				  Defaults to 1000. If specified overrides sample_model_fraction.
	; num_robust_residual_samples: optional. Total sample size of model to use (using sampling with replacement) for robust mda and residual computation.
	;				  Defaults to 1000 * (1 + log(number of features)).  Note: robust mda will be updated to use num_robust_influence_samples in a future release.
	; num_robust_influence_samples: optional. Total sample size of model to use (using sampling with replacement) for robust contribution computation.
	;				  Defaults to 300.
	; num_robust_influence_samples_per_case: optional, Specifies the number of robust samples to use for each case for robust contribution computations.
	;				  Defaults to 300 + 2 * (number of features).
	; sample_model_fraction : optional, value 0.0 - 1.0, percent of model to use in sampling (using sampling without replacement).
	;				  Applicable only to non-robust computation. Ignored if num_samples is specified.
	; sub_model_size: optional. if specified will calculate only on a sub model of the specified size from the full model.
	;				  Applicable only to models > 1000 cases.
	; hyperparameter_param_path: optional. full path for hyperparameters to use for computation.
	;				  If specified for any residual computations, takes precendence over action_feature parameter.
	; use_case_weights: optional, flag, if set to true will scale influence weights by each case's weight_feature weight
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	#react_into_trainee
		(declare
			(assoc
				context_features (list)
				use_case_weights (false)
				weight_feature ".case_weight"
				num_samples (null)

				contributions (null)
				contributions_robust (null)
				residuals (null)
				residuals_robust (null)
				mda (null)
				mda_permutation (null)
				mda_robust (null)
				mda_robust_permutation (null)
				action_feature (null)
				num_robust_residual_samples (null)
				num_robust_influence_samples (null)
				num_robust_influence_samples_per_case (null)
				sample_model_fraction (null)
				sub_model_size (null)
				hyperparameter_param_path (null)
			)

			(declare (assoc invalid_parameters (false)))

			(if hyperparameter_param_path
				(let
					(assoc hp_map (get (retrieve_from_entity trainee "hyperparameterMetadataMap") hyperparameter_param_path) )
					(if (= (null) hp_map)
						(assign (assoc invalid_parameters (true) ))
					)
				)
			)
			(if invalid_parameters
				(conclude
					(call !return (assoc errors (list "Invalid hyperparameter param path provided. Please call 'get_internal_parameters' for list of available param paths.")))
				)
			)

			(if (and
					(= (null) action_feature)
					(not (= (null) contributions contributions_robust mda mda_permutation mda_robust mda_robust_permutation))
				)
				(conclude
					(call !return (assoc errors (list "Must specify action_feature when computing feature MDA or contributions.")))
				)
			)

			;sample_model_fraction is ignored for any robust computation
			(if (or contributions_robust residuals_robust mda_robust mda_robust_permutation)
				(assign (assoc sample_model_fraction (null)))
			)

			(declare (assoc
				warnings
					(call_entity trainee "ReactIntoTrainee" (assoc
						context_features context_features
						use_case_weights use_case_weights
						weight_feature weight_feature
						num_samples num_samples
						sample_model_fraction sample_model_fraction
						sub_model_size sub_model_size
						residuals residuals
						residuals_robust residuals_robust
						contributions contributions
						contributions_robust contributions_robust
						mda mda
						mda_permutation mda_permutation
						mda_robust mda_robust
						mda_robust_permutation mda_robust_permutation
						action_feature action_feature
						num_robust_residual_samples num_robust_residual_samples
						num_robust_influence_samples num_robust_influence_samples
						num_robust_influence_samples_per_case num_robust_influence_samples_per_case
						hyperparameter_param_path hyperparameter_param_path
					))
			))

			(call !return (assoc warnings (if (size warnings) (indices warnings)) ))
		)

	;returns cached feature prediction stats for all features in the format of feature -> assoc stat -> value
	;parameters are optional, when not specified will output all stats, when specified will attempt to
	;output the cached stats best matching the requested parameters, null if none match.
	;
	;parameters:
	; stats: list of strings, optional.  Allowed values are:
	;	"mda" : mean decrease in accuracy when each feature is dropped from the model, applies to all features.
	;	"contribution": feature contribution to predicted value when each feature is dropped from the model, applies to all features.
	;	"mda_permutation": mean decrease in accuracy that used scrambling of feature values instead of dropping each feature, applies to all features.
	;	"mae" : Mean absolute error. For continuous features, this is calculated as the mean of absolute values of the difference
    ;		between the actual and predicted values. For nominal features, this is 1 - the average categorical action probability of each case's
    ;		correct classes. Categorical action probabilities are the probabilities for each class for the action feature.
	;	"r2": r-squared coefficient of determination, for continuous features only.
	;	"rmse": root mean squared error, for continuous features only.
	;	"spearman_coeff": Spearman's rank correlation coefficient, for continuous features only.
	;	"precision": precision (positive predictive) value for nominal features only.
	;	"recall": recall (sensitivity) value for nominal features only.
	;	"accuracy": The number of correct predictions divided by the total number of predictions.
	;   "confusion_matrix": A matrix showing the number of predicted values of each class
	;                       for each unique value of the predicted feature.
	;
	; robust: flag, optional. if specified will attempt to return stats that were computed with the specified robust or non-robust type.
	; action_feature: string, optional. if specified will attempt to return stats that were computed for this specified action_feature.
	;				  Note: ".targetless" is the action feature used during targetless analysis.
	; robust_hyperparameters: flag, optional. if specified, will attempt to return stats that were computed using hyperpparameters with the
	;						  specified robust or non-robust type.
	; weight_feature: string, optional. if specified, will attempt to return stats that were computed using this weight_feature.
	; condition: assoc of feature->value(s)
	;		no value = must have feature
	;   	- for continuous or numeric ordinal features:
	;			one value = must equal exactly the value or be close to it for fuzzy match
	;			two values = inclusive between
	;   	- for nominal or string ordinal features:
	;			n values = must match any of these values exactly
	; precision: optional string,  default is 'exact', used only with 'condition' parameter, will find exact matches if 'exact' and similar cases if 'similar'.
	; num_cases: optional, limit on the number of cases to use in calculating conditional prediction stats; If set to zero there will be no limit.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	; num_robust_influence_samples_per_case: optional, Specifies the number of robust samples to use for each case for robust contribution computations.
	;				  Defaults to 300 + 2 * (number of features).
	#get_prediction_stats
		(declare
			(assoc
				stats (list)
				robust (null)
				action_feature (null)
				robust_hyperparameters (null)
				weight_feature (null)
				condition (null)
				precision "exact"
				num_cases (null)
			)

			;if there are specified stats remaining after all the supported stats have been removed, that means unsupported ones were provided
			(if (> (size (remove (zip stats) (retrieve_from_entity trainee "supportedPredictionStats"))) 0)
				(conclude
					(call !return (assoc
						errors
							(list (concat
								"Specified an unsupported stat. Supported stats are: "
								(apply "concat" (trunc (weave supportedPredictionStats ", ")))
							))
					))
				)
			)

			(call !return
				(if (= condition (null))
					(call_entity trainee "GetFeaturePredictionStats" (assoc
						stats stats
						robust robust
						action_feature action_feature
						robust_hyperparameters robust_hyperparameters
						weight_feature weight_feature
					))

					;else condition is present
					(call_entity trainee "CalculateConditionalPredictionStats" (assoc
						stats stats
						robust robust
						action_feature action_feature
						robust_hyperparameters robust_hyperparameters
						weight_feature weight_feature
						condition condition
						precision precision
						num_cases num_cases
						num_robust_influence_samples_per_case num_robust_influence_samples_per_case
					))
				)
			)
		)


	;outputs all marginal stats (min, max, median, mean, mode, count, uniques, mean_absdev, variance, stddev, skew, kurtosis, entropy)
	;for all features in the format of feature -> assoc stat -> value. The marginal stats can be computed for a subset of the data using condition, precision, and num_cases
	;
	;parameters:
	; weight_feature: optional, name of case weight feature
	; condition: assoc of feature->value(s)
	;		no value = must have feature
	;   	- for continuous or numeric ordinal features:
	;			one value = must equal exactly the value or be close to it for fuzzy match
	;			two values = inclusive between
	;   	- for nominal or string ordinal features:
	;			n values = must match any of these values exactly
	; precision: optional string,  default is 'exact', used only with 'condition' parameter, will find exact matches if 'exact' and similar cases if 'similar'.
	; num_cases: optional, limit on the number of cases to use in calculating conditional prediction stats; If set to zero there will be no limit.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	#get_marginal_stats
		(declare
			(assoc
				weight_feature (null)
				condition (null)
				precision "exact"
				num_cases (null)
			)

			(call !return (assoc
				payload
					(call_entity trainee "GetFeatureMarginalStats" (assoc
						weight_feature weight_feature
						condition condition
						precision precision
						num_cases num_cases
					))
			))
		)


	;returns cached feature residuals in the format of assoc feature -> residual value
	;parameters are optional, when not specified will auto-select a cached Residuals set for output, when specified will attempt to
	;output the cached residuals best matching the requested parameters, null if none match.
	;
	;parameters:
	; robust: flag, optional. if specified will attempt to return residuals that were computed with the specified robust or non-robust type.
	; action_feature: string, optional. if specified will attempt to return residuals that were computed for this specified action_feature.
	;				  Note: ".targetless" is the action feature used during targetless analysis.
	; robust_hyperparameters: flag, optional. if specified, will attempt to return residuals that were computed using hyperpparameters with the
	;						  specified robust or non-robust type.
	; weight_feature: string, optional. if specified, will attempt to return residuals that were computed using this weight_feature.
	#get_feature_residuals
		(declare
			(assoc
				robust (null)
				action_feature (null)
				robust_hyperparameters (null)
				weight_feature (null)
			)

			(if (= 0 (size (retrieve_from_entity trainee "residualsMap")) )
				(conclude
					(call !return (assoc
						errors
							(list "Feature Residuals have not been computed for this trainee. Please call 'react_into_trainee' with appropriate parameters to compute and store residuals prior to calling this method.")
					))
				)
			)

			(declare (assoc
				output
					(call_entity trainee "GetFeatureResiduals" (assoc
						robust robust
						action_feature action_feature
						robust_hyperparameters robust_hyperparameters
						weight_feature weight_feature
					))
			))

			(if (= (null) output)
				(call !return (assoc
					errors (list "Feature Residuals for the specified parameters has not been computed.  Please call 'react_into_trainee' with appropriate parameters to compute and store residuals prior to calling this method.")
				))

				(call !return (assoc payload output))
			)
		)


	;returns cached feature mda in the format of assoc feature -> mda value
	;parameters are optional, when not specified will auto-select a cached MDA for output, when specified will attempt to output
	;the cached MDA best matching the requested parameters, null if none match.
	;
	;parameters:
	; robust: flag, optional. if specified will attempt to return MDA that was computed with the specified robust or non-robust type.
	; permutation: flag, optional. if false, will attempt to return MDA that was computed with mda_type of drop. if true will attempt to
	;			   return MDA that was computed with mda_type of permutation.
	; action_feature: string, will attempt to return MDA that was computed for the specified action_feature.
	; weight_feature: string, optional. if specified, will attempt to return MDA that was computed using this weight_feature.
	#get_feature_mda
		(declare
			(assoc
				robust (null)
				permutation (null)
				action_feature (null)
				weight_feature (null)
			)

			(if (= (null) action_feature)
				(conclude
					(call !return (assoc errors (list "Must specify action_feature when computing feature MDA.")))
				)
			)

			(if (and
					(= 0 (size (retrieve_from_entity trainee "mdaMap")) )
					(= 0 (size (retrieve_from_entity trainee "mdaPermutationMap")) )
				)
				(conclude
					(call !return (assoc
						errors
							(list "Feature MDA has not been computed for this trainee. Please call 'react_into_trainee' with appropriate parameters to compute and store MDA prior to calling this method.")
					))
				)
			)

			(declare (assoc
				output
					(call_entity trainee "GetFeatureMDA" (assoc
						robust robust
						permutation permutation
						action_feature action_feature
						weight_feature weight_feature
					))
			))

			(if (= (null) output)
				(call !return (assoc
					errors (list "Feature MDA for the specified parameters has not been computed.  Please call 'react_into_trainee' with appropriate parameters to compute and store MDA prior to calling this method.")
				))

				(call !return (assoc payload output))
			)
		)

	;returns cached feature contributions in the format of assoc feature -> contribution value
	;parameters are optional, when not specified will auto-select cached contributions for output, when specified will attempt to output the cached
	;contributions best matching the requested parameters, null if none match.
	;
	;parameters:
	;
	; directional: flag, optional. Default is false, returns absolute feature contributions. When true returns directional feature contributions.
	; robust: flag, optional. if specified will attempt to return contributions that was computed with the specified robust or non-robust type.
	; action_feature: string, will attempt to return contributions that were computed for the specified action_feature.
	; weight_feature: string, optional. if specified, will attempt to return contributions that were computed using this weight_feature.
	#get_feature_contributions
		(declare
			(assoc
				robust (null)
				directional (false)
				action_feature (null)
				weight_feature (null)
			)

			(if (= (null) action_feature)
				(conclude
					(call !return (assoc errors (list "Must specify action_feature when computing feature contributions.")))
				)
			)

			(if (= 0 (size (retrieve_from_entity trainee "contributionsMap")) )
				(conclude
					(call !return (assoc
						errors
							(list "Feature contributions have not been computed for this trainee. Please call 'react_into_trainee' with appropriate parameters to compute and store contributions prior to calling this method.")
					))
				)
			)

			(declare (assoc
				output
					(call_entity trainee "GetFeatureContributions" (assoc
						directional directional
						robust robust
						action_feature action_feature
						weight_feature weight_feature
					))
			))

			(if (= (null) output)
				(call !return (assoc
					errors (list "Feature contributions for the specified parameters has not been computed.  Please call 'react_into_trainee' with appropriate parameters to compute and store contributions prior to calling this method.")
				))

				(call !return (assoc payload output))
			)
		)


	;set the random seed on a trainee
	; parameters:
	; seed : optional, the value of the random seed to set on the trainee, defaults to a system-provided 64-bit random number
	#set_random_seed
		(declare
			(assoc
				seed (system "rand" 16)
			)

			(set_entity_rand_seed trainee seed)
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;return the full internal parameters map if no parameters are specified.
	;if any of the parameters are specified, then GetHyperparameters is called, which uses the specified parameters to find the most suitable set of hyperparameters to return
	; parameters:
	; action_feature : optional, the target feature of the desired hyperparameters
	; context_features : optional, the set of context features used for the desired hyperparameters
	; mode : optional, the method of calculation used to find the desired hyperparameters
	; weight_feature : optional, the weight feature used in the calculation of the desired hyperparameters
	#get_internal_parameters
		(call !return (assoc
			payload
				(call_entity trainee "GetInternalParameters" (assoc
					action_feature action_feature
					context_features context_features
					mode mode
					weight_feature weight_feature
				))
		))

	;sets internal hyperparameters
	;
	;parameters:
	; hyperparameter_map: required. must have at least an action feature (e.g., .targetless) -> context feature key (sorted and concatenated context features with "." separators) ->robust -> k, p and dt provided.
	;	example:
	;   {
	;	    ".targetless" { "featureA.featureB.": { "robust" : { "k" : number, "p" : number, "dt": number }}},
	;		"featureA" : { "featureB.featureC.": { "full" : { "k" : number, "p" : number, "dt": number }}},
	;			...
	;	}
	; default_hyperparameter_map: optional. an assoc of hyperparameters to use when no others are available must contain k, p, and dt.
	; auto_analyze_enabled: flag, default is false. when true, returns when it's time for model to be analyzed again.
	; analyze_threshold: optional, stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
	; analyze_growth_factor: the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
	;						default of two orders of magnitude using the universal scaling factor e
	; auto_analyze_limit_size: optional, the size of of the model at which to stop doing outo-analysis
	#set_internal_parameters
		(let
			(assoc
				success
					(call_entity trainee "SetInternalParameters" (assoc
						hyperparameter_map hyperparameter_map
						default_hyperparameter_map default_hyperparameter_map
						auto_analyze_enabled auto_analyze_enabled
						analyze_threshold analyze_threshold
						analyze_growth_factor analyze_growth_factor
					))
			)

			(if success
				(call !return)

				(call !return (assoc
					errors (list "Failed to set parameters: invalid parameters specified.")
				))
			)
		)


	;set the minimum size of the model before ablatement kicks in, value must be above 0
	#set_min_ablatement_model_size
		(if (> min_ablatement_model_size 0)
			(seq
				(assign_to_entities trainee (assoc minAblatementModelSize min_ablatement_model_size))
				(accum_to_entities trainee (assoc revision 1))
				(call !return)
			)

			(call !return (assoc errors (list "Failed to set min ablatement size: invalid min_ablatement_model_size specified.")))
		)


	;set the influence weight threshold for outputting only the K neighbors whose inflence weight is <= to this threshold
	;default value is 0.99
	#set_influence_weight_threshold
		(seq
			(assign_to_entities trainee (assoc influenceWeightThreshold influenceWeightThreshold))
			(accum_to_entities trainee (assoc revision 1))
			(call !return)
		)


	;moves all cases that match the specified conditions from trainee to the target trainee
	;removes all cases that match the specified conditions if target trainee is not specified
	;parameters:
	; target_trainee : the trainee to move cases to. if not specified will remove cases
	; case_indices : a list of session id and training index tuples that specify which cases are to be moved
	; precision: flag, whether to query for 'exact' matches; if set to 'similar' will move num_cases with the most similar values. Ignored if case_indices is specified.
	; condition: assoc of feature->value(s) (no value = must have feature, one value = must equal exactly the value, two values = inclusive between). Ignored if case_indices is specified.
	; condition_session: optional, if specified, ignores condition and instead operates on all cases that were trained with this session id. Ignored if case_indices is specified.
	; num_cases: optional, limit on the number of cases to move; If set to zero there will be no limit. Ignored if case_indices is specified.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	; preserve_session_data: if true will just remove cases, otherwise will do session cleanup
	; session: the session id when this call is being made. Applicable  only when target_trainee is specified,
	; 	used for training the cases into the target_trainee
	; distribute_weight_feature: name of feature into which to distribute the removed cases' weights to their neighbors.
	;  	Applicable only if specified and removing cases (target_trainee is not specified).
	#move_cases
		(declare
			(assoc
				case_indices (null)
				condition (assoc)
				precision "exact"
				num_cases (null)
				preserve_session_data (false)
				session "none"
				distribute_weight_feature (null)
			)

			;if moving cases, make sure target trainee entity exists, otherwise return 0
			(if (and
					(!= target_trainee (null))
					(not (contains_entity target_trainee))
				)
				(conclude
					(call !return (assoc
						errors (list (concat "Failed to move cases: target trainee " target_trainee " does not exist."))
					))
				)
			)

			;build list of case ids that match criteria
			(declare (assoc
				cases_to_move
					(if (= (null) case_indices)
						;compute the cases to re/move
						(call_entity trainee "GetCasesByCondition" (assoc
							condition condition
							condition_session condition_session
							precision precision
							num_cases num_cases
						))

						;else use case_indices
						(call_entity trainee "GetCaseIds" (assoc case_indices case_indices))
					)
			))

			;move or remove cases matching the criteria
			(if (!= target_trainee (null))
				;iterate over each case and move it from the trainee into target_trainee
				(if preserve_session_data
					;just move the cases without editing session data
					(map
						(lambda
							;if target already has an entity with this exact id, move it into the target without maintaining original id
							(if (contains_entity target_trainee (current_value))
								(move_entities (list trainee (current_value 1)) target_trainee)

								;else move the entity to the target maintaining its id
								(move_entities (list trainee (current_value 1)) (list target_trainee (current_value 1)))
							)
						 )
						cases_to_move
					)

					;else move the cases by retraining them in the target trainee and clearing out session data from trainee
					(map
						(lambda (let
							(assoc
								;grab all the case data as an assoc
								case_map (get_all_labels (retrieve_entity_root (list trainee (current_value 2)) 1 ))
							)
							(declare (assoc
								;keep all features from the case except for 'sessions' since that'll have to be recomputed
								case_features
									(filter
										(lambda (!= (current_value) ".session"))
										(indices case_map)
									)
							))
							(call_entity target_trainee "Train" (assoc
								features case_features
								input_cases (list (unzip case_map case_features))
								session session
								;allow training on reserved features to preserve all case data
								allow_training_reserved_features (true)
							))
						))
						cases_to_move
					)
				)
			)

			;remove cases and do session cleanup
			(if (or (not preserve_session_data) (= (null) target_trainee))
				(call_entity trainee "RemoveCases" (assoc
					cases cases_to_move
					distribute_weight_feature distribute_weight_feature
				))
			)

			(accum_to_entities trainee (assoc revision 1))

			;return the number of cases moved
			(call !return (assoc payload (assoc "count" (size cases_to_move)) ))
		)


	;Returns a list of computed distances between respective cases specified in either from_values or from_case_indices to to_values or to_case_indices.
	; If one case is specified in any of the lists, all respective distances are computed to/from that one case.
	;
	;parameters:
	; from_values: optional list of cases (lists of values), i.e., a 2d-list of values. Either from_values or from_case_indices must be specified, not both.
	;			if specified must be either length of 1 or match length of to_values or to_case_indices.
	; to_values: optional list of cases (lists of values), i.e., a 2d-list of values. Either to_values or to_case_indices must be specified, not both.
	;			if specified must be either length of 1 or match length of from_values or from_case_indices.
	; from_case_indices: optional, list of pair (list) of session id and index, where index is the original 0-based session_training_index of the case as it was trained.
	;			if specified must be either length of 1 or match length of to_values or to_case_indices.
	; to_case_indices: optional list of pair (list) of session id and index, where index is the original 0-based session_training_index of the case as it was trained.
	;			if specified must be either length of 1 or match length of from_values or from_case_indices.
	; features: optional, which features to use when computing pairwise distances. If unspecified uses all features.
	; action_feature: optional, if specified, uses targeted hyperparameters used to predict this action_feature, otherwise uses targetless hyperparameters.
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	; use_case_weights: optional flag, if set to true will scale influence weights by each case's weight_feature weight
	#pairwise_distances
	(declare
		(assoc
			features (null)
			action_feature (null)
			from_values (list)
			to_values (list)
			from_case_indices (list)
			to_case_indices (list)
			weight_feature ".case_weight"
			use_case_weights (false)
		)

		(declare (assoc
			size_to_values (size to_values)
			size_from_values (size from_values)
			size_to_cases (size to_case_indices)
			size_from_cases (size from_case_indices)
		))

		(if
			(and (> size_from_cases 0) (> size_from_values 0) )
			(call !return (assoc errors (list "Must specify one of from_case_indices or from_values, not both.") ))

			(and (> size_to_cases 0) (> size_to_values 0) )
			(call !return (assoc errors (list "Must specify one of to_case_indices or to_values, not both.") ))

			(and (> size_from_values 1) (> size_to_cases 1) (!= size_from_values size_to_cases ) )
			(call !return (assoc errors (list "from_values and to_case_indices must be the same length or of length of 1.") ))

			(and (> size_from_values 1) (> size_to_values 1) (!= size_from_values size_to_values ) )
			(call !return (assoc errors (list "from_values and to_values must be the same length or of length of 1.") ))

			(and (> size_from_cases 1) (> size_to_cases 1) (!= size_from_cases size_to_cases ) )
			(call !return (assoc errors (list "from_case_indices and to_case_indices must be the same length or of length of 1.") ))

			(and (> size_from_cases 1) (> size_to_values 1) (!= size_from_cases size_to_values ) )
			(call !return (assoc errors (list "from_case_indices and to_values must be the same length or of length of 1.") ))

			(= 0 size_from_values size_from_cases)
			(call !return (assoc errors (list "Must specify either from_case_indices or from_values.") ))

			(= 0 size_to_values size_to_cases)
			(call !return (assoc errors (list "Must specify either to_case_indices or to_values.") ))

			;else inputs are valid
			(call !return (assoc
				payload
					(call_entity trainee "PairwiseDistances" (assoc
						features features
						action_feature action_feature
						from_values from_values
						to_values to_values
						from_case_indices from_case_indices
						to_case_indices to_case_indices
						weight_feature weight_feature
						use_case_weights use_case_weights
					))
			))
		)
	)


	;Returns an assoc with case distances, containing a list of case session indices and a list of lists (matrix) of the computed distances.
	; {
	;   'column_case_indices' : [ session-indices ],
	;	'row_case_indices' : [ session-indices ],
	;	'distances': [ [ pairwise distances ] ]
	; }
	;
	;parameters:
	; features: optional, which features to use when computing case distances. If unspecified uses all features.
	; feature_values: optional, if specified, returns case distances of the local model relative to these values, ignores case_indices parameter.
	; action_feature: optional, if specified, uses targeted hyperparameters used to predict this action_feature, otherwise uses targetless hyperparameters.
	; case_indices: optional, list of pair (list) of session id and index, where index is the original 0-based session_training_index of the case as it was
	;	   trained. If specified, returns pairwise distances for all of these cases. Ignored if feature_values is provided. If neither feature_values nor
	;		case_indices is specified, runs on the full dataset.
	; column_offset: optional, starting column index of the full matrix of cases for which to compute distances. default value is 0
	; column_count: optional, number of columns to compute in the matrix.  If unspecified, is set to the same number as all the cases.
	; row_offset: optional, starting row index of the full matrix of cases for which to compute distances. default value is 0
	; row_count: optional, number of rows to compute in the matrix.  If unspecified, is set to the same number as all the cases.
	; weight_feature: optional, default '.case_weight'.  name of feature whose values to use as case weights
	; use_case_weights: optional flag, if set to true will scale influence weights by each case's weight_feature weight
	#distances
		(declare
			(assoc
				features (null)
				feature_values (null)
				action_feature (null)
				case_indices (null)
				weight_feature ".case_weight"
				use_case_weights (false)
				column_offset 0
				row_offset 0
				column_count (null)
				row_count (null)
			)

			(if (and feature_values features (!= (size features) (size feature_values)))
				(call !return (assoc
					errors (list "Specified features must be of same length as feature_values.")
				))

				(and (!= (null) case_indices) (<= (size case_indices) 1) )
				(call !return (assoc
					errors (list "If providing case_indices, must provide at least 2 cases for computation.")
				))

				;else inputs are valid
				(call !return (assoc
					payload
						(call_entity trainee "Distances" (assoc
							features features
							feature_values feature_values
							action_feature action_feature
							case_indices case_indices
							column_offset column_offset
							row_offset row_offset
							column_count column_count
							row_count row_count
							weight_feature weight_feature
							use_case_weights use_case_weights
						))
				))
			)

		)

	;reset trainee hyperparameters and thresholds while leaving feature definitions
	#reset_parameter_defaults
		(seq
			(call_entity trainee "ResetParameterDefaults")
			(call !return)
		)


	;export trainee's metadata, case and session data into json files.
	;this method should be run by a script from the ./migrations folder
	;
	;parameters:
	; trainee: name of trainee
	; decode_cases: flag, default false. if true will decode (e.g., convert from epoch to datetime) any encoded feature values
	;				when exporting cases If false case feature values will be exported just as they are stored in the trainee
	; root_filepath: base path to Howso Engine Core installation
	; trainee_filepath: optional, base path from which to load persisted trainee
	; separate_files: optional flag, if true will load each case from its individual file
	#export_trainee
		(declare
			(assoc decode_cases (false) )

			(declare (assoc trainee_is_loaded (contains_value (contained_entities) trainee) ))
			(declare (assoc
				loaded_successfully_id
					(if (not trainee_is_loaded)
						(get (call load (assoc filename trainee filepath trainee_filepath)) (list "payload" "name"))
						;else trainee is already loaded, output is same as a succssfull load
						trainee
					)
				migration_filepath (concat root_filepath !migration_folder)
			))

			(if (!= trainee loaded_successfully_id)
				(conclude
					(call !return (assoc errors (list "Failed to load trainee: invalid filepath or filename provided.") ))
				)
			)

			(call !export_trainee_metadata (assoc trainee trainee migration_filepath migration_filepath))

			(if decode_cases
				(call !export_cases_and_sessions_decoded (assoc trainee trainee migration_filepath migration_filepath))

				(call !export_cases_and_sessions (assoc trainee trainee migration_filepath migration_filepath))
			)

			;if trainee wasn't loaded to begin with, unload it from memory
			(if (not trainee_is_loaded) (destroy_entities trainee))

			(call !return)
		)


	;update version to latest and overwrite persisted trainee, auto importing any exported data.
	;this method should be run by a script from the ./upgrade_migration folder
	;
	;parameters:
	; trainee: name of trainee to import and update
	; root_filepath: base path to Howso Engine Core installation
	; trainee_filepath: optional, base path from which to load persisted trainee
	; separate_files: optional flag, if true will load each case from its individual file
	#upgrade_trainee
		(seq
			(declare (assoc
				;metadata json should be in the format of: { label : value }
				import_metadata_map (load (concat root_filepath !migration_folder trainee ".meta.json") )
				;cases and sessions json should be in the format of: { entity_id : { feature : value } }
				import_cases_and_sessions_map (load (concat root_filepath !migration_folder  trainee ".exp.json") )
				trainee_is_loaded (contains_value (contained_entities) trainee)
			))

			(declare (assoc
				loaded_successfully_id
					(if (not trainee_is_loaded)
						;don't need to load existing trainee if are going to be importing all exportable data
						(if (and (!= (null) import_metadata_map) (!= (null) import_cases_and_sessions_map) )
							(get (call create_trainee (assoc filepath root_filepath)) (list "payload" "name"))

							(get (call load (assoc filename trainee filepath trainee_filepath)) (list "payload" "name"))
						)
						;else trainee is already loaded, output is same as a succssfull load
						trainee
					)
			))

			(if (!= trainee loaded_successfully_id)
				(conclude
					(call !return (assoc errors (list "Failed to load trainee: invalid filepath or filename provided") ))
				)
			)

			;run the update
			(declare (assoc
				output
					(call !update_trainee_code (assoc
						trainee trainee
						root_filepath root_filepath
						import_metadata_map import_metadata_map
						import_cases_and_sessions_map import_cases_and_sessions_map
					))
			))

			(if (= (null) output)
				(conclude
					(call !return (assoc errors (list "Failed to instantiate trainee: check permissions and validate installation.") ))
				)
			)

			;save the updated trainee
			(call save (assoc trainee trainee filename trainee filepath trainee_filepath))

			;print statement for use in utiility scripts: upgrade_trainee and export_trainee
			(print
				"Updated " trainee " to version: "
				(retrieve_from_entity trainee "majorVersion") "."
				(retrieve_from_entity trainee "minorVersion") "."
				(retrieve_from_entity trainee "pointVersion")
				"\n"
			)

			;if trainee wasn't loaded to begin with, unload it from memory
			(if (not trainee_is_loaded) (destroy_entities trainee))

			(call !return)
		)


	;returns a structure containing all of the API details for this module
	#get_api
		(seq
			(declare (assoc
				api
					(assoc
						"description"
						(get_entity_comments)

						"labels"
						(map
							(lambda
								(assoc
									"description" (current_value 1)
									"parameters" (get_entity_comments (null) (current_index 1) (true))
								)
							)
							(get_entity_comments (null) (null) (true))
						)
					)
			))

			;output api with all 'breeding' labels removed
			(call !return (assoc
				payload
					(set api "labels"
						(remove (get api "labels") (list "initialize_breeding" "breeder_load_point"))
					)
			))
		)

	;returns the trainee's revision
	#get_revision
		(call !return (assoc payload (assoc "count" (retrieve_from_entity trainee "revision")) ))


	;applies custom code to every case and returns the results
	;  parameters:
	;	features_to_code_map: assoc of feature names to custom code
	;	aggregation_code: custom code to aggregrate the results from using
	;					   features_to_code_map
	#evaluate
		(declare
			(assoc
				features_to_code_map (null)
				aggregation_code (null)
			)

			(if (= (null) features_to_code_map)
				(conclude
					(call !return (assoc errors (list "features_to_code_map must be specified.")))
				)
			)

			(declare (assoc
				output
					(call_entity trainee "Evaluate" (assoc
						features_to_code_map features_to_code_map
						aggregation_code aggregation_code
					))
			))
			(call !return (assoc payload output))
		)

	; -----------------------------------------------------------------------------
	; labels below are used internally and should NOT be referenced by outside  API calls
	; -----------------------------------------------------------------------------

	#!migration_folder "migrations/"

	;set the private label !file_extension during deployment and clear out this method so that the file extension cannot be edited after deployment.
	;This should be run once by the deployment script.
	#initialize_for_deployment
		(declare
			(assoc file_extension "caml")
			(assign_to_entities (assoc !file_extension file_extension ))

			;clear out this label so that it can't be run again
			(assign_to_entities (assoc initialize (null)))
		)

	;loads the breeding framework so it can be called and sets up a manifest such that it can keep track of entity evaluations for breeding
	#initialize_breeding
		(seq
			(direct_assign_to_entities (assoc breeder_load_point (load (concat filepath "breeder" "." !file_extension))))
			(call "initialize_population_manifest")

			;evaluate to indicate it worked
			(!= breeder_load_point (null))
		)

	;label from which to load the breeder code into so that its labels can be loaded
	#breeder_load_point (null)

	;internal label for GP entities
	#!breeder_manifest "_breeder_manifest"

	;default value to use for filepath when calling save or load
	#filepath "./"

	;location of Howso Engine Core and trainee_template files, used for upgrading trainees (referencing
	#root_filepath "./"

	;default value to use for filename when calling save or load
	#filename "default_trainee"

	;location of trainee template
	#!trainee_template_filename "trainee_template"

	;current trainee being processed
	#trainee "TestTrainee"

	;valid extensions are:
	; amlg : raw amalgam code
	; caml : compressed amalgam, binary format
	#!file_extension "amlg"

	;debug value, if set to something other than 0 will parse debug prints when a trainee is created
	#debug_print 0


	;helper method to validate specified batch react parameters are either length of num_reacts or 1
	; if the aren't, sets the variable invalid_react_parameters to (true)
	#!validate_batch_react_parameter
		(if (and
				(> (size param) 0)
				(!= 1 (size param))
				(!= num_reacts (size param))
			)
			(assign (assoc invalid_react_parameters (true)))
		)


	;Method to update a trainee by overwriting its data and running all version dependent migration scripts.
	;
	;parameters:
	; trainee: name of trainee
	; root_filepath: base path to Howso Engine Core installation
	; import_metadata_map: optional imported metadata map, if one existed for this trainee
	; import_cases_and_sessions_map: optional imported cases and sessions map, if one existed for this trainee
	#!update_trainee_code
		(seq
			(declare (assoc temptrainee (concat "_temptrainee" (rand)) ))
			(load_entity (concat root_filepath !trainee_template_filename "." !file_extension) temptrainee (false) (false))

			;this can only happen if the trainee_template file fails to load, meaning probably a bad installation
			(if (not (contains_entity temptrainee))
				(conclude (null))
			)

			(call_entity temptrainee "Initialize")

			(declare (assoc
				old_major_version (retrieve_from_entity trainee "majorVersion")
				old_minor_version (retrieve_from_entity trainee "minorVersion")
				old_point_version (retrieve_from_entity trainee "pointVersion")
				imported_metadata (false)
			))

			;if not importing metadata from saved file, then copy it from the persisted trainee
			(if (= (null) import_metadata_map)
				(let
					(assoc
						;create a list of all the matadata labels
						labels_to_keep (indices (first (retrieve_from_entity temptrainee "InitializeValues")))
						old_labels (indices (first (retrieve_from_entity trainee "InitializeValues")))
					)

					;keep only those that are in the old trainee
					(assign (assoc
						labels_to_keep (filter (lambda (contains_label trainee (current_value))) labels_to_keep)

						;set import_metadata_map to values from the old trainee
						import_metadata_map (zip old_labels (retrieve_from_entity trainee old_labels) )
					))

					;for each label pull its value from the old trainee and overwrite it in the new one
					(assign_to_entities temptrainee (zip labels_to_keep (retrieve_from_entity trainee labels_to_keep)))
				)

				;else overwrite old version from exported file instead of from trainee
				(assign (assoc
					imported_metadata (true)
					old_major_version (get import_metadata_map "majorVersion")
					old_minor_version (get import_metadata_map "minorVersion")
					old_point_version (get import_metadata_map "pointVersion")
				))
			)

			;overwrite trainee code with the new code, this does not overwrite contained entities (cases, sessions),
			;but does overwrite all labels including versions with new ones
			(assign_entity_roots trainee (retrieve_entity_root temptrainee))

			;import cases and sessions from saved json and re-create them in the trainee
			(if import_cases_and_sessions_map
				;iterate over all the entities and re-create them as contained entities with corresponding features and values
				(map
					(lambda
						(create_entities
							(list trainee (current_index 1))
							(set_type
								(zip_labels
									(indices (current_value))
									(values (current_value))
								)
								(null)
							)
						)
					)
					import_cases_and_sessions_map
				)
			)

			;import metadata into trainee from exported file
			(if imported_metadata
				;store data_map into trainee without the old version information and with parsed code
				(seq
					(assign (assoc
						import_metadata_map
							(set import_metadata_map
								"featureCustomDerivedMethods"
								(parse (get import_metadata_map "featureCustomDerivedMethods"))
							)
					))
					(assign_to_entities trainee (remove import_metadata_map (list "majorVersion" "minorVersion" "pointVersion")) )
				)
			)

			;recreate custom derive feature code on trainee if it has derived features
			(call !recreate_feature_custom_derived_methods (assoc trainee trainee))

			(declare (assoc migration_filepath (concat root_filepath !migration_folder) ))

			;perform all custom version-based conversions on metadata/cases/sessions here now that they are stored in the trainee
			(declare (assoc migration_conversions (load (concat migration_filepath "migrations" "." !file_extension))))

			;filter out all script versions older than the version of the trainee being upgraded
			(declare (assoc
				migration_versions
					(filter
						(lambda (let
							(assoc
								file_versions (split (current_value 1) "\\.")
								major 0
								minor 0
								point 0
							)
							(assign (assoc
								major (first file_versions)
								minor (get file_versions 1)
								point (last file_versions)
							))

							;keep files with newer major version. if major is same, consider minor version, etc.
							(if (> major old_major_version)
								(true)

								;filter out older major versions
								(< major old_major_version)
								(false)

								(> minor old_minor_version)
								(true)

								;major is same, filter out older minor versions
								(< minor old_minor_version)
								(false)

								(> point old_point_version)
								(true)

								;else filter out any version that is same or older
								(false)
							)
						))
						(sort (indices (first migration_conversions)))
					)
			))

			;execute all the necessary conversion scripts in ascending version order
			(map
				(lambda (call (get (first migration_conversions) (current_value))))
				migration_versions
			)

			(accum_to_entities trainee (assoc revision 1))
			(destroy_entities temptrainee)

			;output true on success
			(true)
		)


	;Export trainee metadata in json format as a dict of: { label : value }
	;
	;parameters:
	; trainee: name of trainee, reference for filename
	; migration_filepath: path to migration folder where migration scripts are stored
	#!export_trainee_metadata
		(declare
			(assoc
				meta_labels_to_persist (indices (get (retrieve_from_entity trainee "InitializeValues")  0))
				meta_values_to_persist (list)
			)

			(assign (assoc
				meta_values_to_persist
					(map
						(lambda
							;code needs to be stored as a string
							(if (= "featureCustomDerivedMethods" (current_value))
								(unparse (retrieve_from_entity trainee (current_value)))

								(retrieve_from_entity trainee (current_value))
							)

						)
						meta_labels_to_persist
					)
			))

			;ensure the version of the trainee is exported along with the data
			(accum (assoc
				 meta_values_to_persist (retrieve_from_entity trainee (list "majorVersion" "minorVersion" "pointVersion"))
				 meta_labels_to_persist (list "majorVersion" "minorVersion" "pointVersion")
			))

			(store
				(concat migration_filepath trainee ".meta.json")
				(zip meta_labels_to_persist meta_values_to_persist)
			)
		)


	;Export entities in json format as they are currently stored in the trainee
	;as dict of:  { entity_id : { feature : value } }
	;
	;parameters:
	; trainee: name of trainee, reference for filename
	; migration_filepath: path to migration folder where migration scripts are stored
	#!export_cases_and_sessions
		(store
			(concat migration_filepath trainee ".exp.json")
			(map
				(lambda
					(get_all_labels
						(retrieve_entity_root (list trainee (current_index 1)) (true))
					)
				)
				(zip (contained_entities trainee))
			)
		)


	;Export entities in json format, keeping all original case values as they were trained,
	;instead of whatever they are encoded internally.
	;as dict of:  { entity_id : { feature : value } }
	;Decode nominal encoding, round and convert from epoch back to correct datetime formats as necessary
	;
	;parameters:
	; trainee: name of trainee, reference for filename
	; migration_filepath: path to migration folder where migration scripts are stored
	#!export_cases_and_sessions_decoded
		(seq

			(declare (assoc
				has_encoded_features (retrieve_from_entity trainee "hasEncodedFeatures")
				has_rounded_features (retrieve_from_entity trainee "hasRoundedFeatures")
				has_datetime_features (retrieve_from_entity trainee "hasDateTimeFeatures")
			))

			;if there are no encoded features, run the raw ExportCasesAndSessions call
			(if (= (false) has_encoded_features has_rounded_features has_datetime_features)
				(conclude (call !export_cases_and_sessions))
			)

			(store
				(concat migration_filepath trainee ".exp.json")
				(map
					(lambda (let
						(assoc
							;assoc of feature -> feature value
							entity_code_map	(get_all_labels (retrieve_entity_root (list trainee (current_index 2)) (true)) )
						)

						;"case" entity has a label named ".session", decode values as needed
						(if (contains_index entity_code_map ".session")
							(zip
								(indices entity_code_map)
								;decode the values accordingly
								(if has_encoded_features
									(call_entity trainee "ConvertToOutput" (assoc
										features (indices entity_code_map)
										feature_values (values entity_code_map)
										has_rounded_features has_rounded_features
										has_datetime_features has_datetime_features
									))

									has_rounded_features
									(call_entity trainee "RoundContinuousFeatures" (assoc
										features (indices entity_code_map)
										feature_values (values entity_code_map)
									))
								)
							)

							;else non-case entity, output as-is
							entity_code_map
						)
					))
					(zip (contained_entities trainee))
				)
			)
		)


	;Method to re-create the featureCustomDerivedMethods label from attributes for a trainee, used when upgrading a trainee
	#!recreate_feature_custom_derived_methods
		(let
			(assoc
				custom_derived_features_map
					(filter
						(lambda (or
							(!= (null) (get (current_value) "auto_derive_on_train"))
							(!= (null) (get (current_value) "derived_feature_code"))
						))
						(retrieve_from_entity trainee "featureAttributes")
					)
			)

			;only if there are derived features
			(if (size custom_derived_features_map)
				(let
					(assoc
						;filter features, leaving only those with custom derivations
						custom_derived_features_map
							(filter
								(lambda (or
									(= "custom" (get (current_value) (list "auto_derive_on_train" "derive_type")))
									(!= (null) (get (current_value) "derived_feature_code"))
								))
								custom_derived_features_map
							)
					)

					;cache all the custom specified derivation code into trainee
					(assign_to_entities trainee (assoc
						featureCustomDerivedMethods
							(call_entity trainee "ComposeCustomDerivedMethods" (assoc
								custom_derived_features_map custom_derived_features_map
							))
					))
				)
			)
		)


	;method that rewrites the trainee code such that any comments that start with '^^^' are parsed as code to print out debug info
	#!parse_debug_print
		(seq
			(assign_entity_roots trainee
				(rewrite
					(lambda
						(let
							(assoc
								comments (get_comments (current_value 1))
								;list to hold indivdiual lines of 'debug' comments that should be parsed as code
								debug_code (list)
							)
							(if (!= (null) comments)
								(let
									(assoc chars (explode comments))
									(declare (assoc
										carriage_indices (filter (lambda (= (get chars (current_value)) "\r")) (indices chars))
										prev_index 0
									))
									(accum (assoc carriage_indices (size chars)))

									(declare (assoc
										individual_comment_lines
											(map
												(lambda
													(let
														(assoc line (apply "concat" (unzip chars (range prev_index (- (current_value 1) 1)))))
														;adjust for "\r\n"
														(assign (assoc prev_index (+ 2 (current_value 1))))
														line
													)
												)
												carriage_indices
											)
									))

									(map
										(lambda
											;if comment starts with ^^^, parse it as code
											(if (= "^^^" (trunc (current_value) 3))
												(accum (assoc debug_code (tail (current_value 1) (- (size (current_value 1)) 3)  )))
											)
										)
										individual_comment_lines
									)
								)
							)

							(set_labels
								;if there is debug code, pre-pend it above its code block, and then change from 'list' to 'seq' to
								;ensure that the original code block isn't encompassed in a list
								(if (size debug_code)
									(set_type
										(append
											(map
												(lambda (parse (current_value)))
												debug_code
											)
											(get_value (current_value))
										)
										"seq"
									)

									;else just output the code
									(get_value (current_value))
								)

								(get_labels (current_value))
							)
						)
					)
					(retrieve_entity_root trainee 1)
				)
			)
			(assign_to_entities trainee (assoc debug_print debug_print ))
		)


	;create a return response object in the format of:
	; {
	;	'status' : 'ok', # string 'ok' or 'error'
	;	'errors' : [ {'detail': 'Some error message'} ], # list of error dicts
	;	'warnings' : [ {'detail': 'Some warning message'} ], # list of warning dicts
	;	'payload' : whatever # json response payload
	; }
	;
	;parameters:
	; errors: optional, list of error strings to output
	; warnings: optional, list of warning strings to output
	; payload: any value or object
	#!return
		(if errors
			(assoc "status" "error"	"errors" (map (lambda (assoc "detail" (current_value 1))) errors) "warnings" (null)	"payload" payload)

			warnings
			(assoc "status" "ok"	"errors" (null) "warnings" (map (lambda (assoc "detail" (current_value 1))) warnings) "payload" payload)

			(assoc "status" "ok"	"errors" (null)	"warnings" (null) 	"payload" payload)
		)
)
