(null
	;Since all cases are expected for a series to be trained together as a group, this checks if there are any
	;cases from one series that are between cases of another series. If it finds a case that is not grouped
	;together with others of its series, this method will return true.
	#!DoesDataNeedGroupingById
	(declare
		(assoc
			data []
			id_indices [0]
		)

		(declare (assoc
			one_id (= 1 (size id_indices))
			id_index (first id_indices)
			needs_grouping (false)
		))

		;This flow creates a set of all unique ids, then iterates over all cases, looking at each case's id
		;if a different id is encountered it is removed from that unique set
		;if an id that has already been removed from the set is encountered again,
		;that means the case is out of order and the data needs to be grouped
		(if one_id
			(let
				(assoc
					unique_ids_set
						(zip (map
							(lambda (get (current_value) id_index) )
							data
						))
					previous_id (null)
				)

				(while (< (current_index) (size data))
					;first row sets previous_id and unique_ids_set into (previous_result)
					(if (= 0 (current_index))
						(seq
							(assign (assoc
								previous_id (get data [(current_index 2) id_index])
							))
							(remove unique_ids_set previous_id)
						)

						;if the current id doesn't match previous_id, check to see if it has
						;already been encountered. if so, the data is out of order
						(!= previous_id (get data [(current_index 1) id_index]))
						(seq
							(assign (assoc
								previous_id (get data [(current_index 2) id_index])
							))

							;new ids should still be in unique_ids_set, but if they are not they've been encountered before
							(if (not (contains_index (previous_result 0 (true)) previous_id))
								(conclude (conclude
									(assign (assoc needs_grouping (true) ))
								))
							)

							;id has not been encountered before, remove it from unique_ids_set
							(remove (previous_result) previous_id)
						)

						;else no change to unique_ids_set
						(previous_result)
					)
				)
			)

			;else multiple ids, less efficient
			(let
				(assoc
					unique_ids_list
						(values
							(map (lambda (unzip (current_value) id_indices)) data)
							(true)
						)
					previous_ids []
				)

				(while (< (current_index) (size data))
					;first row sets previous_id and unique_ids_list into (previous_result)
					(if (= 0 (current_index))
						(seq
							(assign (assoc
								previous_ids (unzip (get data (current_index 1)) id_indices)
							))
							(filter
								(lambda (!= (current_value) previous_ids))
								unique_ids_list
							)
						)

						;if the current ids don't match previous_ids, check to see if they have
						;already been encountered. if so, the data is out of order
						(!= previous_ids (unzip (get data (current_index)) id_indices) )
						(seq
							(assign (assoc
								previous_ids (unzip (get data (current_index 1)) id_indices)
							))

							;new ids should still be in unique_ids_list, but if they are not they've been encountered before
							(if (not (contains_value (previous_result 0 (true)) previous_ids))
								(conclude (conclude
									(assign (assoc needs_grouping (true) ))
								))
							)

							;id has not been encountered before, remove it from unique_ids_list
							(filter
								(lambda (!= (current_value) previous_ids))
								(previous_result)
							)
						)

						;else no change to unique_ids_list
						(previous_result)
					)
				)
			)
		)

		;output true if data needs grouping
		needs_grouping
	)


	;helper method
	;outputs a sorted list of cases where any case for a specific series that was among cases of a different series,
	;will be moved to be together among other cases of its own series, while maintaining the original order of different series
	;e.g., if these are series IDS of cases: A A A B A A B B C B C C C the result would be: A A A A A B B B B C C C C
	#!GroupDataByIds
	(seq
		(declare (assoc
			unique_ids_list
				(values
					(map (lambda (unzip (current_value) id_indices)) cases)
					(true)
				)
		))

		(apply "append"
			(map
				(lambda (let
					(assoc ids (current_value 1))
					(filter
						(lambda (= ids (unzip (current_value) id_indices)))
						cases
					)
				))
				unique_ids_list
			)
		)
	)

	#!TrainTimeSeriesAblation
	(seq
		(declare (assoc
			feature_index_map (zip features (indices features))
		))

		(declare (assoc
			lag_features
				(filter
					(lambda (and
						(= "lag"  (get !featureAttributes [ (current_value 1) "ts_type"]) )
						(= "custom" (get !featureAttributes [ (current_value 1) "auto_derive_on_train" "derive_type"]) )
					))
					derived_features
				)
			progress_features
				(if !tsTimeFeatureUniversal
					[".series_index" ".reverse_series_index" ".time_to_horizon"]
					[".series_index" ".reverse_series_index"]
				)
			ts_series_length_limit (retrieve_from_entity "!tsSeriesLimitLength")
			time_feature_index (get feature_index_map !tsTimeFeature)
			id_features (get !tsFeaturesMap "series_id_features")
			id_indices (unzip feature_index_map (get !tsFeaturesMap "series_id_features"))
			original_features (replace features)
			max_time_value
				(get
					(first (compute_on_contained_entities
						(query_max !tsTimeFeature)
						(query_exists !tsTimeFeature)
					))
					!tsTimeFeature
				)
		))
		(declare (assoc
			series_id_features (get !tsFeaturesMap "series_id_features")
			series_ordered_by_features [!tsTimeFeature !internalLabelSessionTrainingIndex]
			;check if the incoming cases are group sorted by series_id
			needs_grouping
				(call !DoesDataNeedGroupingById (assoc
					data cases
					id_indices id_indices
				))
		))

		;set last column to be the original index of the cases
		(assign (assoc
			cases (map (lambda (append (current_value) (current_index))) cases)
			features (append features ".original_index")
			feature_index_map (append feature_index_map { ".original_index" (size feature_index_map)} )
		))

		;if the cases aren't ordered together by series ids, shuffle them around so they are grouped by ids
		(if needs_grouping
			(assign (assoc cases (call !GroupDataByIds) ))
		)

		;the non-lag 'custom' derivation type features below
		(assign (assoc
			derived_features
				(filter
					(lambda
						(and
							(not (contains_value lag_features (current_value)))
							(= "custom" (get !featureAttributes [(current_value 1) "auto_derive_on_train" "derive_type"]) )
						)
					)
					derived_features
				)
		))

		(if encode_features_on_train
			(assign (assoc
				cases
					(map
						(lambda
							(call !ConvertFromInput (assoc
								feature_values (current_value 1)
								features features
							))
						)
						cases
					)
			))
		)

		(declare (assoc
			previous_ids []
			start_index 0
			end_index 0
			num_rows (size cases)
			output_case_ids []
			;map of sorted case index -> original case index used to lookup which original rows were ablated after data is sorted
			ts_ablated_indices_map (null)
			;series which received new cases that occurred before the last trained case of the series
			out_of_sequence_series_ids []
		))

		(while (< (current_index) num_rows)
			(if (= 0 (current_index))
				(assign (assoc previous_ids (unzip (get cases (current_index 1)) id_indices) ))
			)

			;encountering next id or at end of all cases, train on the previous list of cases
			(if
				(or
					(!= previous_ids (unzip (get cases (current_index)) id_indices) )
					(= (current_index) (- num_rows 1))
				)
				(let
					(assoc
						end_index
							;if last index, should be as-is
							(if (= (current_index 1) (- num_rows 1))
								(current_index 1)
								(- (current_index 1) 1)
							)
						features original_features
						features_indices (indices original_features)
					)

					;train one entire series at a time
					(accum (assoc
						output_case_ids
							(call !TrainSingleSeriesWithAblation (assoc
								data (unzip cases (range start_index end_index))
							))
					))

					(assign (assoc
						previous_ids (unzip (get cases (current_index 1)) id_indices)
						start_index (current_index 1)
					))
				)
			)
		)

		;remove the temporary features
		(assign (assoc features original_features))

		;warn when there are out of sequence new cases
		(if (size out_of_sequence_series_ids)
			(accum (assoc
				warnings
					(associate (concat
						"Training time series cases out of sequence with ablation enabled is not supported and may "
						"cause unexpected results. The following series received out of sequence cases: "
						(apply "concat" (trunc (weave out_of_sequence_series_ids ", ")) )
					))
			))
		)

		;return trained case_ids
		output_case_ids
	)

	;derive then train with ablation
	#!TrainSingleSeriesWithAblation
	(seq

		(declare (assoc
			;series_index of each row, will be set to be non-zero if some series cases were already trained previously
			continue_series_index 0
			id_values (unzip (first data) id_indices)
			untrained_data_size (size data)
		))

		;check if this series has already been trained, if so, pull those cases and prepend to these
		(declare (assoc
			trained_series_case_ids
				(contained_entities
					(apply "append"
						(map
							(lambda
								[(query_equals
									(current_value 1)
									(if (contains_index !numericNominalFeaturesMap (current_value 1))
										(+ (get id_values (current_index 1)))
										(get id_values (current_index 1))
									)
								)]
							)
							id_features
						)
					)
				)
			trained_series_cases_features (append features [".series_index" ".case_id"])
			;cases with the same series id that are already trained
			trained_series_cases []
			;indices of trained cases in the sorted combined data
			trained_case_indices []
			;indices of nulls for previously ablated cases in the sorted combined data
			trained_ablated_indices []
			last_trained_time_value (null)
		))

		;if previously trained series cases exist for this series, prepend them to data
		(if (size trained_series_case_ids)
			(let
				(assoc
					;last seen series index (for finding ablated cases to insert nulls)
					prev_series_index (null)
					;row index for existing cases
					next_series_row 0
					;series_index index in trained_series_cases
					series_index_feature_index (- (size trained_series_cases_features) 2)
					;case_id index in trained_series_cases
					case_id_feature_index (- (size trained_series_cases_features) 1)
				)

				;set trained_series_cases to contain each cases's feature values, series index, and case id
				(assign (assoc
					trained_series_cases
						(map
							(lambda
								;NOTE: columns here must match trained_series_cases_features
								(append
									(retrieve_from_entity (current_value) (append features ".series_index") )
									(current_value)
								)
							)
							trained_series_case_ids
						)
				))

				;combine and sort the new cases with existing cases
				(assign (assoc
					data
						(call !MultiSortList (assoc
							data (append trained_series_cases data)
							column_order_indices
								(if (size series_ordered_by_features)
									(unzip feature_index_map series_ordered_by_features)
									[ time_feature_index ]
								)
						))
				))

				(assign (assoc
					;determine the last time value so we can verify new cases occur after this
					last_trained_time_value
						(apply "max" (map
							(lambda (get (current_value) time_feature_index))
							trained_series_cases
						))
					;set continue_series_index to the would-be next index value
					continue_series_index
						(+
							1
							(apply "max" (map
								(lambda (get (current_value) series_index_feature_index))
								trained_series_cases
							))
						)
					;using sorted data we need to map index -> original_index where the index is the
					;index in a list of *only* the new cases
					ts_ablated_indices_map
						(zip
							(range 0 (- (size data) (size trained_series_cases) 1) 1)
							(filter (map
								(lambda
									(if (!= (size (current_value)) (size trained_series_cases_features))
										(last (current_value))
									)
								)
								data
							))
						)
				))

				;previously trained series was ablated because the number of cases is less than the continue series index
				(if (< (size trained_series_cases) continue_series_index)
					(assign (assoc
						data
							;fill previously ablated cases with nulls
							(range
								(lambda (let
									(assoc
										series_index (get data [next_series_row series_index_feature_index])
										current_row (get data next_series_row)
									)
									(if (!= (size current_row) (size trained_series_cases_features))
										;output the new case
										(seq
											(accum (assoc next_series_row 1))
											;return the new case
											current_row
										)

										;else if the first series index we encounter is > 0 we need to add nulls to the start
										(and (= (null) prev_series_index) (> series_index 0))
										(seq
											(assign (assoc prev_series_index 0))
											;return null
											(null)
										)

										;else if there is a gap since the last series index, output null
										(> (- series_index prev_series_index) 1)
										(seq
											(accum (assoc prev_series_index 1))
											;return null
											(null)
										)

										;else output the existing case
										(seq
											(assign (assoc
												next_series_row (+ next_series_row 1)
												prev_series_index series_index
											))
											;return the existing case
											current_row
										)
									)
								))
								0 (+ continue_series_index untrained_data_size -1) 1
							)
					))
				)

				(assign (assoc
					;get updated order of case ids
					trained_series_case_ids
						(filter (map
							(lambda
								(if (= (size (current_value)) (size trained_series_cases_features))
									(get (current_value) case_id_feature_index)
								)
							)
							data
						))
					;get the indices of the trained cases so they can be removed later
					trained_case_indices
						(filter
							(lambda (=
								(size (get data (current_value)))
								(size trained_series_cases_features)
							))
							(indices data)
						)
					;get the indices of the ablated cases so they can be removed later
					trained_ablated_indices
						(filter
							(lambda (= (null) (get data (current_value))))
							(indices data)
						)
				))
			)

			;else if no existing trained cases
			(seq
				;sort the data by time
				(assign (assoc
					data
						(call !MultiSortList (assoc
							data data
							column_order_indices
								(if (size series_ordered_by_features)
									(unzip feature_index_map series_ordered_by_features)
									[ time_feature_index ]
								)
						))
				))

				;map of index -> original index
				(assign (assoc
					ts_ablated_indices_map
						(zip
							(indices data)
							(map (lambda (last (current_value))) data)
						)
				))
			)
		)

		;drop extra temporary columns from data
		(assign (assoc
			data
				(map
					(lambda
						(if (= (null) (current_value))
							(map (null) features_indices) ;ablated case
							(unzip (current_value) features_indices)
						)
					)
					data
				)
		))

		;now that the length of each new series is known, ensure that ts_series_length_limit is e*(longest series)
		(if (> (* 2.718281828459 (size data)) ts_series_length_limit)
			(assign (assoc ts_series_length_limit (* 2.718281828459 (size data)) ))
		)
		;if ts_series_length_limit has been been updated to a larger value in the loop above, update the dataset with this new value
		(if (and (not read_only_mode) (> ts_series_length_limit !tsSeriesLimitLength))
			(assign_to_entities (assoc !tsSeriesLimitLength ts_series_length_limit ))
		)

		;derive lag features and append to data
		(call !DeriveLagFeaturesForData)

		;derive custom code features
		(call !DeriveCustomFeaturesForData)

		;derive progress features
		(declare (assoc
			derived_progress_values_lists (call !DeriveProgressFeaturesForData)
		))

		;append all the progress values to data
		(assign (assoc
			features (append features progress_features )
			data
				(map
					(lambda (append
						(current_value)
						(get derived_progress_values_lists (current_index))
					))
					data
				)
		))

		(if (size trained_series_case_ids)
			(seq
				;there were existing cases, update their progress values
				(if read_only_mode
					(accum (assoc
						ts_case_edits_map
							(zip
								trained_series_case_ids
								(map
									(lambda
										(zip
											progress_features
											(get derived_progress_values_lists (current_value))
										)
									)
									trained_case_indices
								)
							)
					))

					(map
						(lambda
							(assign_to_entities
								(get trained_series_case_ids (current_index))
								(zip
									progress_features
									(get derived_progress_values_lists (current_value))
								)
							)
						)
						trained_case_indices
					)
				)
				;filter out the already trained cases so we only train the new ones
				(assign (assoc
					data (unzip data (remove (indices data) (append trained_case_indices trained_ablated_indices)))
				))

				;Check if we need to warn about out of sequence cases
				(if
					(and
						(!= (null) last_trained_time_value)
						(< (get (first data) time_feature_index) last_trained_time_value)
					)
					(accum (assoc
						out_of_sequence_series_ids (unzip (first data) id_indices)
					))
				)
			)
		)

		;train and ablate cases and output created case ids
		(call !TrainCasesWithAblation (assoc
			cases data
			;features have already been encoded
			encode_features_on_train (false)
		))
	)

	#!DeriveLagFeaturesForData
	(seq
		(declare (assoc
			derived_lag_values_lists
				(call !AddDerivedIndependentCodeFeatures (assoc
					derived_features lag_features
					features features
					series_data data
				))
		))

		(assign (assoc
			features (append features lag_features)
			data
				(map
					(lambda
						(append (first (current_value)) (last (current_value)))
					)
					data
					derived_lag_values_lists
				)
		))
	)

	;every derived feature must be immediately fed back into data because it may be needed by the next derived feature
	#!DeriveCustomFeaturesForData
	(let
		(assoc
			;compute the maximum order of rate or deltas needed, since higher orders depend on lower ones and need to be derived sequentially
			;e.g., 1st order for a rate feature needs to be derived before the 2nd order rate feature, etc.
			max_order
				(apply "max"
					(map (lambda (get !featureAttributes [(current_value 1) "ts_order"])) derived_features)
				)
			time_feature_delta (concat "." !tsTimeFeature "_delta_1")
		)

		;first explicitly derive time feature delta
		(assign (assoc
			data
				(map
					(lambda
						(append (first (current_value)) (last (current_value)))
					)
					data
					(call !AddDerivedCodeFeature (assoc
						feature time_feature_delta
						features features
						series_data data
					))
				)
		))
		(assign (assoc
			features (append features time_feature_delta)
			derived_features (filter (lambda (!= time_feature_delta (current_value))) derived_features)
		))

		(range
			(lambda (let
				(assoc
					;keep only those features matching this order (current_index 2) value
					derived_order_features
						(filter
							(lambda (= (current_index 2) (get !featureAttributes [(current_value 1) "ts_order"])))
							derived_features
						)
				)
				(assign (assoc
					data
						(map
							(lambda
								(append (first (current_value)) (last (current_value)) )
							)
							data
							(call !AddDerivedIndependentCodeFeatures (assoc
								derived_features derived_order_features
								features features
								series_data data
							))
						)
				))
				(accum (assoc features derived_order_features))
			))
			1 max_order 1
		)
	)


	;all the time values
	#!DeriveProgressFeaturesForData
	(declare
		(assoc
			sorted_time_values (map (lambda (get (current_value) time_feature_index)) data)

			;not param
			is_universal !tsTimeFeatureUniversal
		)

		(declare (assoc time_to_horizon (- max_time_value (last sorted_time_values)) ))

		;output a list of tuples [ series_index, reverse_index, time_to_horizon ] for each row in the data
		(map
			(lambda
				(if is_universal
					[
						(current_index 1)
						(- (size sorted_time_values) 1 (current_index 1))
						time_to_horizon
					]

					[
						(current_index 1)
						(- (size sorted_time_values) 1 (current_index 1))
					]
				)
			)
			sorted_time_values
		)
	)
)