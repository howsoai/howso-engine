;Contains methods to set and get feature attributes.
(null
	;set all features and their attributes for the trainee, and returns the updated feature attributes
	;{idempotent .true}
	#set_feature_attributes
	(declare
		;returns {ref "FeatureAttributesIndex"}
		(assoc
			;{ref "FeatureAttributesIndex" required .true}
			;assoc of feature -> attributes, attributes defined below:
			;
			;	'type': string, one of 'continuous', 'ordinal' or 'nominal'. Default is 'continuous'.
			;
			;	'bounds' : assoc of of bounds for feature value generation, keys of assoc defined below as:
			;		'min': number or date string, the minimum value to be output
			;		'max': number or date string, the maximum value to be output
			;		'allowed': list of explicitly allowed values to be output. Example: ["low", "medium", "high"]
			;		'allow_null': flag, allow nulls to be output, per their distribution in the data. Defaults to true (false for time feature)
			;		'constraint': code, whose logic has to evaluate to true for value to be considered valid.
			;			Same format as 'derived_feature_code'. Example: "(> (call value {feature \"f1\"}) (call value {feature \"f2\"}) )"
			;       'observed_min': number, string, or date string, the minimum value observed in the data
			;       'observed_max': number, string, or date string, the maximum value observed in the data
			;
			;	'cycle_length': integer, specifies cycle length of cyclic feature, default is no cycle length
			;
			;	'date_time_format': string datetime format, only applicable to continuous features. If specified, feature values
			;						should match the date or time format specified by this string and sets 'data_type' to 'formatted_date_time'.
			;						Example: "%Y-%m-%d". If unspecified but 'data_type' is 'formatted_date_time', this will be set to
			;						ISO8601 format of "%Y-%m-%dT%H:%M:%S", if 'data_type' is 'formatted_time', this will be
			;						ISO8601 format of "%H:%M%S".
			;
			;	'locale': string, the date time format locale. If unspecified, uses platform default locale. Example: "en_US"
			;
			;	'default_time_zone': string, the default time zone used for datetimes if a time zone is not specified
			;					explicitly specified in the date_time_format.  Defaults to 'UTC' when unspecified.
			;
			;	'significant_digits': integer, round to the specified significant digits, default is no rounding
			;
			;	'decimal_places': integer, decimal places to round to, default is no rounding. If "significant_digits"
			;					is also specified, the number will be rounded to the specified number of significant
			;					digits first, then rounded to the number of decimal points as specified by this parameter
			;
			;	'observational_error': number, specifies the observational mean absolute error for this feature. Use when the error
			;						value is already known. Default is 0
			;
			;	'data_type': string, specify the data type for features with a type of nominal or continuous
			;				Defaults to 'string' for nominals and 'number' for continuous
			;				Valid values for both are: 'string', 'number', 'json', 'amalgam', 'yaml'
			;				'string_mixable', 'formatted_time' and 'formatted_date_time' are valid only when type is continuous
			;				'boolean' is valid only when type is nominal
			;
			;	'recursive_matching': boolean, only applicable to code features (when 'data_type' is one of json/yaml/amalgam).
			;				If unspecified, defaults to false for 'json' and 'yaml' features and true for 'amalgam' features.
			;				When true, operatations will work recursively on feature values. When false, will operate on positional
			;				matches without considering recursion, which will yield better and faster results if the schema of the
			;				semistructured data is not recursive.
			;
			;	'types_must_match': boolean, defaults to true, applicable to code features (when 'data_type' is one of json/yaml/amalgam).
			;				If true, only considers nodes common if their types match.
			;
			;	'nominal_numbers': boolean, defaults to false, applicable to code features (when 'data_type' is one of json/yaml/amalgam).
			;				If true, will assume that all numbers will match only if identical; if false, it will compare similarity of values.
			;
			;	'nominal_strings': boolean, defaults to true,  applicable to code features (when 'data_type' is one of json/yaml/amalgam).
			;				If true, will assume that all strings will match only if identical;
			;				if false uses string edit distance to compare similarity.
			;
			;	'id_feature': boolean, Set to true only for nominal features containing nominal IDs to specify that this
			;				feature should be used to compute case weights for id based privacy. For time series,
			;				this feature will be used as the id for each time series generation. Default is false
			;
			;	'unique': boolean, flag feature as only having unique values. Only applicable to nominal features. Defaults to false.
			;
			;	'dependent_features': list, a list of other feature(s) that this feature depends on or that are dependent on this
			;                       feature. This restricts the cases that can be selected as neighbors (such as in react) to ones
			;						that satisfy the dependency, if possible. If this is not possible, either due to insufficient data
			;						which satisfy the dependency or because dependencies are probabilistic, the dependency may not be
			;						maintained. Be aware that dependencies introduce further constraints to data and so several
			;						dependencies or dependencies on already constrained datasets may restrict which operations are
			;						possible while maintaining the dependency. As a rule of thumb, sets of features that have
			;						dependency relationships should generally not include more than 1 continuous feature, unless
			;						the continuous features have a small number of values that are commonly used.
			;
			;	'null_is_dependent': boolean, modifies how dependent features with nulls are treated during a react, specifically
			;						when they use null as a context value. Only applicable to dependent features. When false, the
			;						feature will be treated as a non-dependent context feature. When true for nominal types,
			;						treats null as an individual dependent class value, only cases that also have nulls as this
			;						feature's value will be considered. When true for continuous types, if continuous value is null,
			;						only considers cases that also have null for this feature value. Default is false.
			;
			;	'auto_derive_on_train': assoc, defines how to create and derive all the values for this feature from
			;							the trained dataset. For full list of specific 'auto_derive_on_train' feature
			;							attributes refer the comments at the top of the derive_features.amlg module.
			;
			;	'derived_feature_code': string, code defining how the value for this feature could be derived if this feature
			;							is specified as a "derived_context_feature" or a "derived_action_feature" during
			;							react flows. For react_series, the data referenced is the accumulated series data
			;							(as a list of rows), and for non-series reacts, the data is the one single row.
			;							Each row is comprised of all the combined context and action features. Referencing
			;							data in these rows uses 0-based indexing, where the current row index is 0, the
			;							previous row's is 1, etc. Specified code may do simple logic and numeric operations
			;							on feature values referenced via feature name and row offset. Format to get feature
			;							value is: (call value {feature "feature_name" lag lag_value }) where lag and lag_value
			;							are optional and only needed if lag > 0.
			;							Examples:
			;							"(call value {feature \"x\" lag 1})" - Use value for feature 'x' from the previous row (offset of 1, one lag value).
			;							"(- (call value {feature \"y\"})  (call value {feature \"x\" lag 1}) )" - Feature 'y' value from
			;								current (offset 0) row minus feature 'x' value from previous (offset 1) row.
			;
			;							Note: Feature names must be explicitly specified as the 'feature' parameter and not as output from logic.
			;							This example code will not work: "(call value {feature (call value {feature \"another\"}) })" because
			;							the feature name is determined dynamically from the value of 'another' feature and not specified directly.
			;
			;	'post_process': string, custom Amalgam code that is called on resulting values of this feature during react operations.
			;					Same format as 'derived_feature_code'. Example: "(set_digits (call value {feature \"x\"})  3.1 [1 0] 2 3 .false)"
			;
			;	'non_sensitive': boolean, flag a categorical nominal feature as non-sensitive. It is recommended that
			;					all nominal features be represented with either an 'int-id' subtype or another
			;					available nominal subtype using the 'subtype' attribute. However, if the nominal
			;					feature is non-sensitive, setting this parameter to true will bypass the 'subtype'
			;					requirement. Only applicable to nominal features. Default is false
			;
			;	'shared_deviations': list or boolean, The shared deviations feature group. If a list, this feature will share deviations with
			;					the features in this list. By default, derived lag values share deviations with the parent feature. If
			;					false and a parent feature, derived lags of this feature will not share deviations.
			;
			;	'subtype': string, the type used in novel nominal substitution.
			;
			;	'original_type': string, original data type details. Used by clients to determine how to serialize and deserialize feature data.
			;					Note: 'json' features with original_type of 'tokenizable_string' won't be mutated during generative reacts.
			;
			;	'original_format': string, original data formats used by clients. Automatically populated by clients
			;					to store client language specific context about features.
			;
			;	'time_series': assoc, defining time series options for a feature, keys of assoc defined below as:
			;
			;		'type': string, one of "rate", "delta", or "covariate". When 'rate' is specified, uses the difference of the current value
			;				from its previous value divided by the change in time since the previous value.
			;				When 'delta' is specified, uses the difference of the current value from its previous value
			;				regardless of the elapsed time. Set to 'delta' if feature has 'time_feature' set to true.
			;				When `covariate` is specified, temporal changes are not modeled and feature values are directly
			;				predicted with interpolation in series generation rather than derived using a rate or delta.
			;
			;		'time_feature': boolean, When true, the feature will be treated as the time feature for time
			;						series modeling. Additionally, time features must use type 'delta'. Default is false.
			;
			;		'order': integer, if provided, will generate the specified number of derivatives and boundary values. Default is 1
			;
			;		'derived_orders': integer, The number of orders of derivatives that should be derived instead of synthesized.
			;						Ignored if order is not provided. Default is 0.
			;
			;		'lags': list of number, if specified, generates lag features containing previous values using the enumerated lag offsets.
			;				Takes precedence over 'num_lags'. If neither 'num_lags' nor 'lags' is specified for a feature, then a single
			;				lag feature is generated. Example: [1,2]
			;
			;		'num_lags': integer, if specified, generates the specified amount of lag features containing previous values.
			;					If 'lags' is specified, then this parameter will be ignored. If neither 'num_lags' nor 'lags' is specified
			;					for a feature, then a single lag feature is generated. Default is 1.
			;
			;		'rate_min': list of number, if specified, ensures that the rate (the difference quotient, the discrete version
			;					of derivative) for this feature won't be less than the value provided. A null value means no min boundary.
			;					The value must be in epoch format for the time feature. The length of the list must match the number of
			;					derivatives as specified by 'order'. Only applicable when time series type is set to 'rate'. Example: [0.1]
			;
			;		'rate_max': list of number, if specified, ensures that the rate (the difference quotient, the discrete version
			;					of derivative) for this feature won't be more than the value provided. A null value means no max boundary.
			;					The value must be in epoch format for the time feature. The length of the list must match the number of
			;					derivatives as specified by 'order'. Only applicable when time series type is set to 'rate'. Example: [0.8]
			;
			;		'delta_min': list of number, if specified, ensures that the smallest difference between features values is not smaller
			;					than this specified value. A null value means no min boundary. The length of the list must match the number of
			;					derivatives as specified by 'order'. Only applicable when time series type is set to 'delta'. Example: [0.2]
			;
			;		'delta_max': list of number, if specified, ensures that the largest difference between feature values is not larger than
			;					this specified value. A null value means no max boundary. The length of the list must match the number of
			;					derivatives as specified by 'order'. Only applicable when time series type is set to 'delta'. Example: [2.0]
			;
			;		'universal': boolean, applicable only to the time_feature, controls whether future values of independent time series are considered.
			;					When false, time_feature is not universal and allows using future data from other series in decisions;
			;					this is applicable when the time is not globally relevant and is independent for each time series.
			;					When true, universally excludes using any data with from the future from all series;
			;					this is applicable when time is globally relevant and there are events that may affect all time series.
			;					If there is any possibility of global relevancy of time, it is generally recommended to set this value to true, which is the default.
			feature_attributes (null)
			;{type "boolean"}
			;flag, default to true. create time series feature attributes if necessary
			create_ts_attributes .true
		)

		(call !ValidateParameters)

		(if (contains_value (indices feature_attributes) "")
			(conclude
				(call !Return (assoc errors (list "Empty strings feature names are not allowed.")))
			)
		)

		;filter out any features that start with reserved characters
		(assign (assoc
			feature_attributes
				(filter
					(lambda (not (contains_index !reservedFeatureCharacterSet (first (current_index)))))
					feature_attributes
				)
		))

		(declare (assoc
			ordinals (list)
			nominals (list)

			cyclics_map (assoc)
			nominals_map (assoc)
			ordinals_map (assoc)
			boundaries_map (assoc)

			source_to_derived_feature_map (assoc)
			unique_nominals_set (assoc)
			derived_features_map (assoc)

			has_encoded_features .false
			has_string_ordinals .false
			has_rounded_features .false
			has_datetime_features .false
			has_dependent_features .false
			has_post_processing .false

			ordinal_string_to_ordinal_map (assoc)
			ordinal_ordinal_to_string_map (assoc)
			non_number_continuous_features_map (assoc)
			code_feature_domain_attributes_map (assoc)
			numeric_nominal_features_map (assoc)
			string_nominal_features_set (assoc)
			feature_rounding_map (assoc)
			user_specified_feature_errors_map (assoc)
			feature_datetime_map (assoc)
			feature_bounds_map (assoc)
			post_process_map (assoc)
			feature_custom_derived_methods (assoc)
			time_series_feature (null)

			continuous_to_nominal_dependents_map (null)
			nominal_to_nominal_dependents_map (null)
			novel_substition_feature_set (null)
			shared_deviations_map (null)
		))

		(call !UpdateAttributesForDateTimeDataTypes)

		(assign (assoc
			shared_deviations_map
				(filter
					;don't keep those that have .false for "shared_deviations"
					(lambda (or (current_value)))
					(map
						(lambda (get (current_value) "shared_deviations") )
						feature_attributes
					)
				)
			ordinals_map
				(filter
					(lambda (= "ordinal" (get (current_value) "type")))
					feature_attributes
				)
			nominals_map
				(filter
					(lambda (= "nominal" (get (current_value) "type")))
					feature_attributes
				)
			boundaries_map
				(filter
					(lambda (or (!= (null) (get (current_value) "bounds")) (!= (null) (get (current_value) "allow_null"))))
					feature_attributes
				)
			custom_derived_features_map
				(filter
					(lambda (or
						(!= (null) (get (current_value) "auto_derive_on_train"))
						(!= (null) (get (current_value) "derived_feature_code"))
					))
					feature_attributes
				)
			cyclics_map (call !ComposeCyclicsMap)
			feature_datetime_map (call !ComposeDateTimeMap)
			non_number_continuous_features_map (call !ComposeNonNumberContinuousMap)
			feature_rounding_map (call !ComposeRoundingMap)
			user_specified_feature_errors_map (call !ComposeUserSpecifiedFeatureErrorsMap)

			time_series_feature
				(filter
					(lambda (get feature_attributes (list (current_value 1) "time_series" "time_feature")))
					(indices feature_attributes)
				)
			post_process_map (call !ComposePostProcessMap)
		))

		;TODO: add support for multiple time features
		;output error setting invalid attributes
		(if (> (size time_series_feature) 1)
			(conclude
				(call !Return (assoc errors (list "Only one time feature may be specified.")))
			)
		)

		(declare (assoc constraint_referenced_features_map (call !ComposeConstraintReferencedFeaturesMap) ))

		(declare (assoc invalid_constraint_features (call !ComposeInvalidConstraintFeatures) ))

		(if (size invalid_constraint_features)
			(conclude
				(call !Return (assoc errors
					(list (concat
						"The following features have an invalid constraint defined: "
						(apply "concat" (weave
							invalid_constraint_features
							(range " " 1 (size invalid_constraint_features) 1)
						))
					))
				))
			)
		)

		(if (size non_number_continuous_features_map)
			(assign (assoc
				code_feature_domain_attributes_map
					(call !ComposeCodeFeatureDomainAttributesMap (assoc code_features_map non_number_continuous_features_map))
			))
		)

		;check that ordinal features are either numbers or have a valid ordered list of allowed values
		(if (size ordinals_map)
			(let
				(assoc invalid_ordinals (list))
				(map
					(lambda (let
						(assoc
							current_feature (current_index 1)
							current_ordinal_map (get ordinals_map (current_index 1))
						)
						(if
							(and
								(!= "number" (get current_ordinal_map "data_type"))
								(= (null) (get current_ordinal_map (list "bounds" "allowed")))
							)
							(accum (assoc invalid_ordinals current_feature))
						)
					))
					ordinals_map
				)
				(if (> (size invalid_ordinals) 0)
					(conclude (call !Return
						(assoc errors
							(list (concat
								"The ordinal feature(s): " (apply "concat" (trunc (weave invalid_ordinals ", "))) " must either have a list of ordered allowed values set if they "
								"are non numeric values or have the `data_type` attribute set to 'number' if they are numeric values. To set the list of ordered allowed values, "
								"please modify the 'allowed' key in the 'bounds' attribute in the feature attributes mapping. "
								"If using a python client, in addition to manually modifying the feature attributes mapping, you may also use the `ordinal_feature_values` parameter "
								"when calling `infer_feature_attributes`."
							))
					)))
				))
		)

		;set time_series_feature to null if none are set, otherwise set it to the one time_series time_feature
		(assign (assoc
			time_series_feature (if (size time_series_feature) (first time_series_feature))
		))

		;set the smallest allowed time interval to be the min delta for the time feature
		(if time_series_feature
			(let
				(assoc min_time_interval (+ (or 0 (get feature_attributes (list time_series_feature "time_series" "delta_min" 0)))) )
				;default to 1e-3 if not specified in the feature attribute
				(assign_to_entities (assoc
					!tsMinTimeInterval (if (> min_time_interval 0) min_time_interval 1e-3)
					;default the flag to true unless it's explicitly specified as false
					!tsTimeFeatureUniversal (!= .false (get feature_attributes (list time_series_feature "time_series" "universal")))
				))
				;ensure that time feature time series type is always 'delta'
				(assign "feature_attributes" (list time_series_feature "time_series" "type") "delta")
			)
		)

		(if (size feature_rounding_map)
			(assign (assoc has_rounded_features .true))
		)

		(if (size ordinals_map)
			(seq
				(assign (assoc ordinals (indices ordinals_map) ))
				(assign (assoc
					;filter down only to string ordinals
					ordinals_map
						(filter
							(lambda (> (size (get (current_value) (list "bounds" "allowed"))) 0))
							ordinals_map
						)
				))
			)
		)
		(if (size feature_datetime_map)
			(assign (assoc has_datetime_features .true))
		)
		;process string ordinals
		(if (size ordinals_map)
			(assign (assoc
				ordinal_string_to_ordinal_map
					(map
						(lambda (let
							(assoc ordered_ordinals (get (current_value 1) (list "bounds" "allowed")))
							(zip
								ordered_ordinals
								(range 1 (size ordered_ordinals))
							)
						))
						ordinals_map
					)

				ordinal_ordinal_to_string_map
					(map
						(lambda (let
							(assoc ordered_ordinals (get (current_value 1) (list "bounds" "allowed")))
							(zip
								(range 1 (size ordered_ordinals))
								ordered_ordinals
							)
						))
						ordinals_map
					)
			))
		)

		;ordinal_feature_values
		(if (size ordinal_string_to_ordinal_map)
			(assign (assoc has_string_ordinals .true ))
		)

		(if (size nominals_map)
			(assign (assoc
				nominals (indices nominals_map)
				numeric_nominal_features_map (call !ComposeNumericNominalsMap)
				;this set is to track nominal features that have all unique values (e.g., UUIDs), so that residuals won't be computed for
				;them since they are unpredictable
				unique_nominals_set
					(map
						(null)
						(filter
							(lambda (= .true (get (current_value) "unique")))
							nominals_map
						)
					)
				novel_substition_feature_set (call !ComposeNovelSubstitionFeatureSet)
			))
		)

		(if (size nominals)
			(assign (assoc
				;string nominals are those remaining after numeric and booleans are removed
				string_nominal_features_set
					(filter
						(lambda (!= "boolean" (get feature_attributes [(current_index 1) "data_type"])))
						(remove (zip nominals) (indices numeric_nominal_features_map))
					)
			))
		)

		(if (size shared_deviations_map)
			(seq
				(assign (assoc shared_deviations_map (call !ProcessSharedDeviationsMap)))
				(call !ValidateSharedDeviations)
			)
		)

		(if (size post_process_map)
			(assign (assoc has_post_processing .true))
		)

		;substition features may be set outside of setting attributes, so any of these means we have encoded values that need to be decoded for output
		(if (or
				!hasSubstituteFeatureValues
				has_rounded_features
				has_string_ordinals
				has_datetime_features
				has_post_processing
				;any non-string continuous
				(size (filter
					(lambda (and (!= "string" (current_value)) (!= "string_mixable" (current_value))))
					non_number_continuous_features_map
				))
			)
			(assign (assoc has_encoded_features .true ))
		)

		;the set of features that need to be encoded in some way during training: string nominals, string ordinals, datetimes, json and amalgam
		(declare (assoc
			encoding_needed_features_set
				(zip
					(append
						(indices string_nominal_features_set)
						(indices feature_datetime_map)
						(indices ordinal_string_to_ordinal_map)
						(indices
							(filter
								(lambda (and (!= "string" (current_value)) (!= "string_mixable" (current_value))))
								non_number_continuous_features_map
							)
						)
					)
				)
		))

		(if (size boundaries_map)
			(assign (assoc feature_bounds_map (call !ComposeBoundariesMap) ))
		)

		(if (size custom_derived_features_map)
			(seq
				(assign (assoc
					;leave only those that need to be derived on train
					derived_features_map
						(filter
							(lambda (!= (null) (get (current_value) "auto_derive_on_train")))
							custom_derived_features_map
						)
				))

				;add a list of all features referenced by the derived code into "code_features"
				(assign (assoc
					feature_attributes
						(map
							(lambda
								(if (contains_index custom_derived_features_map (current_index))
									(if (and
											(contains_index (current_value) "auto_derive_on_train")
											(contains_index (get (current_value) "auto_derive_on_train") "code")
										)
										(set
											(current_value)
											["auto_derive_on_train" "code_features"]
											(call !FeaturesInCustomCode (assoc
												code_string (get (current_value 1) ["auto_derive_on_train" "code"])
											))
										)

										(contains_index (current_value) "derived_feature_code")
										(set
											(current_value)
											"code_features"
											(call !FeaturesInCustomCode (assoc
												code_string (get (current_value 1) "derived_feature_code")
											))
										)
									)
									(current_value)
								)
							)
							feature_attributes
						)
				))

				(assign (assoc
					;filter features, leaving only those with custom derivations
					custom_derived_features_map
						(filter
							(lambda (or
								(= "custom" (get (current_value) (list "auto_derive_on_train" "derive_type")))
								(!= (null) (get (current_value) "derived_feature_code"))
							))
							custom_derived_features_map
						)
				))

				;Accumulate source_to_derived_feature_map from all the auto_derive_on_train features
				(call !AccumulateSourceToDerivedFeatureMap)

				;cache all the custom specified derivation code
				(assign (assoc feature_custom_derived_methods (call !ComposeCustomDerivedMethods) ))
			)
		)

		(declare (assoc query_distance_type_map (call !ComposeDistanceTypeMap) ))

		(assign_to_entities (assoc
			!featureAttributes
				;drop the 'parent' key from any time series related feature that has it
				(if time_series_feature
					(map (lambda (remove (current_value) "parent")) feature_attributes)

					feature_attributes
				)

			!trainedFeatures (sort (values (append !trainedFeatures (indices feature_attributes)) .true) )
			!trainedFeaturesContextKey
				(call !BuildContextFeaturesKey (assoc
					context_features (values (append !trainedFeatures (indices feature_attributes)) .true)
				))

			!hasEncodedFeatures has_encoded_features
			!hasStringOrdinals has_string_ordinals
			!hasRoundedFeatures has_rounded_features
			!hasDateTimeFeatures has_datetime_features

			!hasFeaturesNeedEncodingFromInput (> (size encoding_needed_features_set) 0)
			!hasPostProcessing has_post_processing
			!encodingNeededFeaturesSet encoding_needed_features_set
			!uniqueNominalsSet unique_nominals_set
			!derivedFeaturesMap (map (lambda (get (current_value) "parent")) derived_features_map)
			!sourceToDerivedFeatureMap source_to_derived_feature_map
			!postProcessMap post_process_map

			!ordinalStringToOrdinalMap ordinal_string_to_ordinal_map
			!ordinalOrdinalToStringMap ordinal_ordinal_to_string_map
			!editDistanceFeatureTypesMap non_number_continuous_features_map
			!codeFeatureDomainAttributesMap code_feature_domain_attributes_map
			!numericNominalFeaturesMap numeric_nominal_features_map
			!stringNominalFeaturesSet string_nominal_features_set
			!novelSubstitionFeatureSet novel_substition_feature_set
			!featureRoundingMap feature_rounding_map
			!userSpecifiedFeatureErrorsMap user_specified_feature_errors_map
			!featureDateTimeMap feature_datetime_map
			!featureBoundsMap feature_bounds_map
			!featureCustomDerivedMethods feature_custom_derived_methods

			!queryDistanceTypeMap query_distance_type_map
			!tsTimeFeature time_series_feature
			!tsTimeDeltaFeature (concat "." time_series_feature "_delta_1")
			!sharedDeviationsMap (get shared_deviations_map "shared_deviations_key_map")
			!sharedDeviationGroupByPrimaryMap (get shared_deviations_map "shared_deviations_group_by_primary")
			!sharedDeviationsPrimaryFeatures (get shared_deviations_map "shared_deviations_primary_features")
			!sharedDeviationsNonPrimaryFeatures (get shared_deviations_map "shared_deviations_non_primary_features")

		))
		(call !UpdateDefinedFeatures)

		(call !SetOrdinalFeatures (assoc ordinal_features ordinals))
		(call !SetNominalFeatures (assoc nominal_features nominals))
		(call !SetCyclicFeatures (assoc feature_attributes cyclics_map))

		(declare (assoc feature_limits_map (call !ComposeFeatureDomainAttributesMap) ))
		(declare (assoc
			updated_hp_map (call !UpdateHyperparametersWithFeatureDomainAttributes (assoc hp_map !hyperparameterMetadataMap))
			updated_default_hp_map (call !UpdateHyperparametersWithFeatureDomainAttributes (assoc hp_map !defaultHyperparameters))
		))

		;overwrite computed deviations with user specified ones if user specified ones were larger
		(if (> (size !userSpecifiedFeatureErrorsMap) 0)
			(assign (assoc
				updated_hp_map (call !UpdateHyperparametersWithUserErrors (assoc hp_map updated_hp_map))
				updated_default_hp_map (call !UpdateHyperparametersWithUserErrors (assoc hp_map updated_default_hp_map))
			))
		)

		(assign_to_entities (assoc
			!hyperparameterMetadataMap updated_hp_map
			!defaultHyperparameters updated_default_hp_map
		))


		;if time series, create TS features and attributes here if needed
		(if (and create_ts_attributes time_series_feature)
			(call !CreateTimeSeriesFeatures)

			(accum_to_entities (assoc !revision 1))
		)

		;this is strictly after !CreateTimeSeriesFeatures, so that the filtering logic
		;will prioritize the assigned "joined_on" key features rather than series IDs for those applicable
		(declare (assoc
			duplicated_features_map (call !ComposeDuplicateFeaturesMap)
		))
		(if (size duplicated_features_map)
			(accum_to_entities (assoc
				!duplicatedFeaturesMap duplicated_features_map
			))
		)

		;compose dependents after TS features are made so that TS features can be made dependent as necessary
		(declare (assoc
			dependents_map (call !ComposeDependentsMap)
		))
		(if (size dependents_map)
			(assign (assoc
				has_dependent_features .true
				;create an assoc of: continuous feature -> [ list of sorted nominal dependents ]
				continuous_to_nominal_dependents_map (call !ComposeContinuousToNominalDependenciesMap)
			))
		)
		(assign_to_entities (assoc
			!hasDependentFeatures has_dependent_features
			!dependentFeatureMap dependents_map
			!continuousToNominalDependenciesMap continuous_to_nominal_dependents_map
		))

		(call get_feature_attributes)
	)

	#!ComposeCustomDerivedMethods
	(map
		(lambda (let
			(assoc
				feature (current_index 1)
				attributes (current_value 1)
				train_derived_method (null)
			)
			(if (= "custom" (get attributes (list "auto_derive_on_train" "derive_type")))
				(assign (assoc
					train_derived_method
						(call !ParseDerivedFeatureCode (assoc
							code_string (get attributes (list "auto_derive_on_train" "code"))
							value
								(lambda
									(if (and (>= (- series_row_index lag) 0) (contains_index feat_index_map feature))
										(get series_data (list (- series_row_index lag) (get feat_index_map feature)) )
									)
								)
						))
				))
			)

			;if feature has custom specified derived code, compute and cache it
			(if (contains_index attributes "derived_feature_code")
				(let
					(assoc raw_code_string (get attributes "derived_feature_code") )

					;add the max_row_lag attribute to this feature attribute
					(assign "feature_attributes" [ feature "max_row_lag" ] (call !MaxLagInCustomCode (assoc code_string raw_code_string)) )

					;cache the parsed single and series react derived custom code methods for this feature
					(assoc
						"train"
							train_derived_method
						"react"
							(call !ParseDerivedFeatureCode (assoc
								code_string raw_code_string
								value
									(lambda
										;feature label offsets must all be 0 to derive valid values since we can only pull data from the
										;one existing 'row' of data that is provided for computation. Any values other than 0 output a null.
										(if (and (= lag 0) (contains_index feature_values_map feature))
											(get feature_values_map feature)
										)
									)
							))
						"series_react"
							(call !ParseDerivedFeatureCode (assoc
								code_string raw_code_string
								value
									(lambda
										(if (and (>= (- series_row_index lag) 0) (contains_index feature_index_map feature))
											(let
												(assoc
													val (get series_data [ (- series_row_index lag) (get feature_index_map feature) ] )
												)

												;encode datetime by converting string date time into seconds since epoch
												(if (contains_index !featureDateTimeMap feature)
													(if (!= (null) val)
														(call !ConvertDateToEpoch (assoc "date" val "feature" feature))
													)
													;not a datetime, return continuous value
													val
												)
											)
										)
									)
							))
					)
				)

				;else feature only has a train-derive method, cache that
				(!= (null) train_derived_method)
				(assoc "train" train_derived_method)
			)
		))
		custom_derived_features_map
	)

	;output all feature attributes
	;{idempotent .true}
	#get_feature_attributes
	(declare
		;returns {ref "FeatureAttributesIndex"}
		(assoc)
		;if feature attributes is empty but there are feature definitions, manually populate !featureAttributes
		(if (and
				(!= (null) !trainedFeatures)
				(= (assoc) !featureAttributes)
			)
			(assign_to_entities (assoc
				!featureAttributes
					;iterate over the default features as an assoc, such that they keys are feature names
					;and the values are the feature attributes
					(map
						(lambda (let
							(assoc
								type
									(if (contains_index !nominalsMap (current_index 1))
										"nominal"

										(contains_index !ordinalFeaturesSet (current_index 1))
										"ordinal"

										;else
										"continuous"
									)
								decimal_places (get !featureRoundingMap (list (current_index 2) 1))
								significant_digits (get !featureRoundingMap (list (current_index 2) 0))
								cycle_length (get !cyclicFeaturesMap (current_index 1))
								date_time_format (get !featureDateTimeMap (list (current_index 2) "date_time_format"))
								locale (get !featureDateTimeMap (list (current_index 2) "locale"))
								default_time_zone (get !featureDateTimeMap (list (current_index 2) "default_time_zone"))
								observational_error (get !userSpecifiedFeatureErrorsMap (current_index 1))
							)

							;create an assoc of feature attributes
							(append
								{ "type" type }
								(if (!= (null) decimal_places) { "decimal_places" decimal_places } {} )
								(if (!= (null) significant_digits) { "significant_digits" significant_digits } {} )
								(if (!= (null) cycle_length) { "cycle_length" cycle_length } {} )
								(if (!= (null) observational_error) { "observational_error" observational_error } {} )
								(if (!= (null) date_time_format) { "date_time_format" date_time_format } {} )
								(if (!= (null) locale) { "locale" locale } {} )
								(if (!= (null) default_time_zone) { "default_time_zone" default_time_zone } {} )
							)
						))
						(zip !trainedFeatures)
					)
			))
		)

		;output stored !featureAttributes
		(call !Return (assoc payload (get_value !featureAttributes) ))
	)

	;a recursive method to generate a nested assoc of feature values -> (feature values) -> min,max boundary for those values
	;when provided a list of nominal features and a their dependent continuous value feature
	;for example, if there are two nominal features named 'measure' and 'unit', and a continuous feature named 'amount',
	;this would generate a nested dict of all measure-units -> min,max bounds for each respective measure and unit combination
	;
	;parameters:
	; base_query_among_statements: the list of query_among's that should be appended to for each recursive call
	; value_feature: name of the continuous feature for which we want to determine all the possible min/max bounds
	; nominals: list of nominal features corresponding to the continuous value feature
	;value_feature_nulls_are_dependent: flag, if true nulls are treated as valid dependent values
	#!ComputeDependentBoundaries
	(declare
		(assoc
			base_query_among_statements (list)
			value_feature ""
			nominals (list)
			value_feature_nulls_are_dependent .false

			;not params
			feature (null)
		)

		;store the first dependent nominal value
		(assign (assoc feature (first nominals) ))
		;the rest of the dependent nominal values, if there are any
		(assign (assoc nominals (tail nominals) ))

		;pull all the unique values for this nominal feature
		(declare (assoc
			feature_values
				(indices
					(compute_on_contained_entities
						;if non-string nominal, pull as numeric count
						(query_value_masses feature (null))
					)
				)
		))

		;if the continuous feature's attribute is to treat null as dependent, add (null) as a valid value for this dependent nominal feature if it has nulls
		(if value_feature_nulls_are_dependent
			;if this feature has any nulls, add (null) as a unique nominal feature value for which to compute boundaries
			(if
				(size (contained_entities (query_equals feature (null)) ))
				(accum (assoc feature_values (list (null)) ))
			)
		)

		;if there are more dependent nominals, we need to call !this method for those nominals recursively,
		;once for each feature value for this feature.  for example, if there are two nominal features A (with values 'h','i' and 'j')
		;and B with values 'x','y','z', we'll call !this method for each value of A, with nominals=[B] and base_query_among_statements = (list (query_among "A" (list "h"))),
		;then again with base_query_among_statements = (list (query_among "A" (list "i"))), and finally with base_query_among_statements = (list (query_among "A" (list "j"))),
		(if (> (size nominals) 0)
			(map
				(lambda
					(call !ComputeDependentBoundaries (assoc
						base_query_among_statements
							(append base_query_among_statements (list
								(query_among feature
									(list
										;ensure that the value in the query_among is a number by wrapping it in a (+) if the nominal is not a string
										;if the value is (null), it will still be (null) after the (+)
										(if (contains_index !numericNominalFeaturesMap feature)
											(+ (current_index 3))
											(current_index 3)
										)
									)
								)
							))
						nominals nominals
						value_feature value_feature
						value_feature_nulls_are_dependent value_feature_nulls_are_dependent
					))
				)
				(zip feature_values)
			)

			;else there are no more dependent nominals left, continuing the above example, we iterate over all the values of this last nominal feature 'B'
			;appending to each of the query amongs passed in, to create all the combinations of feature values for A and B,
			;eg., h+x, h+y, h+z, i+x, i+y, etc...  so h+x is in the format of (list (query_among "A" (list "h")) (query_among "B" (list "x")))
			;given all these possible combinations of feature values, we determine the min and max value for the continuous feature and output it as a
			;pair of (list min max) for feature value combinations that exist or (null) for those that don't, resulting in a nested assoc that may look like:
			; { 'h': {'x': (list 0 10) }, 'h': {'y': (null) }, 'h': {'z': (null) }, 'i': {'x': (null) }, 'i': {'y': (list 10 100) }, etc... }
			(map
				(lambda (let
					(assoc
						query_among_statements
							(append base_query_among_statements (list
								(query_among feature
									(list
										;ensure that the value in the query_among is a number by wrapping it in a (+) if the nominal is not a string
										(if (contains_index !numericNominalFeaturesMap feature)
											(+ (current_index 3))
											(current_index 3)
										)
									)
								)
							))
						min_value (null)
					)

					;pull the case with the smallest value for the continuous feature given the constructed query_among with the nominal value combinations
					;if there are no cases for such query_among(s), min_case will be null and we output (null) for the bounds pair
					(assign (assoc
						min_case (contained_entities query_among_statements (query_min value_feature 1))
					))

					;if there does exist a case with a minimum value, that means there must also be a max value, so we return the bounds pair for this
					;combination of nominal values
					(if (size min_case)
						;if there are dependent nulls in this continuous value_feature, store null as a valid value for the feature bounds tuple
						(if
							(and
								value_feature_nulls_are_dependent
								(size
									(contained_entities query_among_statements (query_equals value_feature (null)) )
								)
							)
							;output a tuple of [min, (null), max]
							[
								(retrieve_from_entity min_case value_feature)
								(null)
								(retrieve_from_entity (contained_entities query_among_statements (query_max value_feature 1)) value_feature)
							]

							;else output a tuple of [min, max]
							[
								(retrieve_from_entity min_case value_feature)
								(retrieve_from_entity (contained_entities query_among_statements (query_max value_feature 1)) value_feature)
							]
						)

						;else there are no continuous value_feature values for this nominal value
						;but nulls are dependent, set null as the only valid continuous value for this nominal value
						;by outputing it as a bounds tuple containing just (null)
						(and
							value_feature_nulls_are_dependent
							(size
								(contained_entities query_among_statements (query_equals value_feature (null)) )
							)
						)
						[ (null) ]
					)
				))
				(zip feature_values)
			)
		)
	)

	;Recursive method to process the computed dependent boundary map into a list of valid nominal value combinations
	; If there are two dependent nominal features with 4 values each, while there may be 16 unique combinations of values,
	; realistically only 4 are probably valid, so this method filters out all the combinations that do not have a min,max boundary,
	; leaving a list of lists of valid feature values.  Example: 'heartrate' and 'BPM' are valid, but 'heartrate' and 'mSv' is not.
	; Example, given a nested_value_combinations_map like this:
	;		bmi {
	;			(null) [12 (null) 45]
	;			bpm (null)
	;			mSv (null)
	;			ratio [10 30]
	;		}
	;		heartrate {
	;			(null) (null)
	;			bpm [50 180]
	;			mSv (null)
	;			ratio (null)
	;		}
	;		xray {
	;			(null) (null)
	;			bpm (null)
	;			mSv [0.005 0.1]
	;			ratio (null)
	;		}
	;
	; this method outputs the only valid combinations:
	; 	[
	;		[ "bmi" (null)]
	;		[ "bmi" "ratio"]
	;		[ "heartrate" "bpm"]
	;		[ "xray" "mSv"]
	; 	]
	;
	;parameters:
	;
	; nested_value_combinations_map: nested assocs of feature value -> [min, max], eg: {'heartrate : {'bpm' : [ 25, 180] }}
	; values_lists: list of nominal values to append each corresponding feature value. e.g, [ "heartrate", "bpm"]
	#!AccumulateDependentValuesCombinations
	(filter (map
		(lambda
			(if (~ (assoc) (current_value))
				(apply "append" (values
					(call !AccumulateDependentValuesCombinations (assoc
						nested_value_combinations_map (current_value 1)
						values_lists (append values_lists (current_index 1))
					))
				))

				(!= (null) (current_value))
				[(append values_lists (current_index 1))]
			)
		)
		nested_value_combinations_map
	))


	;set the list of ordinal features, or clears it if empty list is specified
	;parameters:
	; ordinal_features: list of ordinal features
	#!SetOrdinalFeatures
	(declare
		(assoc ordinal_features (list))

		(if (= 0 (size ordinal_features))
			(assign_to_entities (assoc
				;filter out all ordinal categorical features, leaving only nominal ones
				!categoricalFeaturesSet (remove !categoricalFeaturesSet (indices !ordinalFeaturesSet))
				!ordinalFeaturesSet (assoc)
				!ordinalNumericFeaturesSet (assoc)
			))

			(assign_to_entities (assoc
				!ordinalFeaturesSet (zip ordinal_features)
				!categoricalFeaturesSet (append !categoricalFeaturesSet (zip ordinal_features))
				!ordinalNumericFeaturesSet (remove (zip ordinal_features) (indices !ordinalStringToOrdinalMap))
			))
		)

		;returns whether or not the trainee has !ordinalFeaturesSet
		(if (> (size !ordinalFeaturesSet) 0) .true .false)
	)

	; set the list of nominal features. If nominal features already exist, appends to them. passing in an empty list disables nominal features
	;parameters
	; nominal_features: list of nominal features
	#!SetNominalFeatures
	(declare
		(assoc nominal_features (list))

		;clear the nominals if empty list is passed in
		(if (= 0 (size nominal_features))
			(assign_to_entities (assoc
				!nominalsMap (assoc)
				;filter out all nominal categorical features, leaving only ordinal ones
				!categoricalFeaturesSet (remove !categoricalFeaturesSet (indices !nominalsMap))
			))

			;else set the nominal value maps
			(assign_to_entities (assoc
				!categoricalFeaturesSet (append !categoricalFeaturesSet (zip nominal_features))
				!nominalsMap (zip nominal_features)
			))
		)

		;invalidate cached class probabilities
		(assign_to_entities (assoc !nominalClassProbabilitiesMap (assoc)))
	)

	;set cyclic feature lengths.  if passed in an empty assoc, clears out cyclic features.  all cycles start at 0
	;parameters:
	; feature_attributes: assoc of feature -> cycle length
	;example: (assoc "day" 7 "degrees" 360)
	#!SetCyclicFeatures
	(declare
		(assoc feature_attributes (assoc))
		(if (= 0 (size feature_attributes))
			(assign_to_entities (assoc
				!hasCyclicFeatures 0
				!cyclicFeaturesMap (null)
			))

			(assign_to_entities (assoc
				!hasCyclicFeatures 1
				!cyclicFeaturesMap feature_attributes
			))
		)

		;trainee definition has changed so clear out these cached value
		(assign_to_entities (assoc
			!averageCaseEntropyAddition (null)
			!averageCaseEntropyRemoval (null)
			!storedCaseConvictionsFeatureAddition (null)
			!averageCaseDistanceContribution (null)
		))

		;returns whether or not the trainee has cyclic features
		!hasCyclicFeatures
	)
)
