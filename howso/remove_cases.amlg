;Contains methods for the removal of cases.
(null

	;removes all cases that match the specified conditions from trainee
	;
	;parameters:
	; case_indices: a list of session id and training index tuples that specify which cases are to be removed
	; precision: flag, whether to query for 'exact' matches; if set to 'similar' will move num_cases with the most similar values. Ignored if case_indices is specified.
	; condition: assoc of feature->value(s) (no value = must have feature, one value = must equal exactly the value, two values = inclusive between). Ignored if case_indices is specified.
	; condition_session: optional, if specified, ignores condition and instead operates on all cases that were trained with this session id. Ignored if case_indices is specified.
	; num_cases: optional, limit on the number of cases to move; If set to zero there will be no limit. Ignored if case_indices is specified.
	;		If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
	; distribute_weight_feature: name of feature into which to distribute the removed cases' weights to their neighbors.
	#remove_cases
	(declare
		(assoc
			case_indices (null)
			condition (assoc)
			precision "exact"
			num_cases (null)
			distribute_weight_feature (null)
		)

		;build list of case ids that match criteria
		(declare (assoc
			cases_to_remove
				(if (= (null) case_indices)
					;compute the cases to re/move
					(call !GetCasesByCondition (assoc
						condition condition
						condition_session condition_session
						precision precision
						num_cases num_cases
					))

					;else use case_indices
					(call !GetCaseIds (assoc case_indices case_indices))
				)
		))

		;remove cases and do session cleanup
		(call !RemoveCases (assoc
			cases cases_to_remove
			distribute_weight_feature distribute_weight_feature
		))

		(accum_to_entities (assoc !revision 1))

		;return the number of cases moved
		(call !Return (assoc payload (assoc "count" (size cases_to_remove)) ))
	)

	;removes all contained entities that are cases except those that are complete contexts and actions
	; as those containing all of context_features or action_features
	;any additional cases to keep should be passed in as keys to the optional parameter cases_to_keep (values don't matter)
	#!RemoveIncompleteCases
	(declare
		(assoc
			context_features (list)
			action_features (list)

			;keys represent contexts that should be kept (for quick lookup), values are null
			cases_to_keep_map (assoc)
		)

		(let
			(assoc
				features
					(if (= 0 (size context_features) (size action_features))
						!trainedFeatures
						(append context_features action_features)
					)
			)

			;populate cases_to_keep_map
			(assign (assoc
				cases_to_keep_map
					(zip
						;cases
						(contained_entities
							(map
								(lambda (query_exists (current_value)) )
								features
							)
						)
					)
			))
		)

		(if (!= (size cases_to_keep_map) (call !GetNumTrainingCases))
			;model has changed so clear out these cached value
			(call !ClearCachedCountsAndEntropies)
		)

		;destroy any cases that aren't in cases_to_keep_map
		(map
			;destroy any entities
			(lambda (destroy_entities (current_value)))

			;that have empty lists of empty replay references
			(filter
				(lambda
					(not (contains_index cases_to_keep_map (current_value)))
				)

				(call !AllCases)
			)
		)
	)

	;goes through every session and removes any cases within the replay that are invalid
	#!RemoveInvalidCasesFromSessionReplay
	(map
		(lambda (assign_to_entities
			(current_value)
			(assoc
				".replay_steps"
					(filter
						(lambda (and
							;case should not be null
							(!= (null) (current_value))
							;case should exist
							(contains_entity (current_value))
						))
						(retrieve_from_entity (current_value 1) ".replay_steps")
					)
			)
		))

		(call !GetSessionIds)
	)

	;removes any unused cases from trainee
	#!RemoveCasesWithoutSessionReferences
	(let
		(assoc sessions_map (zip (call !GetSessionIds)))

		(map
			;destroy any entities
			(lambda (destroy_entities (current_value) ))

			;keep only those cases that don't have a session or non-existent sessions
			(filter
				(lambda
					(or
						(= (retrieve_from_entity (current_value) !internalLabelSession) (null))
						(not (contains_index sessions_map (retrieve_from_entity (current_value) !internalLabelSession)))
					)
				)

				(call !AllCases)
			)
		)

		;model has changed so clear out these cached value
		(call !ClearCachedCountsAndEntropies)

		(true)
	)

	;Remove cases and cleanup session entities replay steps and update all the remaining cases' session indices
	;parameters:
	; cases: list of case ids to remove
	; distribute_weight_feature: name of feature into which to distribute the removed cases' weights to their neighbors.
	#!RemoveCases
	(declare
		(assoc
			cases (list)
			distribute_weight_feature (null)
		)

		(if (= 0 (size cases)) (conclude))

		;list of session ids, one per case
		(declare (assoc
			sessions (map (lambda (retrieve_from_entity (current_value) !internalLabelSession)) cases)
			train_indices (map (lambda (retrieve_from_entity (current_value) !internalLabelSessionTrainingIndex)) cases)
		))

		(declare (assoc
			;map of session -> list of removed case ids. If a session only has one case id, it will be by itself and not in a list.
			sessions_map
				(zip
					(lambda (append (current_value 1) (current_value)))
					;indices are sessions, which when clobbered will append the case id to the growing list of ids for each session
					sessions
					cases
				)
			;map of session -> list of removed case training indices
			session_train_indices_map
				(zip
					(lambda (append (current_value 1) (current_value)))
					;indices are sessions, which when clobbered will append the train_index to the growing list of train_indices for each session
					sessions
					train_indices
				)
		))

		;need to distribute the weight feature values from these removed cases to neighbors
		(if distribute_weight_feature
			(seq
				;CreateCaseWeights will find all cases missing distribute_weight_feature, then initialize
				;distribute_weight_feature with a value of 1.0 for each
				(call !CreateCaseWeights (assoc
					feature_name distribute_weight_feature
				))
				(call !DistributeCaseInfluenceWeights (assoc
					features !trainedFeatures
					case_ids cases
					distribute_weight_feature distribute_weight_feature
				))
			)
		)

		(declare (assoc re_derivation_series_case_ids (null) ))

		;check if time series dataset, if so, need to pull all cases from affected series so that their
		;derived features can be-rederived below after cases are removed
		(if (and (!= (null) !tsTimeFeature) (size !derivedFeaturesSet))
			(let
				(assoc series_id_features (get !tsModelFeaturesMap "series_id_features") )

				;for each case pull the list of series id values for all the series id features
				(declare (assoc
					series_id_lists
						(map
							(lambda (retrieve_from_entity (current_value) series_id_features))
							cases
						)
				))

				;for each series id feature, create a list of cases that were affected and will need to be re-derived
				(declare (assoc
					series_case_ids_per_id_feature
						(map
							(lambda (let
								(assoc
									feature (current_value 1)
									feature_index (current_index 1)
								)

								(apply "append"
									(map
										(lambda
											(contained_entities (list
												(query_equals feature (current_value 1))
											))
										)
										;all unique ids for this feature
										(values
											(map
												(lambda (get (current_value) feature_index))
												series_id_lists
											)
											(true)
										)
									)
								)
							))
							series_id_features
						)
				))

				;collapse all lists of cases into one list of unique case ids
				(assign (assoc
					re_derivation_series_case_ids (values (apply "append" series_case_ids_per_id_feature) (true) )
				))
			)
		)

		;remove all the cases
		(apply "destroy_entities" cases)

		;iterate over every session, cleaning up its replay steps and uptating its cases' training indices
		(map
			(lambda (let
				(assoc
					session (current_index 1)
					replay_steps (retrieve_from_entity (current_index 1) ".replay_steps")
					removed_cases_map
						;if there's only one case for this session, its size will be 0, wrap it in a list prior to zipping
						(if (= 0 (size (current_value 1)))
							(zip (list (current_value 2)))
							(zip (current_value 1))
						)
				)

				;filter cases from replay steps, leave only those cases that have not been removed
				(assign (assoc
					replay_steps (filter (lambda (not (contains_index removed_cases_map (current_value)))) replay_steps)
				))

				(assign_to_entities session (assoc
					".replay_steps" replay_steps
					".indices_map"
						;.indices_map is an assoc of train_index->case_id, so we can just simply delete all the removed training_indices with one delete call
						(remove
							(retrieve_from_entity session ".indices_map")
							(get session_train_indices_map session)
						)
				))
			))
			sessions_map
		)

		;model has changed so clear out these cached value
		(call !ClearCachedCountsAndEntropies)

		;if there are cases that need to have features re-derived, do it here
		(if re_derivation_series_case_ids
			(call !DeriveTrainFeatures (assoc
				features !trainedFeatures
				;keep and derive only those features that are not in the features list
				derived_features (get !tsModelFeaturesMap "ts_derived_features")
				case_ids re_derivation_series_case_ids
			))
		)

		(call !UpdateHasNulls (assoc features !trainedFeatures))

		(null)
	)

)