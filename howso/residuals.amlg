;Contains methods for computing and outputting residuals.
(null

	;iterate over the specified deviation_features_map and output maximum knwown residuals for each feature
	#!ComputeMaxResiduals
	(map
		(lambda
			;if a bounds map is defined, use the max delta for the bounds if min and max are specified
			(if (contains_index !featureBoundsMap (current_index))
				;nominals max residual is 1
				(if (contains_index !nominalsMap (current_index))
					1

					;datetime features with bounds will have epoch bounds defined
					(get !featureBoundsMap "has_epoch_bounds")
					(-
						(get !featureBoundsMap "epoch_max_value")
						(get !featureBoundsMap "epoch_min_value")
					)

					;continuous, non-datetime features
					(and
						(not (contains_index !featureDateTimeMap (current_index)))
						(contains_index !featureBoundsMap "min")
						(contains_index !featureBoundsMap "max")
					)
					(-
						(get !featureBoundsMap "max")
						(get !featureBoundsMap "min")
					)

					;if cyclical, output cycle length
					(contains_index !cyclicFeaturesMap (current_index))
					(get !cyclicFeaturesMap (current_index))

					;if defined numeric ordinal, output the total cardinality
					(contains_index !ordinalOrdinalToStringMap (current_index))
					(size (get !ordinalOrdinalToStringMap (current_index)))

					;else unspecified min/max for feature, return maximum residual
					.infinity
				)

				;no bounds specified, return maximum residual
				.infinity
			)
		)
		deviation_features_map
	)

	;helper method for CalculateFeatureResiduals to compute and cache min gaps and min residuals
	#!CacheFeatureMinGapAndResidual
	(seq
		(declare (assoc
			features_to_compute
				(if (size !sharedDeviationsMap)
					;remove non-primary shared features from the features list
					(indices (remove (zip features) !sharedDeviationsNonPrimaryFeatures) )

					;else use all features
					features
				)
		))

		(declare (assoc
			feature_half_min_gap_map
				(map
					(lambda (let
						(assoc
							;if using shared deviations, the group of shared deviations features including this feature
							feature_grouping
								;returns any empty list if not in a group
								(call !GetSharedDeviationGrouping (assoc feature_group_to_retrieve (current_index 2)))
							current_feature (current_index 1)
						)

						;if not in a group, create a group of just the feature
						(if (= (size feature_grouping) 0)
							(assign (assoc feature_grouping [current_feature]))
						)

						(declare (assoc
							smallest_gap
								(if
									;gap is always 1 for nominals or strings
									(or
										(contains_index !nominalsMap current_feature)
										(contains_value (list "string" "string_mixable") (get !editDistanceFeatureTypesMap current_feature ))
									)
									1
									;else compute the gap
									(apply "min"
										(map
											(lambda
												(compute_on_contained_entities
													(query_min_difference (current_value) (get !cyclicFeaturesMap (current_value)) )
												)
											)
											feature_grouping
										)
									)
								)
						))

						;infinity means there was no gap, set value to zero
						(if (= .infinity smallest_gap)
							0

							;(null) means that all values are nulls and a gap couldn't be computed
							;set it to be 0.1 for edit distance feature, and zero for all other continuous
							(= (null) smallest_gap)
							(if (contains_index !editDistanceFeatureTypesMap current_feature)
								0.1
								0
							)

							;else set the smallest gap to gap / 2
							(/ smallest_gap 2)
						)
					))
					(zip features_to_compute)
				)
		))

		(declare (assoc
			feature_min_residual_map
				(map
					(lambda
						;empty datasets set minimal residual to be half a gap
						(if (= 0 num_training_cases)
							0.5

							;For unique features:
							;Using n+1, n+2, or n+.5 are all possible considerations of Laplacian smoothing to apply a Bayesian approach for
							;estimating the probability of having no incorrect predictions. We chose .5 assuming the Jeffreys prior approach.
							;ensure value is not larger than 0.5
							(contains_index !uniqueNominalsSet (current_index))
							(min 0.5 (/ 1 (+ 0.5 num_training_cases)) )

							;else set nominal lower residual bound to:  gap / (num_cases + 1)
							;multiply (current_value) by 2 because (current_value) is the 'half gap' value
							(contains_index !nominalsMap (current_index))
							(/ (* 2 (current_value)) (+ 1 num_training_cases))

							;else set continuous lower residual bound to:  gap / ( 0.5 + num_cases)
							;Using n+1, n+2, or n+.5 are all possible considerations of Laplacian smoothing to apply a Bayesian approach for
							;estimating the probability of having no incorrect predictions.  We chose .5 assuming the Jeffreys prior approach.
							(if (current_value)
								;multiply (current_value) by 2 because (current_value) is the 'half gap' value
								(/ (* 2 (current_value)) (+ 0.5 num_training_cases))

								;else gap is 0, prevent a 0 smallest residual
								(/ 1 (+ 0.5 num_training_cases))
							)
						)
					)
					feature_half_min_gap_map
				)
		))

		(if (size !sharedDeviationsMap)
			(assign (assoc
				feature_min_residual_map
					(call !ExpandForSharedDeviations (assoc compressed_values feature_min_residual_map))
				feature_half_min_gap_map
					(call !ExpandForSharedDeviations (assoc compressed_values feature_half_min_gap_map))
			))
		)

		(assign_to_entities (assoc
			!cachedFeatureMinResidualMap (replace feature_min_residual_map)
			!cachedFeatureHalfMinGapMap (replace feature_half_min_gap_map )
		))
	)

	;Limit computed residuals from feature_residuals_map to be the max of cached minimum residual, computed residual, and user-specified error
	;outputs the passed in feature_residuals_map with limited values.
	;
	;parameters:
	; feature_residuals_map: output assoc from CalculateFeatureResiduals containing a map of feature -> residual value in the 'residual_map' key
	;					i.e.: { "residual_map" : { "featureA" : 3.4... } }
	; using_shared_deviations: boolean, default (null). If true, will only use parent features and expand according to the shared deviations groups
	#!ExpandResidualValuesToUncertainty
	(set
		feature_residuals_map
		"residual_map"
		(let (assoc
			temp_residual_map
				(map
					(lambda
						;inactive features are bound to min residual
						(if (contains_index !inactiveFeaturesMap (current_index))
							(get !cachedFeatureMinResidualMap (current_index))

							;set upper bound to nominals to be max nominal deviation, accounting for imbalanced classes
							(contains_index !nominalsMap (current_index))
							(let
								(assoc
									;map of class -> count
									feature_grouping
										(if (size !sharedDeviationsMap)
											(call !GetSharedDeviationGrouping (assoc feature_group_to_retrieve (current_index 2)))
										)
									current_feature (current_index 1)
								)
								(declare (assoc
									class_counts_map
										(if (size feature_grouping)
											;get the total class counts for all the features in the shared deviations group
											(reduce
												(lambda
													;add each class's count together
													(map
														(lambda (+
															(or (first (current_value)))
															(or (last (current_value)))
														))
														(previous_result)
														(current_value)
													)
												)
												;list of each feature's class count assocs
												(map
													(lambda
														(compute_on_contained_entities
															(query_value_masses (current_value) (null))
														)
													)
													feature_grouping
												)
											)

											(compute_on_contained_entities
												(query_value_masses current_feature (null))
											)
										)
								))

								;do not max cap nominal deviations if less than 2 classes have been trained
								(if (<= (size class_counts_map) 1)
									(max
										(get !cachedFeatureMinResidualMap (current_index))
										(current_value)
										(get !userSpecifiedFeatureErrorsMap (current_index))
									)

									;else cap the max nominal deviation
									(let
										(assoc total_count (apply "+" (values class_counts_map)) )

										(min
											;nominal max deviation is the sum of: each class's probability multiplied by probability of getting it wrong
											(apply "+"
												(map
													(lambda (let
														(assoc class_prob (* (/ (current_value 1) total_count)) )
														(* class_prob (- 1 class_prob))
													))
													(values class_counts_map)
												)
											)

											(max
												(get !cachedFeatureMinResidualMap (current_index))
												(current_value)
												(get !userSpecifiedFeatureErrorsMap (current_index))
											)
										)
									)
								)
							)

							;else continuous value don't have upper bounds, set the lower bound
							(max
								(get !cachedFeatureMinResidualMap (current_index))
								(current_value)
								(get !userSpecifiedFeatureErrorsMap (current_index))
							)
						)
					)

					;if using shared deviations, map over a reduced residuals map with only features that are not
					; in a shared deviations group or are the primary keys of a shared deviations group
					(if (and
							using_shared_deviations
							(size !sharedDeviationsMap)
						)
						(remove
							(get feature_residuals_map "residual_map")
							!sharedDeviationsNonPrimaryFeatures
						)

						(get feature_residuals_map "residual_map")
					)
				)
			)

			(if (and
					using_shared_deviations
					(size !sharedDeviationsMap)
				)
				(call !ExpandForSharedDeviations (assoc compressed_values temp_residual_map))
				temp_residual_map
			)
		)
	)

	;Wrapper method for computing regional model residuals that doesn't run the full method if the regional model is only of size 1.
	;Computes regional residuals for the specified target_residual_feature provided a 'regional_cases_map' and 'features' to use as contexts.
	;returns an assoc of target_residual_feature -> residual value
	#!ComputeRegionalResiduals
	(if (= 1 (size regional_cases_map))
		(assoc
			"residual_map"
				;if regional model is of size of 1, residual cannot be calculated, therefore
				;for nominal features set it to 0.5
				(if (contains_index !nominalsMap target_residual_feature)
					(associate target_residual_feature 0.5)

					;for continuous features set the residual to: boundary_max - boundary_min (if boundaries are specified)
					(map
						(lambda (let
							(assoc feature (current_index))

							(declare (assoc
								boundaries_tuple
									(call !ConstrainBoundariesForFeature (assoc
										bounds_map (get feature_bounds_map feature)
										feature feature
										is_datetime (and !hasDateTimeFeatures (contains_index !featureDateTimeMap feature))
										cycle_length cycle_length
									))
							))

							;residual is: feature range / 4 to average out residual in each direction

							;if a boundary value is not specified, residual is unknown, set it to 0
							(if (contains_value boundaries_tuple (null))
								0

								;for cyclics with exclusionary bounds where the min is larger than the max,
								;e.g., to allow +/- 60 degrees, boundary_min=300, boundary_max=60
								;therefore the range is: boundary_max + (cycle_length - boundary_min)
								(and cycle_length (> (first boundaries_tuple) (last boundaries_tuple)))
								(/
									(+ (last boundaries_tuple) (- cycle_length (first boundaries_tuple)))
									4
								)

								;else residual is simply the range: (boundary_max - boundary_min)
								(/ (- (last boundaries_tuple) (first boundaries_tuple)) 4)
							)
						))
						(zip (list target_residual_feature))
					)
				)
		)

		;else return the regional residuals for the target_residual_feature
		(call !CalculateFeatureResiduals (assoc
			features features
			target_residual_feature target_residual_feature
			case_ids (indices regional_cases_map)
			regional_data_only (true)
			compute_null_uncertainties (false)
			use_case_weights use_case_weights
			weight_feature weight_feature
			focal_case ignore_case

			;if only one feature provided, attempt to use its parameters, otherwise use targetless
			hyperparameter_feature (if (= 1 (size feature)) feature)

			;all the context features are specified
			robust_residuals (false)
			use_shared_deviations (false)
		))
	)


	;helper method to sample cases from the model, outputs a list of case ids
	;if there are more cases than the sample size, randomly select that many cases, by default cases are in random order
	#!SelectCaseIdsForResiduals
	(if (and (> num_training_cases num_samples) (> num_training_cases 1000))
		(if robust_residuals
			(call !SampleCases (assoc
				num num_samples
				rand_seed (rand)
				case_weight_feature (if valid_weight_feature weight_feature)
			))
			;grab samples from the model
			(call !AllCases (assoc num num_samples rand_seed (rand)))
		)

		(if robust_residuals
			(if (= "deviations" robust_residuals)
				;for local (superfull) deviations, if the dataset is tiny, use more samples than in dataset to compute SDM values
				(call !SampleCases (assoc
					num (min num_samples (* num_training_cases (pow 2 (size features))))
					case_weight_feature (if valid_weight_feature weight_feature)
				))

				(call !SampleCases (assoc
					num num_samples
					case_weight_feature (if valid_weight_feature weight_feature)
				))
			)

			;else just use all the case ids because the model size is <= num_samples or the model is small
			(seq
				(declare (assoc using_all_cases (true) ))
				(call !AllCases)
			)
		)
	)


	;helper method for !CalculateFeatureResiduals to initialize variables and sample case_ids
	#!InitResiduals
	(seq
		;need 2x as many default robust samples since on average half the features won't have computations
		(if (= (null) num_samples)
			(assign (assoc
				num_samples (if robust_residuals 2000 1000)
			))
		)

		;if features aren't specified, assume all !trainedFeatures will need to have their mae calculated
		(if (= (null) features)
			(assign (assoc features !trainedFeatures))
		)

		;if features aren't specified, assume all features will need to have their mae calculated
		(if (= (null) context_features)
			(assign (assoc context_features features))
		)

		(if (size features_to_derive)
			(assign (assoc
				;map of features to features needed for derivation (empty list if derivation is not necessary)
				features_for_derivation_map
					(map
						(lambda
							(indices (filter
								;filter out derivation code that reaches to previous rows of a series
								(lambda (= (current_value) 0))
								(get_all_labels (parse (get !featureAttributes [(current_index 1) "derived_feature_code"]) ))
							))
						)
						features_to_derive
					)
			))
		)

		(if !inactiveFeaturesNeedCaching (call !UpdateInactiveFeatures))

		;if expected values haven't been cached (i.e., analyze was skipped), do that here
		(if (= 0 (size !expectedValuesMap))
			(call !CacheExpectedValuesAndProbabilities (assoc
				features features
				weight_feature weight_feature
				use_case_weights use_case_weights
			))
		)

		;set the passed in one as the hyperparam map to use if specified
		(assign (assoc hyperparam_map custom_hyperparam_map))

		;if not using case weights, change weight_feature to '.none'
		(if (= (false) use_case_weights)
			(assign (assoc weight_feature ".none"))
		)

		(if (= (null) hyperparam_map)
			(assign (assoc
				hyperparam_map
					(call !GetHyperparameters (assoc
						context_features features
						feature hyperparameter_feature
						weight_feature weight_feature
					))
			))
		)

		(call !UpdateCaseWeightParameters)

		(assign (assoc
			k_parameter (get hyperparam_map "k")
			p_parameter (get hyperparam_map "p")
			dt_parameter (get hyperparam_map "dt")
			query_feature_attributes_map (get hyperparam_map "featureDomainAttributes")

			;store an assoc of lag/rate/delta feature -> lag/order amount for time series flows
			ts_feature_lag_amount_map (if !tsTimeFeature (call !BuildTSFeatureLagAmountMap))
		))
		(if ts_feature_lag_amount_map
			(assign (assoc max_lag_index_value (apply "max" (values ts_feature_lag_amount_map)) ))
		)

		;if 'case_id' are not specified, use a random 'num_samples' sampling of cases from the whole model
		(if (= 0 (size case_ids))
			(assign (assoc case_ids (call !SelectCaseIdsForResiduals) ))
		)

		;ensure features with nulls have cases that have values for computation but only if the selected cases were not conditioned
		(if (and
				(not using_all_cases)
				(not robust_residuals)
				(not strict_case_ids)
			)
			(let
				(assoc not_null_feature_output_map (call !SelectNonNullCases) )

				(if (size (get not_null_feature_output_map "skip_features_map"))
					(assign (assoc skip_features_map (get not_null_feature_output_map "skip_features_map") ))
				)

				(if (size (get not_null_feature_output_map "non_null_cases"))
					(accum (assoc case_ids (get not_null_feature_output_map "non_null_cases") ))
				)
			)
		)

		;when calculating residuals for the entire model, cache the heuristic residual values if they haven't been cached yet
		(if	(!=
				(list)
				;filter out all the features that are already in !cachedFeatureMinResidualMap. if any remain,
				;that means we need to cache values, may as well recalculate them all since something in the model probalby changed
				(filter
					(lambda (not (contains_index !cachedFeatureMinResidualMap (current_value))))
					features
				)
			)
			(call !CacheFeatureMinGapAndResidual)
		)

		;since residuals cannot be computed, return the max uncertainty for each feature
		;do this check here, after possibly having cached min gaps and residuals above
		(if (< num_training_cases 2)
			(conclude
				(assoc
					"residual_map" (null)
					"ordinal_residual_map" (null)
					"hyperparam_map"
						(accum (assoc
							hyperparam_map
								(assoc
									"featureDeviations"
									(call !ComputeMaxResiduals (assoc
										deviation_features_map  (if target_residual_feature (zip target_residual_feature) (zip features))
									))
								)
						))
				)
			)
		)

		;if there are unique features whose residuals should be computed, remove them from 'features' and update
		;unique_features_for_populating_output to update the output at the end since unique features don't have residuals
		(if (size !uniqueNominalsSet)
			(seq
				(assign (assoc
					unique_features_for_populating_output (indices (keep (zip features) (indices !uniqueNominalsSet)))
				))

				(if (size unique_features_for_populating_output)
					(assign (assoc
						features (indices (remove (zip features) (indices !uniqueNominalsSet)))
					))

					;else reset unique_features_for_populating_output back to null
					(assign (assoc unique_features_for_populating_output (null) ))
				)
			)
		)

		;don't bother using inactive features in any way for residuals
		(if (size !inactiveFeaturesMap)
			(seq
				(assign (assoc excluded_inactive_features_map (keep !inactiveFeaturesMap features) ))
				(assign (assoc
					features (filter (lambda (not (contains_index excluded_inactive_features_map (current_value)))) features)
					context_features (filter (lambda (not (contains_index !inactiveFeaturesMap (current_value)))) context_features)
				))
			)
		)
	)

	;Helper method, return returns a binomial distrubution value for (n, k, p):
	; (gamma(n+1) / (gamma(k+1) * gamma(n-k+1))) * (p**k) * ((1-p)**(n-k))
	; compute in logarithmic space for stability with large values
	#!BinomialDistribution
	(exp
		(+
			(-
				(lgamma (+ n 1))
				(lgamma (+ k 1))
				(lgamma (- n k -1))
			)
			(* k (log p))
			(*
				(- n k)
				(log (- 1 p))
			)
		)
	)

	;helper method for CalculateFeatureResiduals to calculate robust residuals
	#!RunRobustResiduals
	(seq
		;keep a copy of all originally specified features
		(assign (assoc
			case_features
				(values (append context_features features (if !tsTimeFeature [".series_index"] [])) (true))
		))

		;Ensure enough cases
		(if (< (size case_ids) 2000)
			(assign (assoc
				case_ids (rand case_ids 2000)
			))
		)

		;if computing for one target_residual_feature, remove it from features so it's never in the context
		(if target_residual_feature
			(assign (assoc
				context_features (filter (lambda (!= (current_value) target_residual_feature)) context_features)
			))
		)

		;create a map of feature -> flag, set to true if the feature has any null values
		;that way there's no need to explicitly filter nulls out when querying for a feature that no nulls
		;or if it's inactive
		(declare (assoc
			feature_may_have_nulls_map
				(map
					(lambda (and
						(!= (false) (get !featureNullRatiosMap (list (current_index 1) "has_nulls")) )
						(not (contains_index !inactiveFeaturesMap (current_index)) )
					))
					(zip
						(if target_residual_feature
							(list target_residual_feature)
							features
						)
					)
				)
			;create a backup of context_features for time series flows
			original_context_features (if !tsTimeFeature (replace context_features))
			num_features (size context_features)
		))

		;the number of features that will be used as contexts is random for every react, following a binomial distribution.
		;since at least one feature must be predicted, the most number of features that can be used for any react is
		;'(num_features - 1)'  therefore a binomial distribution for '(num_features - 1)' can be used to precompute the
		;probabilities of how many features to use for any react. To undo the bias of those cases that have fewer
		;features selected as contexts being used more often in computations, each probability is scaled down by the number of
		;results (left out features). e.g., if there are 5 features, and all 5 are left out (0 selected), that case will be
		;used 5x as often as a case that had only 1 feature left out (4 selected), so the binomial probability of selecting
		;0 features would be divided by 5, but the probability of selecting 4 features would be divided by 1 and thus left as-is.
		;These normalized scaled probabilities happen to be the same as a binomial distribution for 'num_features'
		;with the tail probability for the last feature cut off.
		;
		;This creates the binomial probabilities map for enabling 0 to (num_features - 1) features, given num_features.
		(declare (assoc
			enabled_num_features_probability_map
				#!ComputeNumEnabledFeaturesProbabilitiesMap
				;map of num_enabled_features -> probability
				(map
					(lambda
						(call !BinomialDistribution (assoc
							k (current_index 1)
							n num_features
							p 0.5
						))
					)
					(zip (range 0 (- num_features 1)))
				)
			all_features_map (zip features)
			feature_deviations
				(if custom_residuals_map
					custom_residuals_map
					(get hyperparam_map "featureDeviations")
				)
		))

		;iterate over each case and accumulate residuals for all the feature(s)
		#!AccumulateFeatureResiduals
		(assign (assoc
			case_residuals_lists
				||(map
					(lambda (let
						(assoc
							case_id (current_value 1)
							;map of feature -> value for all the case values
							case_values_map (zip case_features (retrieve_from_entity (current_value 1) case_features) )
							time_series_filter_query (list)
							feature_weights (get hyperparam_map "featureWeights")
							context_features context_features
						)

						(if !tsTimeFeature
							(assign (assoc
								context_features
									(call !FilterContextsBySeriesIndex (assoc
										all_context_features original_context_features
										series_index (get case_values_map ".series_index")
									))
							))
						)

						;filter out a random number of context features
						(declare (assoc
							react_context_features
								(rand
									context_features
									;number of features to enable is probabilistically weighted
									(if (and !tsTimeFeature (!= (size context_features) num_features))
										(rand
											(call !ComputeNumEnabledFeaturesProbabilitiesMap (assoc num_features (size context_features) ))
										)

										(rand enabled_num_features_probability_map)
									)
									;unique random features (not with replacement)
									(true)
								)
						))

						;assoc of all removed features to their residual values
						(declare (assoc
							removed_features_map
								(if target_residual_feature
									(zip (list target_residual_feature))

									;filter the action features to be those that are not context features, feature/context_features params may overlap
									(remove (zip features) react_context_features)
								)
						))

						(if !tsTimeFeature
							(let
								(assoc context_map (keep case_values_map react_context_features) )
								(if (contains_index context_map !tsTimeFeature)
									(assign (assoc time_series_filter_query (call !ComputeTimeSeriesFilterQuery) ))
								)
							)
						)

						;use dynamic deviations subtrainee if present
						(if (get hyperparam_map "subtraineeName")
							(call !UseDynamicDeviationsAndWeights (assoc
								context_features react_context_features
								context_values (unzip case_values_map react_context_features)
								hyperparam_map hyperparam_map
							))
						)

						(declare (assoc
							local_cases_map
								;if empty context set, use global expected values for all features, set local_cases_map to null
								(if (= 0 (size react_context_features))
									(null)

									;else compute the local model around the case using the robust set of react_context_features
									(compute_on_contained_entities
										(if focal_case
											(query_not_in_entity_list (list (replace case_id) (replace focal_case)))
											(query_not_in_entity_list (list (replace case_id)))
										)
										(if (size context_condition_filter_query)
											context_condition_filter_query
											(list)
										)
										time_series_filter_query
										(query_nearest_generalized_distance
											(replace k_parameter)
											(replace react_context_features)
											(replace (unzip case_values_map react_context_features))
											(replace p_parameter)
											(replace feature_weights)
											(replace !queryDistanceTypeMap)
											(replace query_feature_attributes_map)
											(replace feature_deviations)
											(null)
											(replace dt_parameter)
											(if valid_weight_feature (replace weight_feature) (null))
											(replace tie_break_random_seed)
											(null) ;radius
											(replace !numericalPrecision)
										)
									)
								)
						))

						;create a map of removed feature -> residual value for each removed feature
						(assign (assoc
							removed_features_map
								(map
									#!ComputeFeatureDiff
									(lambda (let
										(assoc
											feature (current_index 1)
											case_feature_value (get case_values_map (current_index 1))
											feature_is_nominal (contains_index !nominalsMap (current_index 1))
											output_categorical_action_probabilities (true)
											categorical_action_probabilities_map (assoc)
											feature_is_edit_distance (contains_index !editDistanceFeatureTypesMap (current_index 1))
											feature_is_non_string_edit_distance (false)
										)

										(if (and feature_is_edit_distance (!= "string_mixable" (get !editDistanceFeatureTypesMap feature)) )
											(assign (assoc feature_is_non_string_edit_distance (true)))
										)

										;create the feature-specific candidate_cases_lists tuple for interpolation
										(declare (assoc
											candidate_cases_lists
												(if (!= (null) local_cases_map)
													(if (get feature_may_have_nulls_map feature)
														(let
															(assoc
																filtered_local_cases_maps
																	(compute_on_contained_entities
																		(query_in_entity_list (indices local_cases_map))
																		(query_not_equals feature (null))
																		(query_exists feature)
																	)
															)

															(if (size filtered_local_cases_maps)
																[
																	(indices filtered_local_cases_maps)
																	(unzip local_cases_map (indices filtered_local_cases_maps))
																	(map (lambda (first (current_value))) (values filtered_local_cases_maps))
																]

																(list
																	[(first (indices local_cases_map))]
																	[(first (values local_cases_map))]
																	[(null)]
																)
															)
														)

														(list
															(indices local_cases_map)
															(values local_cases_map)

															(map (lambda (retrieve_from_entity (current_value) feature)) (indices local_cases_map))
														)
													)
												)
										))

										(call !InterpolateAndComputeDiffToCase)
									))
									removed_features_map
								)
						))

						(declare (assoc
							with_features_map
								(if estimating_residual_lower_bound
									(map
										(call !ComputeFeatureDiff)
										(remove all_features_map (indices removed_features_map))
									)
								)
						))

						;return the computed value for this one feature as a list
						(if target_residual_feature
							(values removed_features_map)

							;output a list of pairs of [ with diff ] : if feature was used in contexts 'with' is (true)
							;and (false) if it was removed from contexts, and 'diff' is the computed diff
							(if estimating_residual_lower_bound
								(map
									(lambda [
										(contains_index with_features_map (current_value 1) )
										(if (contains_index with_features_map (current_value 1) )
											(get with_features_map (current_value 1))
											(get removed_features_map (current_value 1))
										)
									])
									features
								)

								;else output list of: residual value for each removed feature and null for each feature used as a context
								(unzip removed_features_map features)
							)
						)
					))
					case_ids
				)
		))

		;if we only collected residuals for this one feature, set the residuals features list to have only target_residual_feature
		(if target_residual_feature
			(assign (assoc features (list target_residual_feature) ))
		)

		;transpose (turn columns into rows) case_residuals_lists into a list the length of features
		;where each value matches a feature, and is comprised of each feature's residuals, then filter out nulls
		(assign (assoc
			feature_residuals_lists
				#!TransposeResidualLists
				(map
					(lambda (let
						(assoc feature_index (current_index 1) )
						(if leave_nulls_in_results
							;get each column while leaving nulls
							(map
								(lambda (get (current_value) feature_index) )
								case_residuals_lists
							)

							;else get each column and filter out all the nulls
							(filter (map
								(lambda (get (current_value) feature_index) )
								case_residuals_lists
							))
						)
					))
					features
				)
		))

		(declare (assoc
			feature_index_map (zip features (indices features))
		))

		;determine if any of the lists in feature_residuals_lists are too short (< 50 values), if so keep feature as needing to be resampled
		;applicable only to global models (i.e. not regional_data_only)
		(if (not regional_data_only)
			(let
				(assoc
					num_valid_values_per_feature_map
						(filter
							(lambda (< (current_value) min_value_count) )
							(zip
								features
								(map
									(lambda (size
										(if leave_nulls_in_results
											;need to have nulls removed for this part and they weren't if leave_nulls_in_results was true
											;(current_value) is a list of pairs of [with diff], this checks that the diff isn't null
											(if estimating_residual_lower_bound
												(filter (lambda (last (current_value))) (current_value) )
												(filter (current_value))
											)
											;else this is already a filtered list of values
											(current_value)
										)
									))
									feature_residuals_lists
								)
							)
						)
				)

				;some features did not have 50 values, accrue case_ids, then call !the main method agan
				(if (size num_valid_values_per_feature_map)
					(let
						;create the resampled case_ids list that contains cases with enough necessary non-null feature values
						(assoc
							case_ids_without_nulls
								;append all the lists of cases ids for each feature into one list
								(apply "append"
									;for each (current_index) feature, need to find 50 - (current_value) cases to have enough values for those features
									(values (map
										(lambda
											(contained_entities
												(query_not_equals (current_index) (null))

												(if valid_weight_feature
													(query_sample (- min_value_count (current_value)) weight_feature (rand))
													(query_sample (- min_value_count (current_value)) (null) (rand))
												)
											)
										)
										num_valid_values_per_feature_map
									))
								)
						)

						;re-compute residuals on these case_ids, store into case_residuals_lists
						(call !AccumulateFeatureResiduals (assoc case_ids case_ids_without_nulls))

						;transpose case_residuals_lists into a list the length of features and append the results into feature_residuals_lists
						(assign (assoc
							feature_residuals_lists
								(map
									(lambda (append (first (current_value)) (last (current_value))))
									feature_residuals_lists
									(call !TransposeResidualLists)
								)
						))
					)
				)
			)
		)
	)

	;helper method for CalculateFeatureResiduals to calculate full residuals
	#!RunFullResiduals
	(seq
		(declare (assoc context_features_map (zip context_features) ))

		(assign (assoc
			feature_residuals_lists
				||(map
					(lambda (let
						(assoc
							feature (get_value (current_value 1))
							feature_is_nominal (contains_index !nominalsMap (current_value 1))
							feature_is_ordinal (contains_index ordinal_features_map (current_value 1))
							react_context_features (indices (remove context_features_map (current_value 1)))
							feature_is_edit_distance (contains_index !editDistanceFeatureTypesMap (current_value 1))
							feature_is_non_string_edit_distance (false)
							feature_deviations (get hyperparam_map "featureDeviations")
							feature_weights
								(if (= (null) (get hyperparam_map "featureMdaMap"))
									(get hyperparam_map "featureWeights")
									(get hyperparam_map "featureMdaMap")
								)
							needed_features (append context_features (get_value (current_value 1)) (if !tsTimeFeature [".series_index"] []) )
						)

						;filter out rate of change features if deriving the feature
						(if (contains_index features_for_derivation_map feature)
							(assign (assoc
								react_context_features
									(filter
										;stays in context if it is not needed for derivation or if it is not a rate-of-change feature
										;of the feature being predicted (which should just be lags)
										(lambda (or
											(not (contains_value (get features_for_derivation_map feature) (current_value)))
											(!= feature (get !derivedFeaturesMap (current_value)))
											(contains_value (get !tsFeaturesMap "lag_features") (current_value))
										))
										react_context_features
									)
							))
						)

						(if (and feature_is_edit_distance (!= "string_mixable" (get !editDistanceFeatureTypesMap feature)) )
							(assign (assoc feature_is_non_string_edit_distance (true)))
						)

						(declare (assoc
							;if feature has no nulls, no need to ignore it, if it has nulls or nulls are unknown, explicitly ignore nulls in the query
							ignore_null_action_feature
								(and
									(!= (false) (get !featureNullRatiosMap (list feature "has_nulls")))
									(not (contains_index !inactiveFeaturesMap feature) )
								)
							has_time_series_filter_query (and !tsTimeFeature (contains_value react_context_features !tsTimeFeature) )
							time_series_filter_query (list)
							;create a backup of react_context_features for time series flows
							original_react_context_features (if !tsTimeFeature (replace react_context_features))
						))

						(if (contains_index skip_features_map feature)
							(list)

							;else compute residuals for feature
							(map
								(lambda (let
									(assoc
										local_cases_map (assoc)
										case_id (current_value 1)
										case_values_map (zip needed_features (retrieve_from_entity (current_value 1) needed_features))

										output_categorical_action_probabilities (true)
										categorical_action_probabilities_map (assoc)
									)

									(if !tsTimeFeature
										(let
											(assoc original_react_context_features (replace react_context_features))

											(assign (assoc
												react_context_features
													(call !FilterContextsBySeriesIndex (assoc
														all_context_features react_context_features
														series_index (get case_values_map ".series_index")
													))
											))
										)
									)

									;set the filter query if has_time_series_filter already checked that time feature is in context features
									(if has_time_series_filter_query
										(assign (assoc
											time_series_filter_query
												(call !ComputeTimeSeriesFilterQuery (assoc
													context_map (zip react_context_features (unzip case_values_map react_context_features))
												))
										))
									)


									;use dynamic deviations subtrainee if present
									(if (get hyperparam_map "subtraineeName")
										(call !UseDynamicDeviationsAndWeights (assoc
											context_features react_context_features
											context_values (unzip case_values_map react_context_features)
											hyperparam_map hyperparam_map
										))
									)

									(declare (assoc
										candidate_cases_lists
											(compute_on_contained_entities
												(if focal_case
													(query_not_in_entity_list (list case_id focal_case))
													(query_not_in_entity_list (list case_id))
												)
												(if ignore_null_action_feature
													(query_not_equals feature (null))
													(list)
												)
												(if (size context_condition_filter_query)
													context_condition_filter_query
													(list)
												)
												time_series_filter_query
												(query_nearest_generalized_distance
													(replace k_parameter)
													(replace react_context_features)
													(replace (unzip case_values_map react_context_features))
													(replace p_parameter)
													(replace feature_weights)
													(replace !queryDistanceTypeMap)
													query_feature_attributes_map
													(replace feature_deviations)
													(replace feature) ;weight selection
													(replace dt_parameter)
													(if valid_weight_feature (replace weight_feature) (null))
													(replace tie_break_random_seed)
													(null) ;radius
													(replace !numericalPrecision)
													(replace feature)
												)
											)
										case_feature_value (get case_values_map feature)
									))

									(call !InterpolateAndComputeDiffToCase)
								))
								case_ids
							)
						)
					))
					(if target_residual_feature
						(list target_residual_feature)

						;else
						features
					)
				)
		))

		;if we only collected residuals for this one feature, set the residuals features list to have only target_residual_feature
		(if target_residual_feature
			(assign (assoc features (list target_residual_feature) ))
		)

		;filter out nulls
		(assign (assoc
			feature_residuals_lists (map (lambda (filter (current_value)) ) feature_residuals_lists )
		))

	)


	;helper method for RunRobustResiduals, RunFullResiduals, and ComputeDeviations to compute difference between interpolated value and actual case value
	#!InterpolateAndComputeDiffToCase
	(if (contains_index features_for_derivation_map feature)
		;feature must be derived. interpolate necessary features and derive
		(let
			(assoc
				values_for_derivation_map
					(map
						(lambda
							(if (contains_value react_context_features (current_index))
								;use case value if its in the context
								(get case_values_map (current_index))

								;otherwise interpolate among inf. cases
								(call !InterpolateActionValues (assoc
									action_feature (current_index 1)
									candidate_case_ids (first candidate_cases_lists)
									candidate_case_weights (get candidate_cases_lists 1)
									candidate_case_values
										;retrieve the feature to be interpolated from each case
										(map (lambda (retrieve_from_entity (current_value) (current_index 2))) (first candidate_cases_lists))
									allow_nulls (false)
									output_influence_weights (false)
								))
							)
						)
						(zip (get features_for_derivation_map feature))
					)
			)

			(call !ComputeDiffTuple (assoc
				interpolated_value
					(call_sandboxed
						(call !ParseDerivedFeatureCode (assoc
							code_string (get !featureAttributes [feature "derived_feature_code"])
							label_to_code
								(lambda
									(if (= (lambda label_value) 0)
										;pull the feature value
										(get case (lambda label_name))

										(null)
									)
								)
						))
						{"case" values_for_derivation_map}
						!sandboxedComputeLimit !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit (false)
					)
			))
		)

		;else use standard interpolation and diff logic
		(declare
			(assoc
				interpolated_value
					;no candidate cases means we use expected feature value
					(if (= 0 (size (first candidate_cases_lists)))
						;global nominal probabilities will pulled below
						(if feature_is_nominal
							(null)
							;else get continuous expected value
							(call !CalculateFeatureExpectedValue (assoc
								feature feature
								allow_nulls (false)
							))
						)

						;else interpolate the feature value from the local model
						(call !InterpolateActionValues (assoc
							action_feature feature
							candidate_case_ids (first candidate_cases_lists)
							candidate_case_weights (get candidate_cases_lists 1)
							candidate_case_values (last candidate_cases_lists)
							allow_nulls (false)
							output_influence_weights (false)
						))
					)
			)

			;small wrapper around ComputeFeatureMAEDiff, but possibly wrapped in extra information
			;for other prediction stats
			#!ComputeDiffTuple
			(if (= (null) case_feature_value)
				(null)

				compute_all_statistics
				(if feature_is_nominal
					;output [diff, cap, actual, predicted] for computing MAE, accuracy, precision, recall
					(append (call !ComputeFeatureMAEDiff) case_feature_value interpolated_value)

					;else continuous, output [diff, ordinal_diff, actual, predicted] for computing MAE, RSME, R^2
					(and
						(= (null) (- case_feature_value interpolated_value))
						(not feature_is_edit_distance)
					)
					(null)

					;if non-string edit distance feature, wrap code values in a list so the append keeps this output as a tuple
					(if feature_is_non_string_edit_distance
						(append (call !ComputeFeatureMAEDiff) (list case_feature_value) (list interpolated_value))

						(append (call !ComputeFeatureMAEDiff) case_feature_value interpolated_value)
					)
				)

				;else just output diff (Mean Absolute Error)
				#!ComputeFeatureMAEDiff
				(declare
					(assoc
						diff
							(if feature_is_nominal
								(- 1
									(if (size (first candidate_cases_lists))
										(get categorical_action_probabilities_map (list feature case_feature_value))

										;else return expected value
										(get
											(call !ComputeNominalClassProbabilities (assoc feature feature))
											case_feature_value
										)
									)
								)

								;else continuous
								(if feature_is_edit_distance
									;use string edit distance only if it's a string
									(edit_distance case_feature_value interpolated_value
										(or
											(= "string" (get !editDistanceFeatureTypesMap  feature))
											(= "string_mixable" (get !editDistanceFeatureTypesMap  feature))
										)
									)

									(abs (- case_feature_value interpolated_value))
								)
							)
					)

					;output the residual. if it's (null), output null for non-nominals, and 1 (or case weight) for nominals
					(if (= (null) diff)
						(if feature_is_nominal
							(if compute_all_statistics
								[1 (filter (lambda (> (current_value) 0.01)) (get categorical_action_probabilities_map feature))]
								1
							)
						)

						;else output tuple [diff, ordinal_diff] for ordinals, and diff for continuous if applicable
						(contains_index ordinal_features_map feature)
						(let
							(assoc
								ordinal_diff
									(if (!= (null) (get !ordinalFeaturesRangesMap feature))
										(if diff
											(/ diff (get !ordinalFeaturesRangesMap feature))
											0
										)
									)
							)

							;output only diff if computing mda for feature weights during analyze
							;otherwise output the tuple for residual aggregation flows
							(if computing_mda
								diff
								[diff ordinal_diff]
							)
						)

						;else output it as-is
						(if (and feature_is_nominal compute_all_statistics)
							[diff (filter (lambda (> (current_value) 0.01)) (get categorical_action_probabilities_map feature))]

							diff
						)
					)
				)
			)
		)
	)

	;output assoc of 1-based ranks for specified values. duplicates are averaged out
	;parameters:
	;  values: list of values
	#!GetRankMapForValues
	(declare
		(assoc
			values (list)

			;not parameters
			num_dupe 0
			dupe_val (null)
		)

		(zip
			(lambda (seq
				;encountered a new duplicate value, set the initial number of dupes to 1
				(if (!= (current_index) dupe_val)
					(assign (assoc
						num_dupe 1
						dupe_val (current_index 1)
					))
					;else same value is a dupe again, increase number of dupes for this particular value
					(accum (assoc num_dupe 1))
				)

				;average out rank based on number of dupes and round up to nearest integer
				;e.g. if a value has ranks 4 5 6, average out its rank to be 5
				(round (- (current_value) (/ num_dupe 2)) 1)
			))

			(sort values)
			(range 1 (size values))
		)
	)

	;Helper method to compute null uncertainties and accuracies
	; assigns to null_uncertainties_map and null_accuracies_map
	#!ComputeNullUncertainties
	(declare
		(assoc
			;assoc of feature to cases with nulls
			null_cases_map (assoc)
			features_with_nulls (list)
			context_features (list)
		)

		(declare (assoc
			context_map (zip context_features)
			features_list (values (append context_features features_with_nulls) (true))

			;assoc of feature -> number of cases with nulls
			null_cases_counts_map (map (lambda (size (current_value))) null_cases_map)
		))

		;leave only features that have at least 2 cases with nulls
		(declare (assoc
			features_with_at_least_2_nulls
				(filter
					(lambda (> (get null_cases_counts_map (current_value)) 1))
					features_with_nulls
				)
		))

		;output an empty assoc of null deviations
		(if (= 0 (size features_with_at_least_2_nulls))
			(conclude {})
		)

		(if (!= (size features_with_at_least_2_nulls) (size features_with_nulls))
			(assign (assoc
				null_cases_map (keep null_cases_map features_with_at_least_2_nulls)
				features_with_nulls features_with_at_least_2_nulls
			))
		)

		;iterate over all the features with nulls, and predict each feature's case's list
		(assign (assoc
			feature_residuals_lists
				||(map
					(lambda (let
						(assoc
							feature (get_value (current_value 1))
							feature_is_nominal (contains_index !nominalsMap (current_value 1))
							all_react_context_features (indices (remove context_map (current_value 1)))
							null_case_ids (get null_cases_map (current_value 1))
						)

						;need to oversample cases if robust and not many cases
						(if (and
								robust_residuals
								(< (size null_case_ids) 200)
							)
							(assign (assoc null_case_ids (rand null_case_ids 200) ))
						)

						;iterate over list of cases that have nulls for this feature and predict each one,
						;output a list of 1s and 0s where every correctly predicted null is a 1
						(map
							(lambda (let
								(assoc
									case_id (current_value 1)
									case_values_map (zip features_list (retrieve_from_entity (current_value 1) features_list))
									interpolated_value 0
									react_context_features
										(if robust_residuals
											;grab a random set of context features when computing robust residuals
											(filter (lambda (< (rand) 0.5)) all_react_context_features)

											;otherwise use the whole set
											all_react_context_features
										)
								)

								(if (and
										!tsTimeFeature
										(contains_index react_context_features !tsTimeFeature)
									)
									(assign (assoc
										time_series_filter_query
											(call !ComputeTimeSeriesFilterQuery (assoc
												context_map (zip react_context_features (unzip case_values_map react_context_features))
											))
									))
								)

								(declare (assoc
									candidate_cases_lists
										(compute_on_contained_entities
											(if focal_case
												(query_not_in_entity_list (list case_id focal_case))
												(query_not_in_entity_list (list case_id))
											)
											(or time_series_filter_query [])
											(query_nearest_generalized_distance
												(replace (get hyperparam_map "k"))
												(replace react_context_features)
												(replace (unzip case_values_map react_context_features))
												(replace (get hyperparam_map "p"))
												(replace (get hyperparam_map "featureWeights"))
												(replace !queryDistanceTypeMap)
												(replace (get hyperparam_map "featureDomainAttributes"))
												(replace (get hyperparam_map "featureDeviations"))
												(null)
												(replace (get hyperparam_map "dt"))
												(if valid_weight_feature (replace weight_feature) (null))
												(replace tie_break_random_seed)
												(null) ;radius
												(replace !numericalPrecision)
												(replace feature)
											)
										)
								))

								(assign (assoc
									interpolated_value
										;no local_cases_map means we use expected feature value
										(if (size (first candidate_cases_lists))
											(call !InterpolateActionValues (assoc
												action_feature feature
												candidate_case_ids (first candidate_cases_lists)
												candidate_case_weights (get candidate_cases_lists 1)
												candidate_case_values (last candidate_cases_lists)
												allow_nulls (true)
												output_influence_weights (false)
											))

											;else there's no local model, return expected values
											(if feature_is_nominal
												;pull global probability for feature
												(get (call !ComputeNominalClassProbabilities (assoc feature feature)) feature)

												;else get continuous expected value
												(call !CalculateFeatureExpectedValue (assoc feature feature allow_nulls (true) ))
											)
										)
								))

								;output a 1 if predicted a null correctly, else a 0
								(+ (= (null) interpolated_value))
							))
							null_case_ids
						)
					))

					features_with_nulls
				)
		))

		(if use_shared_deviations
			(seq
				(assign (assoc
					feature_residuals_lists (call !PrepSharedDeviations (assoc features features_with_nulls))
				))
				(assign (assoc
					features_with_nulls (filter (lambda (not (contains_value !sharedDeviationsNonPrimaryFeatures (current_value)))) features_with_nulls)
				))
			)
		)

		;create a map of feature -> null prediction probability by averaging out all the correctly predicted nulls for each feature
		(assign (assoc
			null_accuracies_map
				(zip
					features_with_nulls
					(map
						(lambda (generalized_mean (current_value)) )
						feature_residuals_lists
					)
				)
		))

		;compute and cache all min-max values for all features
		(if (= 0 (size !featureMarginalStatsMap))
			(call !CalculateMarginalStats (assoc
				weight_feature (if use_case_weights weight_feature)
			))
		)

		;assoc of feature -> null uncertainty pair of [known-null distance, null-null distance]
		(assign (assoc
			null_uncertainties_map
				(map
					(lambda (let
						(assoc
							feature (current_index 1)
							feature_grouping
								(if (size !sharedDeviationsMap)
									(call !GetSharedDeviationGrouping (assoc feature_group_to_retrieve (current_index 2)))
								)

							;null deviation is: 1 - null prediction probability
							null_prediction_deviation (- 1 (current_value 1))
						)

						;don't allow it to be 0 by setting it to the smallest allowed value
						(if (= 0 null_prediction_deviation)
							(assign (assoc null_prediction_deviation (get !cachedFeatureMinResidualMap feature) ))
						)

						(if (contains_index !nominalsMap feature)
							;for nominals output a list of: null_mismatch, null_prediction_deviation
							[
								;max value that is as reasonably close to 1.0 given the number of cases in the dataset
								;and the sample size used in analyze to compute maximum deviations
								(- 1 (/ 1 (max num_training_cases num_samples)))

								(if (= 1 null_prediction_deviation)
									(- 1 (/ 1 (max num_training_cases num_samples)))
									null_prediction_deviation
								)
							]

							(contains_index !cyclicFeaturesMap feature)
							(list
								(get !cyclicFeaturesMap feature)
								(* (get !cyclicFeaturesMap feature) null_prediction_deviation)
							)

							;for continuous output a list of: max_uncertainty_delta, null_null_uncertainty_delta
							(let
								(assoc
									max_uncertainty
										;compute from the existing feature max-min value or bounds if provided
										(max
											(-
												(if (size feature_grouping)
													(apply "max"
														(filter (map
															(lambda (get !featureMarginalStatsMap (list weight_feature (current_value 1) "max")))
															feature_grouping
														))
													)
													(get !featureMarginalStatsMap (list weight_feature feature "max"))
												)
												(if (size feature_grouping)
													(apply "min"
														(filter (map
															(lambda (get !featureMarginalStatsMap (list weight_feature (current_value 1) "min")))
															feature_grouping
														))
													)
													(get !featureMarginalStatsMap (list weight_feature feature "min"))
												)
											)
											(-
												(if (size feature_grouping)
													(apply "max"
														(filter (map
															(lambda (get !featureBoundsMap (list (current_value 1) "max")))
															feature_grouping
														))
													)
													(get !featureBoundsMap (list feature "max"))
												)
												(if (size feature_grouping)
													(apply "min"
														(filter (map
															(lambda (get !featureBoundsMap (list weight_feature (current_value 1) "min")))
															feature_grouping
														))
													)
													(get !featureBoundsMap (list feature "min"))
												)
											)
										)
								)
								;don't allow nulls, nan or 0 as the max_uncertainty, return null in those situations
								(if max_uncertainty
									(list max_uncertainty (* max_uncertainty null_prediction_deviation))
								)
							)
						)
					))
					null_accuracies_map
				)
		))
	)

	;Helper method that auto converges robust residuals to within the specified convergence_threshold
	;Since all the robust feature residuals are needed after this method is called to compute accuracy contributions,
	;this method accumulates all the robust residuals via ever-increasing batches instead of computing them all at once.
	;Every batch is increased in size by 'convergence_samples_growth_rate', and accumulation is stopped when the new average
	;residual for every feature has a percent delta less than 'convergence_threshold' relative to the running
	;average residual value of the accumulated previous batches.
	#!AutoConvergeRobustResiduals
	(seq

		;when computing robust accuracy contributions via react_aggregate, all possible sampled case_ids will be provided
		;make a copy here and set the index to iteratively grab more cases from this preselected list
		(declare (assoc
			computing_ac_via_react_aggregate (and output_raw_mda (size case_ids))
		))
		(if computing_ac_via_react_aggregate
			(declare (assoc preselected_case_ids (replace case_ids) ))
		)

		;run the first batch of robust residuals, stores them all into feature_residuals_lists
		(call !RunRobustResiduals (assoc
			leave_nulls_in_results (true)
			case_ids
				(if computing_ac_via_react_aggregate
					(trunc preselected_case_ids num_samples)
					case_ids
				)
		))

		;compute the 'previous_residuals_map' by taking the average of all residuals for a feature
		;and storing as an assoc of: feature -> [ avg_residual, count_of_residuals ]
		(declare (assoc
			previous_residuals_map
				(zip
					features
					(map
						(lambda
							;compute the average robust residual for this feature and output as a pair of [ avg_residual, count_of_residuals ]
							;if values are all nulls, this ensures the tuple is output as [0 0]
							[
								(+ (or (generalized_mean (current_value 1)) ))
								(size (filter (current_value 1)))
							]
						)
						feature_residuals_lists
					)
				)
			first_residuals_lists feature_residuals_lists
			done (false)
			total_samples num_samples
		))

		;store all the accumulated residuals from the while loop into feature_residuals_lists to be used later to compute robust accuracy contributions
		(assign (assoc
			feature_residuals_lists
				(while (not done)
					;increase the number sampled each iteration by 'convergence_samples_growth_rate '
					(assign (assoc num_samples (ceil (* convergence_samples_growth_rate  num_samples)) ))
					(accum (assoc total_samples num_samples))

					;don't exceed the specified maximum of num_feature_probability_samples
					(if (> total_samples num_feature_probability_samples)
						(seq
							(assign (assoc
								num_samples (- num_samples (- total_samples num_feature_probability_samples) )
							))
							(accum (assoc total_samples (- num_feature_probability_samples total_samples ) ))
						)
					)

					(call !RunRobustResiduals (assoc
						leave_nulls_in_results (true)
						case_ids
							;if cases were preselected in react_aggregate, grab the next batch according to the index
							(if computing_ac_via_react_aggregate
								(unzip
									preselected_case_ids
									(range (- total_samples num_samples) (- total_samples 1) )
								)

								;else randomly select num_samples cases
								(call !SelectCaseIdsForResiduals)
							)
					))

					;updated residuals map taking into account new values
					(assign (assoc
						residuals_map
							(map
								(lambda (let
									(assoc
										previous_avg_residual (first (first (current_value 1)))
										prev_count (last (first (current_value 1)))
										new_average_residual (first (last (current_value 1)))
										new_count (last (last (current_value 1)))
									)

									;update the running average, by: multipliying the previous residual by the previous count,
									;adding the product of the new residual and the new count, and dividing by the updated total count
									;and store as a pair of [ avg_residual, count_of_residuals ]
									[
										;updated running mean with the new residual values
										(/
											(+
												(* previous_avg_residual prev_count)
												(* new_average_residual new_count)
											)
											(+ prev_count new_count)
										)

										;new total count
										(+ prev_count new_count)
									]
								))

								previous_residuals_map
								;newly computed residuals
								(zip
									features
									(map
										(lambda
											;compute the average robust residual for this feature and output as a pair of [ avg_residual, count_of_residuals ]
											;if values are all nulls, this ensures the tuple is output as [0 0]
											[
												(+ (or (generalized_mean (current_value 1)) ))
												(size (filter (current_value 1)))
											]
										)
										feature_residuals_lists
									)
								)
							)
					))

					;compute deltas for each feature: new running avg vs previous running avg
					(assign (assoc
						deltas_map
							(map
								(lambda (abs
									(- (first (first (current_value ))) (first (last (current_value))))
								))
								previous_residuals_map
								residuals_map
							)
					))

					;stop if values converged or accumulated 'num_feature_probability_samples' reacts
					(if (or
							(>= total_samples num_feature_probability_samples)
							(=
								0
								(size (filter
									;keep those where the delta is > specified %
									(lambda
										(>
											(/ (current_value) (first (get residuals_map (current_index))) )
											convergence_threshold
										)
									)
									deltas_map
								))
							)
						)
						;need to set loop to done to accumulate the last batch of residuals below insead of simply concluding out of the while loop
						(assign (assoc done (true) ))

						;else overwrite previous residuals
						(assign (assoc previous_residuals_map residuals_map))
					)

					;accumulate all the residuals lists for all the features into one big list into (previous_result)
					(map
						(lambda (append (first (current_value)) (last (current_value)) ))

						(if (= 0 (current_index))
							first_residuals_lists
							(previous_result)
						)
						feature_residuals_lists
					)
				)
		))

	)

)