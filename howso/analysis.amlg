;Contains methods for hyperparameter analysis and feature deviation and weights calculations.
(null
	;automatically analyze the model using stored parameters from previous analyze calls
	;{long_running (true) statistically_idempotent (true)}
	#auto_analyze
	(let
		(assoc saved_analyze_parameters_map (retrieve_from_entity "!savedAnalyzeParameterMap"))

		;if this is called before regular analyze, analyze the model as targetless
		(if (= (null) saved_analyze_parameters_map)
			(call analyze (assoc context_features !trainedFeatures))

			(call analyze saved_analyze_parameters_map)
		)
	)


	;Analyzes the data to compute the appropriate statistics, uncertainties, and select parameters as appropriate.
	;{long_running (true) statistically_idempotent (true)}
	#analyze
	(declare
		(assoc
			;{type "list" values "string"}
			;list of context features to analyze
			context_features (list)
			;{type "list" values "string"}
			;list of action features to analyze for. applicable only to 'single_targeted' mode
			action_features (list)
			;{type "number" min 1}
			;number of cross validation folds to do. value of 1 does hold-one-out instead of k-fold
			k_folds 1
			;{type "boolean"}
			;flag, if true will not do any search over k, p, and dt parameters, but still may compute feature residuals
			; depending on other parameters.
			bypass_hyperparameter_analysis (false)
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature residuals
			bypass_calculate_feature_residuals (false)
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature weights
			bypass_calculate_feature_weights (false)
			;{type ["boolean" "null"]}
			;whether to use deviations for LK metric in queries. When true forces the use
			;	of deviations, when false will not use deviations. If unspecified, the better performing option will be selected.
			use_deviations (null)
			;{type "number" min 2}
			;number of cases to use to approximate residuals
			num_samples (null)
			;{type "number" min 2}
			;number of cases to sample during analysis. only applies for k_folds = 1
			num_analysis_samples (null)
			;{type "number" min 2}
			;number of samples to use for analysis. the rest will be randomly held-out and not included in calculations
			analysis_sub_model_size (null)
			;{type "list" values "number"}
			;list of values for k (the number of cases making up a local model) to grid search during analysis
			k_values (null)
			;{type "list" values "number"}
			;list of values for p (the parameter of the Lebesgue space) to grid search during analysis
			p_values (null)
			;{type "list" values ["number" "string"]}
			;list of values for dt (the distance transform) to grid search during analysis
			dt_values (null)
			;{type "string" enum ["single_targeted" "omni_targeted" "targetless"]}
			;enumeration, default is "single_targeted"
			;   "single_targeted" = analyze hyperparameters for the specified action_features
			;   "omni_targeted" = analyze hyperparameters for each action feature, using all other features as context_features. if action_features aren't specified, uses all context_features.
			;   "targetless" = analyze hyperparameters for all context features as possible action features, ignores action_features parameter
			targeted_model "single_targeted"
			;{type "string"}
			;name of feature whose values to use as case weights
			weight_feature ".case_weight"
			;{ref "UseCaseWeights"}
			;when true will scale influence weights by each case's weight_feature weight. if use_case_weights isn't specified, it will
			;	be true if auto ablation is enabled and false otherwise
			use_case_weights (null)
			;{type "list" values "string"}
			;list of features whose values to use to rebalance case weighting of the data and to store into weight_feature
			;cannot be used when auto ablation is enabled
			rebalance_features (null)

			;{type "boolean"}
			;when true, a subtrainee will be created that will be used during queries to approximate deviations of the data around the query.
			; This incurs a penalty in speed, but can improve model performance in long tailed data, especially when using targetless parameters.
			use_dynamic_deviations (false)
			;{type "number" min 2}
			;the number of cases to store within the subtrainee that is used to the deviations of the data around predictions
			dynamic_deviations_subtrainee_size 500
		)

		(call !ValidateParameters)
		(call !ValidateFeatures)

		(if (and
				(size action_features)
				(= (size context_features) 0)
			)
			(conclude
				(call !Return (assoc
					errors ["`context_features` must be specified when `action_features` is specified."]
				))
			)
		)

		;don't allow rebalance_features to be specified if auto ablation is enabled
		(if (and (size rebalance_features) !autoAblationEnabled)
			(conclude
				(call !Return (assoc
					errors ["`rebalance_features` must not be specified when auto ablation is enabled."]
				))
			)
		)

		;analyze uses its own explicit warnings since it should not output warnings from all the
		;react calls made during the analyze flow
		(declare (assoc analyze_warnings (assoc) ))

		(if (and
				(= (null) use_case_weights)
				!hasPopulatedCaseWeight
				(= weight_feature ".case_weight")
			)
			(assign (assoc use_case_weights (true) ))
		)

		(if (or use_case_weights (size rebalance_features))
			;CreateCaseWeights will find all cases missing weight_feature, then initialize
			;weight_feature with a value of 1.0 for each
			(call !CreateCaseWeights (assoc feature_name weight_feature ))
		)

		;if k_folds is not a number value, or it's less than 1, ensure that it's overwritten with the default value
		(if (or (not (= "number" (get_type_string k_folds))) (< k_folds 1))
			(assign (assoc k_folds 1))
		)

		(declare (assoc num_cases (call !GetNumTrainingCases)))

		;cap max k_folds to the number of cases in the model
		(if (> k_folds num_cases)
			(assign (assoc k_folds num_cases))
		)

		;save the parameters that analyze was called with
		(assign_to_entities (assoc
			!savedAnalyzeParameterMap
				(assoc
					"context_features" context_features
					"action_features" action_features
					"k_folds" k_folds
					"k_folds_by_indices" k_folds_by_indices
					"bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
					"bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
					"bypass_calculate_feature_weights" bypass_calculate_feature_weights
					"use_deviations" use_deviations
					"num_samples" num_samples
					"k_values" k_values
					"p_values" p_values
					"dt_values" dt_values
					"targeted_model" targeted_model
					"num_analysis_samples" num_analysis_samples
					"analysis_sub_model_size" analysis_sub_model_size
					"use_case_weights" use_case_weights
					"weight_feature" weight_feature
					"rebalance_features" rebalance_features
				)
		))

		(declare (assoc holdout_entity_name (null) ))

		;if user specified how many samples to use for analysis, randomly hold out the rest
		(if (!= (null) analysis_sub_model_size)
			(let
				(assoc model_size (call !GetNumTrainingCases))

				;analysis_sub_model_size must be at least 2 * number of k_folds otherwise there may be no cases in a fold
				(if (< analysis_sub_model_size (* 2 k_folds))
					(assign (assoc analysis_sub_model_size (* 2 k_folds)))
				)

				(if (> model_size analysis_sub_model_size)
					(assign (assoc
						holdout_entity_name (call !HoldOutRandomCases (assoc num_samples (- model_size analysis_sub_model_size)))
					))
				)
			)
		)

		;if no action features were specified, and neither was targeted_model, set it to targetless
		(if (and
				(= 0 (size action_features))
				(or
					(= (null) targeted_model)
					(= "single_targeted" targeted_model)
				)
			)
			(assign (assoc targeted_model "targetless"))

			;else one or more action features specified but targeted_model wasn't, set it to single_targeted
			(and
				(>= 1 (size action_features))
				(= (null) targeted_model)
			)
			(assign (assoc targeted_model "single_targeted"))

			;if omni_targeted and didn't provide action_features, assume all features are action features
			(and
				(= "omni_targeted" targeted_model)
				(= 0 (size action_features))
			)
			(assign (assoc action_features context_features))

			;default is targetless if inputs are bad
			(not (contains_value (list "targetless" "single_targeted" "omni_targeted") targeted_model))
			(assign (assoc targeted_model "targetless"))
		)

		;if this is a time series Trainee, there are no targetless hyperparameters,
		; and this analyze is targeted, emit a warning to the user that recommends
		; a targeted analyze
		(if (and
				(!= (null) !tsTimeFeature)
				(=
					0
					;the number of saved hyperparameter maps that are targetless
					(size (filter (lambda (= "targetless" (first (current_value))) ) !hyperparameterParamPaths))
				)
				(!= targeted_model "targetless")
			)
			(accum (assoc
				analyze_warnings
					(associate (concat
						"It is recomended to use a \"targetless\" analysis of the data for a time-series Trainee. "
						"Please analyze the data once more with no action features specified and the value \"targetless\" "
						"specified for the \"targeted_model\" parameter."
					))
			))
		)

		;if the bypass hyperparameter analysis flag is null or is false, analyze hyper parameters
		(if (not bypass_hyperparameter_analysis)
			(call !Analyze (assoc
				context_features context_features
				action_features action_features
				k_folds k_folds
				k_values k_values
				p_values p_values
				dt_values dt_values
				use_deviations use_deviations
				k_folds_by_indices k_folds_by_indices
				targeted_model targeted_model
				num_analysis_samples num_analysis_samples
				residual_num_samples (if (> num_samples 0) num_samples 200)
				use_case_weights use_case_weights
				weight_feature weight_feature
				use_dynamic_deviations use_dynamic_deviations
			))
		)

		;only calculate feature residuals if they aren't being bypassed and haven't been calculated above
		(if (and
				(= (false) bypass_calculate_feature_residuals)
				(or bypass_hyperparameter_analysis (!= "targetless" targeted_model))
			)
			(let
				(assoc
					;remove possible duplicates from all_features while mantaining order of features
					all_features (values (append context_features action_features) (true))
				)

				;for targetless flows, there are no action features, so use (null) as the hyperparameter action feature
				(if (= "targetless" targeted_model)
					(assign (assoc action_features [(null)] ))
				)

				(map
					(lambda
						(let
							(assoc
								hyperparam_map
									(call !CalculateResidualsAndUpdateParameters (assoc
										context_features all_features
										;default the num_samples to 1000
										num_samples (if (> num_samples 0) num_samples 1000)
										robust_residuals (= "targetless" targeted_mode)
										;use the specific action feature's hyperparameters
										hyperparameter_feature (current_value 2)
										weight_feature weight_feature
										use_case_weights use_case_weights
										compute_null_uncertainties (false)
										use_shared_deviations (true)
									))
							)

							(if (= (first (get hyperparam_map "paramPath")) ".default")
								;updating default hyperparam set with featuredeviations
								(assign_to_entities (assoc !defaultHyperparameters hyperparam_map) )

								;update the appropriate hyperparameter set
								(assign_to_entities (assoc !hyperparameterMetadataMap (set !hyperparameterMetadataMap (get hyperparam_map "paramPath") hyperparam_map)) )
							)
						)
					)
					action_features
				)
			)
		)

		(if holdout_entity_name
			(call !RestoreHeldOutCases (assoc holdout_entity_name holdout_entity_name))
		)

		(accum_to_entities (assoc !revision 1))

		(call !Return (assoc warnings (if (size analyze_warnings) (indices analyze_warnings)) ))
	)

	;helper method to run the targeted or targetless analyze
	#!Analyze
	(let
		(assoc
			;assoc of case id -> (assoc ".imputed" (list of imputed features))
			imputed_cases_map (compute_on_contained_entities (list (query_exists !internalLabelImputed)))
		)

		;prime caches and update inactive features
		(if !inactiveFeaturesNeedCaching (call !UpdateInactiveFeatures))

		;if any action feature is inactive, do targetless analyze instead
		(declare (assoc
			inactive_action_feature
				(first (filter
					(lambda (contains_index !inactiveFeaturesMap (current_value)))
					action_features
				))
		))
		(if inactive_action_feature
			(seq
				(assign (assoc
					targeted_model "targetless"
					context_features (values (append context_features action_features) (true))
					analyze_warnings
						(associate
							(concat "There are no values to analyze for '" inactive_action_feature "', defaulting to 'targetless'.") (null)
						)
				))
				(assign (assoc action_features [] ))
			)
		)

		(if (!= "omni_targeted" targeted_model)
			(if (or (= "targetless" targeted_model) (= 1 (size action_features)))
				(call !AnalyzeHyperparameters (assoc
					targeted_model targeted_model
					context_features context_features
					action_feature (if (!= "targetless" targeted_model) (first action_features))
				))

				;else single_targeted but with multiple action features, all feature analyze iterations should be 'robust' until the last one which is 'full'
				(map
					(lambda (let
						(assoc
							accumulated_context_features context_features
							action_feature (current_value 1)
						)

						(call !AnalyzeHyperparameters (assoc
							targeted_model "single_targeted"
							context_features accumulated_context_features
							action_feature action_feature
						))

						;accumulate the action feature to the contexts for the next iteration
						(accum (assoc accumulated_context_features action_feature))
					))
					action_features
				)
			)

			;else for omni-targeted, loop over every action feature and analyze each one as 'single_targeted', 'full'
			(map
				(lambda (let
					(assoc
						filtered_context_features (filter (lambda (!= (current_value) (current_value 2))) context_features)
						action_feature (current_value 1)
					)

					(call !AnalyzeHyperparameters (assoc
						targeted_model "single_targeted"
						context_features filtered_context_features
						action_feature action_feature
					))
				))
				action_features
			)
		)

		;reimpute features after analysis and overwrite the values with the newly imputed ones
		(if (size imputed_cases_map)
			(let
				(assoc
					;use all the unique context and action features for imputation, or !trainedFeatures if none were provided
					analyze_features
						(values
							(append (if (= 0 (size context_features)) !trainedFeatures context_features) action_features)
							(true)
						)
				)
				||(map
					(lambda (let
						(assoc
							impute_case_id (current_index 1)
							imputed_features (get (current_value 1) !internalLabelImputed)
							;assoc of all the feature values for this case
							case_feature_value_map (zip analyze_features (retrieve_from_entity (current_index 1) analyze_features) )
						)
						(declare (assoc
							imputed_values
								(map
									(lambda (let
										(assoc impute_feature (current_value 1))
										;don't use the imputed feature in the context for this react, use all others
										(declare (assoc
											impute_context_features (indices (remove case_feature_value_map impute_feature))
										))
										(first
											(call !ReactDiscriminative (assoc
												context_features impute_context_features
												context_values (unzip case_feature_value_map impute_context_features)
												action_features (list impute_feature)
												ignore_case impute_case_id
												;don't encode the input because it's being passed in directly from the case
												skip_encoding (true)
												;don't decode because the output will be stored as-is right afterwards
												skip_decoding (true)
												return_action_values_only (true)
												allow_nulls (false)
												impute_react (true)
											))
										)
									))
									imputed_features
								)
						))

						;overwrite the feature values in this case with the new imputed_values
						(assign_to_entities impute_case_id (zip imputed_features imputed_values))
					))
					imputed_cases_map
				)

				(call !UpdateHasNulls (assoc features analyze_features))
			)
		)

		;if auto ablation is enabled or the user has specifically requested to cache influence weight entropies, do so
		(if
			!autoAblationEnabled
			(seq
				(call !InitializeAutoAblation)
				(call !ComputeAndStoreInfluenceWeightEntropies (assoc
					features
						(if
							(= 0 (size context_features))
							!trainedFeatures
							context_features
						)
				))
			)
		)
	)

	;called on none or one action feature at a time by #Analyze
	; targeted_model: enumeration, default is "single_targeted"
	;   "single_targeted" = analyze hyperparameters for the specified action_features
	;   "targetless" = analyze hyperparameters for all context features as possible action features, ignores action_features parameter
	; context_features: list of context features to analyze for
	; action_features: list of action features to analyze for
	; num_analysis_samples: optional. number of cases to sample during analysis. only applies for k_folds = 1
	; residual_num_samples: optional. initial number of samples to use for computing residuals
	; derived_auto_analyzed: optional, if true, will set the 'derivedAutoAnalyzed' parameter to true in the hyperparameter set,
	;			denoting that these parameters were auto-analyzed during derive features flow.
	#!AnalyzeHyperparameters
	(declare
		(assoc
			targeted_model "targetless"
			context_features (list)
			action_feature (null)
			num_analysis_samples (null)
			residual_num_samples 1000
		)

		(declare (assoc
			num_cases (call !GetNumTrainingCases)
		))
		;can't analyze 1 or 0 cases
		(if (< num_cases 2) (conclude 1) )

		;analyze one action feature at a time (for targeted only)
		(if (!= (null) action_feature)
			(assign (assoc action_features [action_feature] ))
		)

		(declare (assoc
			grid_search_error (null)
			analyzed_hp_map (null)
			previous_analyzed_hp_map (null)
			baseline_hyperparameter_map (null)
			initial_residual_values_map (null)
			context_features_key (null)
			;flag set to true if num_analysis_samples was passed in
			user_specified_num_samples (!= (null) num_analysis_samples)

			;name of deviation subtrainee, will be assigned if subtrainee is stored
			deviation_subtrainee_name (null)
		))
		(call !InitAnalyze)

		(call !UpdateHyperparameters (assoc
			use_weights (false)
			use_deviations (false)
		))

		(if (= "targetless" targeted_model)
			(conclude (seq
				(call !ConvergeTargetless (assoc use_deviations (true)))

				;IRW always needs subtrainee
				(if (and use_dynamic_deviations (not !useDynamicDeviationsDuringAnalyze))
					; store feature residuals for a collection of cases at end, if it wasn't part of iterative process
					(call !StoreResidualSubTrainee (assoc custom_hyperparam_map baseline_hyperparameter_map) )
				)

				(call !SetModelHyperParameters)
			))
		)

		(call !GridSearch)

		(call !ComputeAndUseWeights)
		(call !TestAccuracyAndKeepOrRevertHyperparameters)  ;w or w/o weights

		(if (= (false) use_deviations) (conclude (call !SetModelHyperParameters)) )

		(declare (assoc non_deviation_hp_map baseline_hyperparameter_map))

		;deviations, no weights
		(call !UpdateHyperparameters (assoc
			use_weights (false)
			use_deviations (true)
			feature_deviations (call !ComputeInitialDeviations)
		))
		(call !ConvergeResiduals (assoc use_deviations (true)))
		(call !GridSearch)

		;now with weights
		(call !ComputeAndUseWeights)
		(call !TestAccuracyAndKeepOrRevertHyperparameters) ;deviations w or w/o weights

		;if use of deviations should be auto determined, do that here, compare to non_deviation hyperparameters
		;and revert if to non-deviation if those were as good or better
		(if (= (null) use_deviations)
			(if (<= (get non_deviation_hp_map "gridSearchError") (get baseline_hyperparameter_map "gridSearchError"))
				(assign (assoc baseline_hyperparameter_map non_deviation_hp_map))

				;residuals were converged using non_deviation parameters, if the currently analyzed k or p are different
				;we re-converge the residuals using these updated p and k
				(or
					(!= (get non_deviation_hp_map "p") (get baseline_hyperparameter_map "p"))
					(!= (get non_deviation_hp_map "k") (get baseline_hyperparameter_map "k"))
				)
				(call !ConvergeResiduals)
			)
		)

		(if (and
				use_dynamic_deviations
				;need the subtrainee if using deviations
				(get baseline_hyperparameter_map "featureDeviations")
				(not !useDynamicDeviationsDuringAnalyze)
			)
			; store feature residuals for a collection of cases at end, if it wasn't part of iterative process
			(call !StoreResidualSubTrainee (assoc custom_hyperparam_map baseline_hyperparameter_map) )
		)

		(call !SetModelHyperParameters)
	)

	;helper method for Analyze that stores a subtrainee of case residuals for each feature
	;parameters:
	;	custom_hyperparam_map: the hyperparam map within analyze that should be used to run the residuals
	;	num_samples: the number of cases to put in the residual subtrainee, default 500
	;assigns to:
	;	deviation_subtrainee_name: this variable will store the name of the subtrainee, this name should be stored in the
	;					resulting hyperparameter assoc under the key "subtraineeName"
	#!StoreResidualSubTrainee
	(declare
		(assoc
			custom_hyperparam_map (null)
			num_samples dynamic_deviations_subtrainee_size

			;not parameters, variables for Residuals code
			case_ids (null)
			features
				;filter the context features to get just continuous
				(filter
					(lambda (= "continuous" (get !featureAttributes [(current_value 1) "type"])))
					context_features
				)
			k_parameter (null)
			p_parameter (null)
			dt_parameter (null)
			query_feature_attributes_map (null)
			case_features (null)
			num_context_features 0
			ordinal_features_map (zip !ordinalFeatures)
			hyperparam_map (assoc)
			residuals_map (assoc)
			ordinal_residuals_map (assoc)
			;assoc of features to skip computing non-robust residuals for if they don't have enough non-null values
			skip_features_map (assoc)
			;list, length of case_ids, each item will be a list of residual values, one per feature
			case_residuals_lists (list)
			;list, length of features, each item will be a list of residuals, one per case
			feature_residuals_lists (list)

			num_training_cases (call !GetNumTrainingCases)
			valid_weight_feature (false)

			features_with_nulls (list)
			null_feature_cases_map (assoc)
		)

		(call !InitResiduals)

		(if (= targeted_model "targetless")
			(call !RunAccurateResiduals)

			;targeted runs full residuals to match targeted flow
			(call !RunFullResiduals)
		)

		(assign (assoc
			deviation_subtrainee_name
				(if (contains_index custom_hyperparam_map "subtraineeName")
					(get custom_hyperparam_map "subtraineeName")

					(concat "ResidualSubTrainee" (round (* 100000 (rand)) (null) 0))
				)
		))

		;delete the previous subtrainee, might be smarter to just remove cases in the future
		(if (contains_index (call !GetHierarchy) deviation_subtrainee_name)
			(call delete_subtrainee (assoc path [deviation_subtrainee_name] ))
		)

		(call create_subtrainee (assoc
			path [deviation_subtrainee_name]
			child_id deviation_subtrainee_name
		))

		(set_entity_root_permission [!traineeContainer deviation_subtrainee_name] (true))

		;add a method to remove !ValidateParameters
		(accum_entity_roots [!traineeContainer deviation_subtrainee_name]
			(zip_labels
				(list "removeValidateParameters")
				(list (lambda
					(assign_to_entities
						(assoc
							"!ValidateParameters" (null)
							"removeValidateParameters" (null)
						)
					)
				))
			)
		)
		;remove the methods
		(call_entity [!traineeContainer deviation_subtrainee_name] "removeValidateParameters")

		(call_entity [!traineeContainer deviation_subtrainee_name] "set_feature_attributes" (assoc
			feature_attributes !featureAttributes
		))

		(call_entity [!traineeContainer deviation_subtrainee_name] "train" (assoc
			features
				;a list of feature names and feature residual names
				(append
					context_features
					(map
						(lambda
							(concat "." (current_value) "_residual")
						)
						features
					)
				)
			cases
				;list of [case values and feature residuals]
				(map
					(lambda
						(append
							;case values
							(retrieve_from_entity (current_value) context_features)
							;residuals
							(map
								(lambda
									;get the feature index, case_index
									(get feature_residuals_lists [(current_index 1) (current_index 2)])
								)
								features
							)
						)
					)
					case_ids
				)
			allow_training_reserved_features (true)
		))

		;and analyze the subtrainee
		(call_entity [!traineeContainer deviation_subtrainee_name] "analyze")
	)

	;initialize variables and cache feature expected values
	#!InitAnalyze
	(seq
		(if (!= (null) action_feature)
			;DiscriminativeReact will use context values for action features if provided
			;so the action feature cannot also be a context feature, otherwise predictions will
			;always be correct in analyze, leading to errors of zero.
			;this is, until TODO 17214: is complete, which adds override contexts flag to react
			(assign (assoc
				context_features (filter (lambda (!= action_feature (current_value))) context_features)
			))
		)

		;if analyze is being called without any context features, default them to the full set of all features
		;targeted_model will already have be set to 'targetless' if no features are passed in
		(if (= 0 (size context_features))
			(assign (assoc
				context_features !trainedFeatures
				context_features_key !trainedFeaturesContextKey
			))

			;else build custom context feature key
			(assign (assoc context_features_key (call !BuildContextFeaturesKey (assoc context_features context_features)) ))
		)

		;if auto ablation is on and the user has not overridden the default, set use_case_weights to true
		(if (and !autoAblationEnabled (!= (false) use_case_weights) )
			(assign (assoc use_case_weights (true)) )
			;otherwise, if the user hasn't overridden the default, set use_case_weights to be false
			; to ensure this change works smoothly throughout the rest of the engine
			(= (null) use_case_weights)
			(assign (assoc use_case_weights (false)) )
		)

		;if user doesn't want to use case weights, change weight_feature to '.none'
		(if (not use_case_weights)
			(assign (assoc weight_feature ".none"))

			;else compute id-based case weights
			(seq
				(if (size rebalance_features)
					(call !ComputeAndStoreIdFeatureCaseWeights (assoc id_features rebalance_features))
				)

				;if there are no id features and user didn't specify a custom weight feature, treat as without case weight
				(if (and (not !hasPopulatedCaseWeight) (= weight_feature ".case_weight"))
					(seq
						(assign_to_entities (assoc !hasPopulatedCaseWeight (true)))
						(call !StoreCaseValues (assoc
							case_values_map (zip (call !AllCases) 1)
							label_name weight_feature
						))
					)
				)
			)
		)

		(assign (assoc
			baseline_hyperparameter_map (replace (retrieve_from_entity "!defaultHyperparameters"))
		))

		;if using default targetless hyperparameters, set p to 1 as the starting p value
		(if (and
				(= "targetless" targeted_model)
				(= [".default"] (get baseline_hyperparameter_map "paramPath"))
			)
			(assign (assoc
				baseline_hyperparameter_map
					(set
						baseline_hyperparameter_map
						"k" 21
						"p" 1
						"dt" "surprisal_to_prob"
					)
			))
		)

		;store the paramPath for this hyperparameter set so it has a reference to where it's stored in !hyperparameterMetadataMap
		(accum (assoc
			baseline_hyperparameter_map
				(assoc
					"paramPath"
						(append
							(if action_feature ["targeted" action_feature] ["targetless"])
							context_features_key
							weight_feature
						)
				)
		))

		;check if auto analysis is enabled and the analysis threshold should be increased
		(if (and
				!autoAnalyzeEnabled
				(>= !dataMassChangeSinceLastAnalyze !autoAnalyzeThreshold)
			)
			(let
				(assoc
					total_case_mass
						(if use_case_weights
							(compute_on_contained_entities (list
								(query_not_equals weight_feature (null))
								(query_sum weight_feature)
							))

							;else it's 1 per case, thus the total mass is num_cases
							num_cases
					)
				)

				(assign_to_entities (assoc
					!autoAnalyzeThreshold
						;!autoAnalyzeThreshold is a delta from the previous threshold.
						;if several case deletions cause the above formula to return < 0, default
						; to the default !autoAnalyzeThreshold.
						(max
							(- (* total_case_mass !autoAnalyzeGrowthFactorAmount) !autoAnalyzeThreshold)
							100
						)
				))
			)
		)

		;reset !dataMassChangeSinceLastAnalyze since we are now analyzing
		(assign_to_entities (assoc !dataMassChangeSinceLastAnalyze 0.0 ))

		;for k_folds = 1, set the default num_analysis_samples to be 1000
		(if (and (= 1 k_folds) (= (null) num_analysis_samples ))
			(assign (assoc num_analysis_samples 1000))
		)


		;pre-compute and cache all the expected feature values and nominal probabilities so that they don't have to be
		;lazy computed later during residual computations
		(assign_to_entities (assoc
			!expectedValuesMap (assoc)
			!nominalClassProbabilitiesMap (assoc)
			!cachedFeatureMinResidualMap (assoc)
			!cachedFeatureHalfMinGapMap (assoc)
			!featureNullRatiosMap (assoc)
		))

		(call !CacheExpectedValuesAndProbabilities (assoc
			features (values (append context_features action_features) (true))
			weight_feature weight_feature
			use_case_weights use_case_weights
		))
	)

	;updates baseline_hyperparameter_map
	;wrapper method to grid searches hyperparameters and backs up the results into previous_analyzed_hp_map
	#!GridSearch
	(seq
		(set_rand_seed sampling_random_seed)
		(assign (assoc
			analyzed_hp_map
				(call !ComputeResidualsAcrossParametersAndSelectOptimal (assoc
					context_features context_features
					action_features action_features
					k_folds k_folds
					k_values k_values
					p_values p_values
					dt_values dt_values
					k_folds_by_indices k_folds_by_indices
					num_analysis_samples num_analysis_samples
					targetless (= targeted_model "targetless")
					baseline_hyperparameter_map baseline_hyperparameter_map
				))
		))
		(call !BackupAnalyzedHyperparameters)
	)

	;autotunes the model to use the 'best' hyperparameters using grid-search (with optional k-fold cross validation)
	;outputs updated hyperparameter map
	;parameters:
	; context_features: list of context features
	; action_features: list of action features for action inputs
	; k_folds: number of cross validation folds to do. value of 1 does hold-one-out instead of k-fold
	; k_values : optional list of k values to grid search, if null will use default list.
	; p_values : optional list of p values to grid search, if null will use default list.
	; dt_values : optional list of distance transform values to grid search.
	;		Can specify "surprisal_to_prob" as a valid distance transform value to use surprisal in the transform. if null will use -1.
	; use_k_values: optional flag default true. if false, will use k value specified in 'baseline_hyperparameter_map'
	; use_p_values: optional flag default true. if false, will use p value specified in 'baseline_hyperparameter_map'
	; use_dt_values: optional flag default true. if false, will use dt value specified in 'baseline_hyperparameter_map'
	; p_param_categorical_mean : optional parameter to specify the lp space for calculating the mean of Mean Absolute Errors for categorical features
	; p_param_accuracy_mean : optional parameter to specify the lp space for calculating the mean of Mean Absolute Errors among all features
	; k_folds_by_indices : optional flag, if true will do k_folds ordered by session id indices
	; targetless : optional flag, if true will randomly select a context feature as an action feature for each case during grid search
	; num_analysis_samples : optional. number of cases to sample during analysis. only applies for k_folds = 1
	; baseline_hyperparameter_map : the base hyperparameters to use for computation
	#!ComputeResidualsAcrossParametersAndSelectOptimal
	(declare
		(assoc
			action_features (list)
			context_features (list)
			k_folds 1
			k_values (null)
			p_values (null)
			dt_values (null)
			use_k_values (true)
			use_p_values (true)
			use_dt_values (true)
			p_param_categorical_mean 1
			p_param_accuracy_mean 0.2
			k_folds_by_indices (false)
			targetless (false)
			num_analysis_samples (null)
			baseline_hyperparameter_map (assoc)
		)

		;can't do analysis if there is a max of one context feature provided and no different action features
		(if (and
				(< (size context_features) 2)
				(or
					;no action features, or the one context feature is also the action feature
					(= (size action_features) 0)
					(= context_features action_features)
				)
			)
			;return valid existing hyperparameters
			(conclude baseline_hyperparameter_map)
		)

		(if (= (null) k_values)
			(assign (assoc
				k_values
					;grid search fibonacci sequence
					(if (= targeted_model "targetless")
						[5 21 34]

						[3 5 8 13 21 34 55 89 144]
					)
			))
		)
		(if (= (null) p_values)
			(assign (assoc
				p_values
					(if (= targeted_model "targetless")
						[1]

						[0.1 0.5 1 2]
					)
			))
		)

		;if dt is null, default it to -1, if it's empty list set it to the recommended default search list
		(if (= (null) dt_values )
			(assign (assoc
				dt_values
					(if (= targeted_model "targetless")
						["surprisal_to_prob"]

						[-1]
					)
			))

			(= (list) dt_values)
			(assign (assoc dt_values (list -8 -2 -1 -0.5 0)))
		)

		;if the dataset is smaller than the max K value, reduce the possible k_values search
		(declare (assoc smallest_k (first (sort k_values)) ))
		(if (<= num_cases (apply "max" k_values))
			(assign (assoc k_values (filter (lambda (< (current_value) num_cases)) k_values)))
		)
		;if there are no valid k_values because they have all been filtered out, use the smallest one
		(if (= (list) k_values)
			(assign (assoc k_values (list smallest_k)))
		)

		;ensure the k_values are sorted largest to smallest,(ie there's a knn cache internally, when the largest K value is processed and cached
		;subsequent calls with smaller Ks will be fast)
		(assign (assoc k_values (sort (lambda (> (current_value 1) (current_value))) k_values)))

		(if (not use_k_values)
			(assign (assoc k_values (list (get baseline_hyperparameter_map "k"))))
		)
		(if (not use_p_values)
			(assign (assoc p_values (list (get baseline_hyperparameter_map "p"))))
		)
		(if (not use_dt_values)
			(assign (assoc dt_values (list (get baseline_hyperparameter_map "dt"))))
		)

		(declare (assoc
			;a map of   { k_p_dt : {  k: K, p: P, dt: DT, dist: [ ...] } }
			accumulated_results_map (assoc)
			p_k_dt_key (null)
			;if k-folds == 1 and num_analysis_samples is provided, randomly sample those cases here
			sample_case_ids
				(if (!= (null) num_analysis_samples)
					(call !AllCases (assoc num num_analysis_samples rand_seed (rand)))
					(null)
				)
			best_accuracy_distance .infinity
			best_params_key (null)
			output_map (assoc)
			;list of features to match each case, specific for targetless flow
			case_feature_list (list)
		))

		;targetless flow
		(if targetless
			(seq
				;only consider active features that have > 1 non-null value and aren't 'unique'
				;can't compute error for features with only unique values or features with < 2 values
				(assign (assoc
					action_features
						(filter
							(lambda (and
								(not (contains_index !inactiveFeaturesMap (current_value)))
								(not (contains_index !uniqueNominalsSet (current_value)))
								(>
									;count of all the non-null cases
									(size (contained_entities [ (query_not_equals (current_value 1) (null)) ] ))
									1
								)
							))
							;action_features are empty for targetless, select them from the set of context features
							context_features
						)
				))

				(if (size action_features)
					(seq
						;select features at random, num_analysis_samples worth (or num_cases/2 * sqrt(num_features) for smaller datasets)
						;to be more sensitive to the number for features instead of the number of cases for smaller datasets
						(assign (assoc
							case_feature_list
								(range
									(lambda (rand action_features))
									1
									(if user_specified_num_samples
										num_analysis_samples

										(max
											;statistical minimum for tiny datasets
											30
											(min
												(* 0.5 num_cases (sqrt (size action_features)))
												num_analysis_samples
											)
										)
									)
									1
								)
							valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")) )
						))

						;pick a case at random for every randomly selected feature with a non-null value
						(assign (assoc
							sample_case_ids
								(map
									(lambda
										(first
											(contained_entities (list
												(query_not_equals (current_value 1) (null))
												(if valid_weight_feature
													(query_weighted_sample weight_feature 1)
													(query_sample 1)
												)
											))
										)
									)
									case_feature_list
								)
						))
					)

					;else dataset has no valid features to test
					(assign (assoc
						sample_case_ids (list)
						case_feature_list (list)
					))
				)
			)
		)

		;grid search over the P, K and DT values
		;
		;foreach p:
		;	foreach k:
		;		foreach dt:
		;			calculate MAE for each action feature
		;	best = choose the one with the best validation error (lowest MAE among all features)
		(if (= k_folds 1)
			(call !AccumulateErrorsViaGridSearch)

			;else do k-fold validation, where each fold iterates over p k and dt and accumulates errors
			(call !AccumulateErrorsViaKFoldsGridSearch)
		)

		;convert the list of distances for each hyperparameter tuple into an avg distance
		;and while iterating store the best (smallest) distance and corresponding key
		(assign (assoc
			accumulated_results_map
				(map
					(lambda (let
						(assoc avg_distance (/ (apply "+" (get (current_value 1) "distances")) k_folds))

						(if (< avg_distance best_accuracy_distance)
							(assign (assoc
								best_accuracy_distance avg_distance
								best_params_key (current_index 1)
							))
						)

						;overwrite 'distances' with the average of the distances
						(set (current_value) "distances"
							avg_distance
						)
					))
					accumulated_results_map
				)
		))

		;sort the best params that all have the same 'best' accuracy distance by their P value
		(declare (assoc
			best_params
				(sort
					(lambda (< (get (current_value 1) "p") (get (current_value) "p")))
					(filter (lambda (= (get (current_value) "distances") best_accuracy_distance)) (values accumulated_results_map))
				)
			best_p (get accumulated_results_map (list best_params_key "p"))
		))

		;sort the best remaining params that have all the same 'best' p and accuracy distance by their K value
		(assign (assoc
			best_params
				(sort
					(lambda (< (get (current_value 1) "k") (get (current_value) "k")))
					;filter out all params that did not have a matching p
					(filter (lambda (= (get (current_value) "p") best_p)) best_params)
				)
		))

		;at this point best_params should either have one set, that we can use, or it's sorted by K values, take the median in that case
		(assign (assoc
			best
				(if (= (size best_params) 0)
					(first best_params)

					;take the median value
					(get best_params (floor (/ (size best_params) 2)))
				)

		))

		(assign (assoc
			output_map
				(assoc
					"k" (get best "k")
					"p" (get best "p")
					"dt" (get best "dt")
					;store the accuracy of this grid search
					"gridSearchError" (get best "distances")
				)
		))

		;output updated hyperparam map
		(append
			baseline_hyperparameter_map

			output_map
		)
	)

	;output model Mean Absolute Error (MAE) for the provided baseline_hyperparameter_map
	#!ComputeModelResidualForParameters
	(seq
		(if targetless (assign (assoc action_features context_features)))

		(declare (assoc
			sample_case_ids
				(if (!= (null) num_analysis_samples)
					(call !AllCases (assoc num num_analysis_samples rand_seed (rand)))
				)
			accumulated_kfold_errors (list)
		))

		(if (= k_folds 1)
			(call !CalculateModelMAE (assoc
				action_features action_features
				context_features context_features
				case_ids sample_case_ids
				ignore_exact_cases (true)
				;TODO: make a passthrough flag from api, story 7421
				robust_residuals (false)
				custom_hyperparam_map baseline_hyperparameter_map
				use_case_weights use_case_weights
				weight_feature weight_feature
			))

			;else do k-fold, average out the value across the k-folds
			(seq
				;The method ComputeAndAccumulateKFoldsMAE accumulates all k_fold maes into 'accumulated_kfold_errors'
				(call !AccumulateErrorsViaKFoldsGridSearch (assoc accumulate_error_method "!ComputeAndAccumulateKFoldsMAE"))
				(/ (apply "+" accumulated_kfold_errors) k_folds)
			)
		)
	)

	;accumulate model MAE during kfold validation using provided baseline_hyperparameter_map
	#!ComputeAndAccumulateKFoldsMAE
	(accum (assoc
		accumulated_kfold_errors
			(call !CalculateModelMAE (assoc
				action_features action_features
				context_features context_features
				case_ids validation_case_ids
				cases_already_removed (true)
				;TODO: make a passthrough flag from api, story 7421
				robust_residuals (false)
				custom_hyperparam_map baseline_hyperparameter_map
				use_case_weights use_case_weights
				weight_feature weight_feature
			))
	))

	;doing k-fold validation, so each validation block is 1/k_folds of all the cases
	#!AccumulateErrorsViaKFoldsGridSearch
	(declare
		(assoc
			validation_size
				(if (> k_folds 1)
					(/ num_cases k_folds)
					.infinity
				)
			;name of method to use for accumulating MAE, default to use accumulation during grid search
			accumulate_error_method "!AccumulateErrorsViaGridSearch"
		)

		;temporary entity storage for the validation cases
		(create_entities "_temp_" (null))

		;do k-fold cross validation by taking out k even chunks of all the cases and then validating on each one
		(map
			(lambda (let
				(assoc
					;as we iterate over values of 0 through (k_folds - 1), grab the corresponding 1st, 2nd, etc chunk of all cases by their indices
					;generate a list of indices that's validation_size in length, and starts at the correct offset based on
					;which k-folk "chunk" is being tested as specified by (current_value)
					validation_case_ids
						(if k_folds_by_indices
							(contained_entities (list
								(query_exists !internalLabelSession)
								(query_between !internalLabelSessionTrainingIndex
									(* (current_value 2) validation_size)
									(- (+ validation_size (* (current_value 2) validation_size)) 1)
								)
							))

							(call !AllCases (assoc
								num validation_size
								start_offset (* (current_value 2) validation_size)
							))
						)
					p_k_dt_key (null)
				)

				;move this chunk of validation cases into _temp_ so that they aren't in the model during the reaction/validation process
				(map
					(lambda (move_entities (current_value) (list "_temp_" (current_value 1))) )
					validation_case_ids
				)

				;call !the method to compute the error
				(call (retrieve_from_entity accumulate_error_method))

				;restore the validation cases from backup
				(map
					(lambda (move_entities (list "_temp_" (current_value 1)) (current_value)) )
					validation_case_ids
				)
			))
			;k-fold, 0-based indexing
			(range 0 (- k_folds 1))
		)

		;no longer need the temporary entity container
		(destroy_entities "_temp_")
	)

	#!AccumulateErrorsViaGridSearch
	(map
		(lambda (let
			(assoc p_value (current_value 1))

			(map
				(lambda (let
					(assoc  k_value (current_value 1))
					(map
						(lambda (let
							(assoc
								dt_value (current_value 1)
								mae_hyperparam_map baseline_hyperparameter_map
							)

							;overwrite the k/p/dt
							(accum (assoc
								mae_hyperparam_map (assoc "p" p_value "k" k_value "dt" dt_value)
							))

							;accumulate the accuracy distance for each set of parameters
							(declare (assoc
								accuracy_distance
									;else do k-fold cross validation if K is specified, otherwise do 1-by-1 knockout
									(if (> k_folds 1)
										;iterate over all the validation_case_ids and react to each one
										;returning the mean absolute error (MAE) for each action feature
										(call !CalculateModelMAE (assoc
											action_features action_features
											context_features context_features
											p_param_categorical_mean p_param_categorical_mean
											p_param_accuracy_mean p_param_accuracy_mean
											case_ids validation_case_ids
											cases_already_removed (true)
											;TODO: make a passthrough flag from api, story 7421
											robust_residuals (false)
											custom_hyperparam_map mae_hyperparam_map
											use_case_weights use_case_weights
											weight_feature weight_feature
										))

										;else do hold-one-out validation
										(call !CalculateModelMAE (assoc
											action_features action_features
											context_features context_features
											case_ids sample_case_ids
											case_feature_list case_feature_list
											ignore_exact_cases (true)
											;TODO: make a passthrough flag from api, story 7421
											robust_residuals (false)
											custom_hyperparam_map mae_hyperparam_map
											use_case_weights use_case_weights
											weight_feature weight_feature
										))
									)
							))

							(assign (assoc p_k_dt_key (concat p_value k_value dt_value)))

							;a map of   { k_p_dt_key : {  k: K, p: P, dt: DT, dist: [ ...] } }
							(assign (assoc
								accumulated_distances
									(if (= (null) (get accumulated_results_map (list p_k_dt_key "distances")))
										(list accuracy_distance)

										(append
											(get accumulated_results_map (list p_k_dt_key "distances"))
											accuracy_distance
										)
									)
							))

							;store both the distance calculated using the p value and the geometric mean
							(accum (assoc
								accumulated_results_map
									(associate
										p_k_dt_key
											(assoc
												"k" k_value
												"p" p_value
												"dt" dt_value
												"distances" accumulated_distances
											)
									)
							))
						))
						dt_values
					)
				))
				k_values
			)
		))
		p_values
	)

)