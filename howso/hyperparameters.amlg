;Contains helper methods for hyperparameter maintenance.
(null

	; contains, p, k, dt, gridSearchError, etc
	#!BackupAnalyzedHyperparameters
	(assign (assoc
		previous_analyzed_hp_map analyzed_hp_map
		baseline_hyperparameter_map analyzed_hp_map
	))

	;updates baseline_hyperparameter_map
	#!KeepOrRevertHyperparameters
	(if (<= (get previous_analyzed_hp_map "gridSearchError") (get analyzed_hp_map "gridSearchError"))
		(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

		;else update with analyzed
		(assign (assoc baseline_hyperparameter_map analyzed_hp_map))
	)

	;updates baseline_hyperparameter_map
	#!UpdateHyperparameters
	(declare
		(assoc
			use_weights (null)
			feature_weights (null)
			use_deviations (null)
			feature_deviations (null)
			null_deviations (null)
			ordinal_feature_deviations (null)
			attribute_map (assoc)
			confusion_matrix_map (null)
		)

		(if (size confusion_matrix_map)
			(assign (assoc
				feature_deviations
					(map
						;convert deviations for nominals that had a confusion matrix computed from a single value into an assoc
						;containing the nominal deviation as 'expected_deviation' and a sparse deviation matrix as 'sdm'
						(lambda
							(if (contains_index confusion_matrix_map (current_index))
								(let
									(assoc feature (current_index 1) )
									(declare (assoc
										sdm
											##SparseDeviationMatrix
											(call !ConfusionMatrixToSDM (assoc
												confusion_matrix (get confusion_matrix_map [feature "matrix"])
												feature feature
												expected_deviation (current_value 2)
											))
									))

									;output an assoc of sdm and expected deviation
									(if sdm
										(assoc
											"sdm" sdm
											"expected_deviation" (current_value 1)
										)

										;else there is no sdm, return just the value
										(current_value)
									)
								)

								;else leave deviation value as-is
								(current_value)
							)
						)
						feature_deviations
					)
			))
		)

		(accum (assoc
			attribute_map
				(append
					;if clearing weights, set them to null
					(if (= (false) use_weights)
						;if there are inactive features, we have to reset active features to 1s and inactives to 0s
						(if !inactiveFeaturesMap
							(assoc "featureWeights"
								(append
									(zip
										(indices (get baseline_hyperparameter_map "featureWeights"))
										1
									)
									!inactiveFeaturesMap
								)
							)

							;else null out the weights
							(assoc "featureWeights" (null))
						)

						(assoc)
					)
					(if feature_weights
						(assoc "featureWeights" feature_weights)
						(assoc)
					)
					(if use_deviations
						(assoc
							"featureDeviations"
								;append null_deviations to feature_deviations
								(if (size null_deviations)
									(map
										(lambda
											;create a tuple of [deviation, value<->null uncertainty, null<->null uncertainty]
											(if (size (last (current_value)))
												;if the deviation is an assoc (nominal feature with SDM), ensure the result is a triple
												(if (~ (assoc) (first (current_value)))
													(append (list (get (current_value 1) (list 0 "sdm"))) (last (current_value)) )

													(append (first (current_value)) (last (current_value)) )
												)

												;else return the deviation value without the known-unkwnown uncertainties
												;an assoc means this is a SDM
												(if (~ (assoc) (first (current_value)))
													;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
													[(get (current_value 1) [0 "sdm"])]

													(first (current_value))
												)
											)
										)
										feature_deviations
										null_deviations
									)

									;else just store provided deviations, but pull the sdm out to store as-is
									(map
										(lambda
											;an assoc means this is a SDM
											(if (~ (assoc) (current_value))
												;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
												[(get (current_value 1) "sdm")]

												(current_value)
											)
										)
										feature_deviations
									)
								)
						)

						;if not using deviations but provided null uncertainties, use those as deviations
						(size null_deviations)
						(assoc
							"featureDeviations"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (current_value))) null_deviations)
						)

						(assoc)
					)
					(if (size ordinal_feature_deviations)
						(assoc "featureOrdinalDeviations" ordinal_feature_deviations)
						(assoc)
					)

					;always store a copy of feature deviations during analyze flow, to be removed once analyze is done
					(if feature_deviations
						(assoc "!analyzeFeatureDeviations" feature_deviations)
						(assoc)
					)

					;null uncertainties store a tuple of [null, value<->null uncertainty, null<->null uncertainty]
					(if (size null_deviations)
						(assoc
							"nullUncertainties"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (current_value))) null_deviations)
						)
						(assoc)
					)
				)
		))

		(accum (assoc baseline_hyperparameter_map attribute_map ))
	)

	;write baseline_hyperparameter_map out to the model's !hyperparameterMetadataMap
	#!SetModelHyperParameters
	(seq
		(if derived_auto_analyzed
			(accum (assoc baseline_hyperparameter_map (assoc "derivedAutoAnalyzed" (true)) ))
		)

		(if (not (contains_value !hyperparameterParamPaths (list action_feature context_features_key robust_mode weight_feature)) )
			(let
				(assoc
					;check if any hyperparameters exist that also match this action_feature robust_mode and weight_feature
					;if any exist that were derived_auto_analyzed, remove them because that means these new hyperparameters supercede them
					old_params_key_to_remove
						(first (filter
							(lambda (and
								(get !hyperparameterMetadataMap (append (current_value) "derivedAutoAnalyzed"))
								(= (remove (current_value) 1) (list action_feature robust_mode weight_feature))
							))
							!hyperparameterParamPaths
						))
				)

				(if (size old_params_key_to_remove)
					(seq
						(assign_to_entities (assoc
							!hyperparameterParamPaths (filter (lambda (!= old_params_key_to_remove (current_value)) ) !hyperparameterParamPaths)
						))

						;remove the old context features set
						(accum_to_entities (assoc
							!hyperparameterMetadataMap
								(associate
									action_feature
										(remove (get !hyperparameterMetadataMap action_feature) (get old_params_key_to_remove 1))
								)
						))
					)
				)

				(accum_to_entities (assoc !hyperparameterParamPaths (list (list action_feature context_features_key robust_mode weight_feature)) ))
			)
		)

		(declare (assoc deviations (get baseline_hyperparameter_map "!analyzeFeatureDeviations") ))

		;remove the analyze-specific deviations map from hyperparameters
		(if deviations
			(assign (assoc baseline_hyperparameter_map (remove baseline_hyperparameter_map "!analyzeFeatureDeviations") ))
		)

		(assign_to_entities (assoc
			!hyperparameterMetadataMap
				(set !hyperparameterMetadataMap (list action_feature context_features_key robust_mode weight_feature) baseline_hyperparameter_map)
		))

		;if deviations were computed, store them in !residualsMap
		(if deviations
			(assign_to_entities (assoc
				!residualsMap
					(set
						!residualsMap
						(concat robust_mode action_feature robust_mode weight_feature)
						(append
							deviations
							(assoc
								".robust" (= "robust" robust_mode)
								".hyperparam_path" (list action_feature context_features_key robust_mode weight_feature)
							)
						)
					)
			))

			;else compute and cache residuals and featureDomainAttributes if there are features with nulls
			(let
				(assoc
					num_features_with_nulls
						(size (filter
							;keep only features that have nulls
							(lambda (get (current_value) "has_nulls") )
							;ignore all inactive features (where all values are nulls)
							(remove !featureNullRatiosMap (indices !inactiveFeaturesMap))
						))
				)

				(if (> num_features_with_nulls 0)
					(call !CalculateAndStoreFeatureResiduals (assoc
						features (values (append context_features action_features) (true))
						robust_residuals (= "robust" robust_mode)
						hyperparameter_feature action_feature
						weight_feature weight_feature
						use_case_weights use_case_weights
						custom_hyperparam_map baseline_hyperparameter_map
					))

				)
			)
		)
	)

	;updates baseline_hyperparameter_map
	;uses provided baseline_hyperparameter_map to compute the model MAE (!gridSerachError), if computed error is less than current/y stored error,
	;updates baseline_hyperparameter_map with the new error value, otherwise reverts it back to previous_analyzed_hp_map
	#!TestAccuracyAndKeepOrRevertHyperparameters
	(seq
		;re-set the defined random seed to run gridsearch the same way as it was run above
		(set_rand_seed sampling_random_seed)

		;run through one pass using feature weights to see if they should be used
		(assign (assoc
			model_mae (call !ComputeModelResidualForParameters (assoc targetless (= targeted_model "targetless")))
		))

		;if previous pass did better than this pass, revert baseline_hyperparameter_map
		(if (>= model_mae (get baseline_hyperparameter_map "gridSearchError"))
			(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

			;else keep update current hyperparams with new error value and back them up
			(seq
				(assign (assoc
					baseline_hyperparameter_map (set baseline_hyperparameter_map "gridSearchError" model_mae)
				))
				(assign (assoc previous_analyzed_hp_map baseline_hyperparameter_map))
			)
		)
	)

	;use rewrite to update all hyperparameters sets with the new featureDomainAttributes
	#!UpdateHyperparametersWithFeatureDomainAttributes
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(seq
						;hp already have featureDomainAttributes defined, overwrite the counts and bounds
						(if (!= (null) (get (current_value) "featureDomainAttributes"))
							(let
								(assoc previous_hp_feature_limits_map (get (current_value 1) "featureDomainAttributes") )

								;smartly overwrite previous values with the newly computed ones
								(assign (assoc
									feature_limits_map
										(map
											(lambda (let
												(assoc
													previous_value (first (current_value 1))
													new_value (last (current_value 1))
												)

												;if both are null, keep them as null
												(if (= (null) previous_value new_value)
													(null)

													;if either value is missing from either map, keep whichever isn't null
													(or (= (null) previous_value) (= (null) new_value) )
													(or previous_value new_value)

													;else overwrite the value with the new one
													new_value
												)
											))
											previous_hp_feature_limits_map
											feature_limits_map
										)
								))
							)
						)

						;append the updated feature_limits_map to this hp map
						(append (current_value) (assoc "featureDomainAttributes" feature_limits_map) )
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update all deviations in hyperparemeters with user specified errors
	#!UpdateHyperparametersWithUserErrors
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					;hp already have featureDeviations defined, overwrite where necessary
					(if (!= (null) (get (current_value) "featureDeviations"))
						(let
							(assoc deviations_map (get (current_value 1) "featureDeviations") )

							(map
								(lambda (let
									(assoc
										deviation (get deviations_map (current_index 1))
										user_error_value (current_value 1)
										feature (current_index 1)
									)

									(declare (assoc
										deviation_value
											;set to max of user specified error and stored deviation in the map
											(if (!= (null) deviation)
												;if deviation is a tuple, update the first value
												(if (= (list) (get_type deviation))
													(set deviation 0 (max user_error_value (first deviation)) )
													;else just update the value itself
													(max user_error_value deviation)
												)
											)
									))

									;if deviation is null, that means we aren't using deviations so keep it as a null
									(if (!= (null) deviation_value)
										(assign (assoc
											deviations_map (set deviations_map feature deviation_value)
										))
									)
								))
								!userSpecifiedFeatureErrorsMap
							)

							;append the updated deviations_map to this hp map
							(append (current_value) (assoc "featureDeviations" deviations_map) )
						)

						(current_value)
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update hyperparameter map for newly added feature
	; hp_map: the hp map to be updated, should be either !defaultHyperparameters or !hyperparameterMetadataMap
	#!UpdateHyperparametersWithNewFeature
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(let
						(assoc
							feature_weights_map (get (current_value 1) "featureWeights")
							feature_deviations_map (get (current_value 1) "featureDeviations")
						)

						(if (!= (null) feature_weights_map)
							(assign (assoc feature_weights_map (append feature_weights_map (associate feature 1)) ))

							;else no weights, assign all active features weight 1
							(assign (assoc
								feature_weights_map
									(append
										(zip (append !trainedFeatures feature) 1)
										;prevent appending null to an assoc
										(if !inactiveFeaturesMap !inactiveFeaturesMap (assoc))
									)
							))
						)

						(if (!= (null) feature_deviations_map)
							(assign (assoc feature_deviations_map (set feature_deviations_map feature min_deviation_value) ))
						)

						(append (current_value) (assoc
							"allFeatureResidualsCached" (false)
							"featureWeights" feature_weights_map
							"featureDeviations" feature_deviations_map
						))
					)

					;else return
					(current_value)
				)
			)
			hp_map
		)
	)


	#!GetHyperparameters
	(declare
		(assoc
			mode "robust"
			weight_feature ".none"
		)

		(if (= 0 (size !hyperparameterParamPaths))
			(seq
				(if (and (not !autoAnalyzeEnabled ) (>= (call !GetNumTrainingCases) 2))
					(accum (assoc
						warnings
							(associate (concat
								"There are no cached hyperparameters in this trainee. "
								"This operation was executed using a set of predefined default hyperparameters. "
								"Please run analyze() with your desired parameters."
							))
					))
				)
				;if no params, use defaults
				(conclude !defaultHyperparameters)
			)

			(= 1 (size !hyperparameterParamPaths))
			;if only one set of analyzed params, return them
			(conclude (get !hyperparameterMetadataMap (first !hyperparameterParamPaths)))
		)

		;there are multiple sets of analyze params, we must determine the best
		(declare (assoc
			context_key
				(if (or (= context_features (null)) (= context_features (list)))
					!trainedFeaturesContextKey

					;else context_features were passed
					(call !BuildContextFeaturesKey (assoc context_features context_features))
				)
		))


		;determine value for feature
		(if (or (= (null) feature) (not (contains_index !hyperparameterMetadataMap feature)))
			(assign (assoc
				feature
					(if (contains_index !hyperparameterMetadataMap ".targetless")
						".targetless"

						;else just use one of the targeted analyzed hyperparam sets
						(first (indices !hyperparameterMetadataMap))
					)
			))
		)

		;if we have completely correct HPs, return them
		(if (contains_index !hyperparameterMetadataMap (list feature context_key mode weight_feature))
			(conclude (get !hyperparameterMetadataMap (list feature context_key mode weight_feature)) )

			(declare (assoc other_mode (if (= mode "robust") "full" "robust") ))
		)

		;if we have the correct HPs, with the alternate mode, return them
		(if (contains_index !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))
			(conclude (get !hyperparameterMetadataMap (list feature context_key other_mode weight_feature)) )
		)

		;we don't have the exact HPs, determine best context_key
		(let
			(assoc
				;sort context keys in order of increasing length
				context_key_options
					(sort
						(lambda (> (size (current_value)) (size (current_value 1))))
						(indices (get !hyperparameterMetadataMap feature) )
					)

				correct_mode (false)
				correct_weight (false)
				iterator 0
			)

			;naively set the context to the longest option
			(assign (assoc context_key (last context_key_options) ))


			(while (< iterator (size context_key_options))
				(assign (assoc candidate_context_key (get context_key_options iterator) ))

				(if (contains_index !hyperparameterMetadataMap (list feature candidate_context_key mode weight_feature))
					;correct mode and weight
					(assign (assoc
						context_key candidate_context_key
						iterator (size context_key_options)
						correct_mode (true)
						correct_weight (true)
					))

					(contains_index !hyperparameterMetadataMap (list feature candidate_context_key other_mode weight_feature))
					;incorrect mode, correct weight
					(if (not correct_weight)
						(assign (assoc
							context_key candidate_context_key
							correct_mode (true)
							correct_weight (false)
						))
					)

					(contains_index !hyperparameterMetadataMap (list feature candidate_context_key mode ".none"))
					;correct mode, default weight
					(if (and (not correct_mode) (not correct_weight))
						(assign (assoc
							context_key candidate_context_key
							correct_mode (true)
							correct_weight (false)
						))
					)
				)

				(accum (assoc iterator 1 ))
			)
		)

		;if we have the correct mode and weight for the action and context, return it
		(if (contains_index !hyperparameterMetadataMap (list feature context_key mode weight_feature))
			(get !hyperparameterMetadataMap (list feature context_key mode weight_feature))

			;if we have the correct weight for the action and context, return it
			(contains_index !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))
			(get !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))

			;only correct mode, no case weight
			(contains_index !hyperparameterMetadataMap (list feature context_key mode ".none"))
			(get !hyperparameterMetadataMap (list feature context_key mode ".none"))

			;in correct mode, no case weight, just feature is right basically
			(contains_index !hyperparameterMetadataMap (list feature context_key other_mode ".none"))
			(get !hyperparameterMetadataMap (list feature context_key other_mode ".none"))

			;else the case_weight and ".none" isn't in the map, return the default params
			!defaultHyperparameters
		)
	)

	;builds a string key based on context feature list
	#!BuildContextFeaturesKey
	(apply "concat" (weave (sort context_features) "."))


	;return the full internal parameters map if no parameters are specified.
	;if any of the parameters are specified, then GetHyperparameters is called, which uses the specified parameters to find the most suitable set of hyperparameters to return
	;
	; parameters:
	; action_feature : optional, the target feature of the desired hyperparameters
	; context_features : optional, the set of context features used for the desired hyperparameters
	; mode : optional, the method of calculation used to find the desired hyperparameters
	; weight_feature : optional, the weight feature used in the calculation of the desired hyperparameters
	#get_params
	(declare
		(assoc
			;{type "string"}
			action_feature (null)
			;{type "list" values "string"}
			context_features (null)
			;{type "string" enum ["robust" "full"]}
			mode (null)
			;{type "string"}
			weight_feature (null)
		)
		(call !ValidateParameters)

		(declare (assoc
			internal_parameters_map
				(assoc
					"hyperparameter_map"
						(if (= (null) action_feature context_features mode weight_feature)
							!hyperparameterMetadataMap

							;else one of these parameters were specified
							(call !GetHyperparameters
								(append
									(assoc
										feature action_feature
										context_features context_features
									)
									;don't pass mode or weight_feature in if they weren't specified,
									;allowing GetHyperparameters to use its defaults
									(if mode (assoc mode mode) (assoc))
									(if weight_feature (assoc weight_feature weight_feature) (assoc))
								)
							)
						)

					"default_hyperparameter_map" !defaultHyperparameters
				)
		))

		(if !autoAnalyzeEnabled
			(accum (assoc
				internal_parameters_map
					(assoc
						"auto_analyze_enabled" !autoAnalyzeEnabled
						"analyze_threshold" !autoAnalyzeThreshold
						"analyze_growth_factor" !autoAnalyzeGrowthFactorAmount
					)
			))
		)

		(call !Return (assoc payload internal_parameters_map))
	)

	;sets internal hyperparameters
	;
	;parameters:
	; hyperparameter_map: optional. must have at least an action feature (e.g., .targetless) -> a contexts key -> robust -> k, p and dt provided.
	;	example:
	;   {
	;	  	".targetless" { "featureA.featureB.": { "robust" : { "k" : number, "p" : number, "dt": number }}},
	;		"featureA" : { "featureB.featureC.": { "full" : { "k" : number, "p" : number, "dt": number }}},
	;			...
	;	}
	; default_hyperparameter_map: optional. an assoc of hyperparameters to use when no others are available must contain k, p, and dt.
	; auto_analyze_enabled: flag, default is false. when true, returns when it's time for model to be analyzed again.
	; analyze_threshold: optional, stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
	; analyze_growth_factor: the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
	;						default of two orders of magnitude using the universal scaling factor e
	; auto_analyze_limit_size: optional, the size of of the model at which to stop doing outo-analysis
	#set_params
	(declare
		(assoc
			;{ref "FullHyperparameterMap"}
			hyperparameter_map (null)
			;{ref "HyperparameterMap"}
			default_hyperparameter_map (null)
			;{type "boolean"}
			auto_analyze_enabled (false)
			;{type "number"}
			analyze_threshold 100
			;{type "number"}
			analyze_growth_factor 7.389056
		)
		(call !ValidateParameters)

		(declare (assoc
			;local var
			bad_param (false)
		))

		(if (!= (null) default_hyperparameter_map)
			(if (or
					(not (contains_index default_hyperparameter_map "p"))
					(not (contains_index default_hyperparameter_map "k"))
					(not (contains_index default_hyperparameter_map "dt"))
				)
				(assign (assoc bad_param (true) ))

				(seq
					(accum (assoc default_hyperparameter_map (assoc "paramPath" (list ".default")) ))
					(assign_to_entities (assoc !defaultHyperparameters default_hyperparameter_map) )
				)
			)
		)

		;the passed in hyperparameters must at least have the basic attributes defined correctly
		;iterate over action features
		(if (!= (null) hyperparameter_map)
			(let
				(assoc param_paths (list))
				(map
					(lambda (if
						(= 0 (size (current_value)))
						(assign (assoc bad_param (true)))
						;else iterate over context feature keys
						(map
							(lambda (if
								(= 0 (size (current_value)))
								(assign (assoc bad_param (true)))
								;else iterate over robust / full
								(map
									(lambda (if
										(= 0 (size (current_value)))
										(assign (assoc bad_param (true)))
										;else iterate over case weights
										(map
											(lambda
												(if (or
														(not (contains_index (current_value) "p"))
														(not (contains_index (current_value) "k"))
														(not (contains_index (current_value) "dt"))
													)
													(assign (assoc bad_param (true)))

													;else this HP assoc is good enough
													(assign (assoc param_paths (append param_paths (list (list (current_index 6) (current_index 5) (current_index 4) (current_index 3))) ) ))
												)
											)
											(current_value)
										)
									))
									(current_value)
								)
							))
							(current_value)
						)
					))
					hyperparameter_map
				)
				(if (not bad_param)
					(assign_to_entities (assoc
						!hyperparameterMetadataMap hyperparameter_map
						!hyperparameterParamPaths param_paths
					))
				)
			)
		)

		;return failure, invalid hyperparameter_map passed in
		(if bad_param (conclude
			(call !Return (assoc
				errors (list "Failed to set parameters: invalid parameters specified.")
			))
		))

		(assign_to_entities (assoc
			!autoAnalyzeEnabled auto_analyze_enabled
			!autoAnalyzeThreshold analyze_threshold
			!autoAnalyzeGrowthFactorAmount analyze_growth_factor
		))

		(accum_to_entities (assoc !revision 1))

		(call !Return)
	)

	;resets all hyperparameters and thresholds back to original values, while leaving feature definitions alone
	#reset_params
	(seq
		(assign_to_entities (assoc
			!numericalPrecision (null)
			!defaultNumSamples 100
			!hyperparameterMetadataMap (assoc)
			!defaultHyperparameters
				(assoc
					"k" 8
					"p" 0.1
					"dt" -1
					"featureWeights" (null)
					"featureDeviations" (null)
					"allFeatureResidualsCached" (false)
				)
		))
		(accum_to_entities (assoc !revision 1))
		(call !Return)
	)

	;sets the model to auto-analyze by tracking its size and notifying the clients in train responses when it should be analyzed
	;parameters:
	; auto_analyze_enabled: flag, default is false. when true, returns when it's time for model to be analyzed again.
	; analyze_threshold: optional, stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
	; analyze_growth_factor: the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
	;						default of two orders of magnitude using the universal scaling factor e
	;
	; optionally, if parameters that are specified for analyze are passed in, they will be stored and used during auto-analysis
	#set_auto_analyze_params
	(declare
		(assoc
			;{type "boolean"}
			auto_analyze_enabled (false)
			;{type "number"}
			analyze_threshold 100
			;{type "number"}
			analyze_growth_factor 7.389056

			;parameter for analyze
			;{type "list" values "string"}
			context_features (null)
			;{type "list" values "string"}
			action_features (null)
			;{type "number"}
			k_folds 1
			;{type "boolean"}
			bypass_hyperparameter_analysis (null)
			;{type "boolean"}
			bypass_calculate_feature_residuals (null)
			;{type "boolean"}
			bypass_calculate_feature_weights (null)
			;{type "boolean"}
			use_deviations (null)
			;{type "number"}
			num_samples (null)
			;{type "number"}
			num_analysis_samples (null)
			;{type "number"}
			analysis_sub_model_size (null)
			;{type "list" values "number"}
			k_values (null)
			;{type "list" values "number"}
			p_values (null)
			;{type "list" values "number"}
			dt_values (null)
			;{type "string" enum ["single_targeted" "omni_targeted" "targetless"]}
			targeted_model (null)
			;{type "string"}
			weight_feature ".case_weight"
			;{type "boolean"}
			use_case_weights (null)
			;{type "boolean"}
			inverse_residuals_as_weights (null)
		)
		(call !ValidateParameters)

		;growth factor must be more than 1
		(if (<= analyze_growth_factor 1)
			(assign (assoc analyze_growth_factor 2))
		)

		(declare (assoc num_cases (call !GetNumTrainingCases) ))

		;if the model is already larger than the specified analyze_threshold, set the analyze_threshold to a valid value nearest the current
		;number of cases in the model without going over
		(if
			(and
				(!= (null) analyze_threshold)
				(> num_cases analyze_threshold)
			)
			(seq
				;keep increasing the analysis_threshold by the growth_factor_amount until it's bigger than the current number of cases
				;and then decrease it back down so that it's just below
				(while (> num_cases analyze_threshold)
					(assign (assoc analyze_threshold (* analyze_threshold analyze_growth_factor)))
				)

				(assign (assoc analyze_threshold (/ analyze_threshold analyze_growth_factor )))
			)
		)

		(accum_to_entities (assoc !revision 1))

		(assign_to_entities (assoc
			!autoAnalyzeEnabled auto_analyze_enabled
			!autoAnalyzeThreshold analyze_threshold
			!autoAnalyzeGrowthFactorAmount analyze_growth_factor
		))

		(if (!= (null) context_features)
			(assign_to_entities (assoc
				!savedAnalyzeParameterMap
					(assoc
						"context_features" context_features
						"action_features" action_features
						"k_folds" k_folds
						"k_folds_by_indices" k_folds_by_indices
						"bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
						"bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
						"bypass_calculate_feature_weights" bypass_calculate_feature_weights
						"use_deviations"  use_deviations
						"num_samples" num_samples
						"k_values" k_values
						"p_values" p_values
						"dt_values" dt_values
						"targeted_model" targeted_model
						"num_analysis_samples" num_analysis_samples
						"analysis_sub_model_size" analysis_sub_model_size
						"inverse_residuals_as_weights" inverse_residuals_as_weights
						"weight_feature" weight_feature
						"use_case_weights" use_case_weights
					)
			))
		)

		(call !Return)
	)

	;get auto-ablation parameters set by #set_auto_ablation_params
	#get_auto_ablation_params
	(call !Return (assoc
		payload
			(assoc
				auto_ablation_enabled !autoAblationEnabled
				auto_ablation_weight_feature !autoAblationWeightFeature
				minimum_model_size !autoAblationMinModelSize
				influence_weight_entropy_threshold !autoAblationInfluenceWeightEntropyThreshold
				exact_prediction_features !autoAblationExactPredictionFeatures
				tolerance_prediction_threshold_map !autoAblationTolerancePredictionThresholdMap
				relative_prediction_threshold_map !autoAblationRelativePredictionThresholdMap
				residual_prediction_features !autoAblationResidualPredictionFeatures
				conviction_upper_threshold !autoAblationConvictionUpperThreshold
				conviction_lower_threshold !autoAblationConvictionLowerThreshold
			)
	))

	;sets the model to auto-ablate by tracking its size and training certain cases as weights
	;parameters
	; auto_ablation_enabled: flag, default is false. when true, any enabled ablation techniques will be run at during training.
	; auto_ablation_weight_feature: string, default is ".case_weight". the weight feature that should be used when ablating.
	; minimum_model_size: optional, stores the threshold for the minimum number of cases at which the model should auto-ablate.
	;   	default of 1000.
	; influence_weight_entropy_threshold: optional, the influence weight entropy quantile that a case must be beneath in order to be trained.
	;	default of 0.15.
	; exact_prediction_features: optional list of features. for each of the features specified, will ablate a case if the prediction
	;   matches exactly.
	; tolerance_prediction_threshold_map: optional assoc of feature -> [MIN, MAX]. for each of the features specified, will
	;   ablate a case if the prediction >= (case value - MIN) and the prediction <= (case value + MAX)
	; relative_prediction_threshold_map: optional assoc of feature -> PERCENT. for each of the features specified, will
	;   ablate a case if abs(prediction - case value) / prediction <= PERCENT
	; residual_prediction_features: optional list of features. for each of the features specified, will ablate a case if
	;   abs(prediction - case value) <= feature residual
	; conviction_upper_threshold: optional float. the conviction value below which cases will be ablated
	; conviction_lower_threshold: optional float. the conviction value above which cases will be ablated
	; batch_size: optional number. number of cases in a batch to consider for ablation prior to training and to recompute influence weight entropy.
	; 	default of 2000
	; ablated_cases_distribution_batch_size: optional number. number of cases in a batch to distribute ablated cases' influence weights.
	;	default of 100
	#set_auto_ablation_params
	(declare
		(assoc
			;{type "boolean"}
			auto_ablation_enabled (false)
			;{type "string"}
			auto_ablation_weight_feature ".case_weight"
			;{type "number"}
			minimum_model_size 1000
			;{type "number"}
			influence_weight_entropy_threshold 0.15
			;{type "list" values "string"}
			exact_prediction_features (null)
			;{type "assoc" values {type "list" min_size 2 max_size 2}}
			tolerance_prediction_threshold_map (null)
			;{type "assoc" values "number"}
			relative_prediction_threshold_map (null)
			;{type "list" values "string"}
			residual_prediction_features (null)
			;{type "number"}
			conviction_upper_threshold (null)
			;{type "number"}
			conviction_lower_threshold (null)
			;{type "number" min 1}
			batch_size 2000
			;{type "number"}
			ablated_cases_distribution_batch_size 100
		)
		(call !ValidateParameters)

		(if
			(or (< influence_weight_entropy_threshold 0) (> influence_weight_entropy_threshold 1))
			(assign (assoc auto_ablation_entropy_threshold_quantile 1.0))
		)

		(accum_to_entities (assoc !revision 1))

		(assign_to_entities (assoc
			!autoAblationEnabled auto_ablation_enabled
			!autoAblationWeightFeature auto_ablation_weight_feature
			!autoAblationMinModelSize minimum_model_size
			!autoAblationInfluenceWeightEntropyThreshold influence_weight_entropy_threshold
			!autoAblationExactPredictionFeatures exact_prediction_features
			!autoAblationTolerancePredictionThresholdMap tolerance_prediction_threshold_map
			!autoAblationRelativePredictionThresholdMap relative_prediction_threshold_map
			!autoAblationResidualPredictionFeatures residual_prediction_features
			!autoAblationConvictionUpperThreshold conviction_upper_threshold
			!autoAblationConvictionLowerThreshold conviction_lower_threshold
			!ablationBatchSize batch_size
			!ablatedCasesDistributionBatchSize ablated_cases_distribution_batch_size
		))

		(call !Return)
	)

	;Convert confusion matrix (assoc class -> (assoc of class -> counts)) to sparse deviation matrix (SDM):
	;with the possible formats:
	; an assoc of assocs: (assoc of class -> (assoc of class -> deviation))
	;if there's a default_class_deviation, the deviation value to be used for any classes that didn't have any counts:
	; each row will be an assoc of list (pair) of: assoc and value:
	;  (assoc of class -> (list of: (assoc of class -> deviation), default_class_deviation))
	;
	;The SDM is output as a tuple (pair) in the format of: [ SDM unknown_class_deviation ]
	;where unknown_class_deviation is the deviation value to be used for any class that isn't defined in the SDM
	;
	;returns null if the the passed in confusion matrix does not have enough counts to be statistically significant.
	;
	;parameters:
	; confusion_matrix:  assoc of class -> assoc of class -> predicted count for each class.
	; feature: name of nominal feature
	; confusion_matrix_min_count: number of predictions a class should have for it to have an explicit deviation value.
	;	If the count is less than this value, the deviation will be in the combined deviation for the class. default value is 10
	; expected_deviation: value of expected deviation if sdm is not being referenced
	#!ConfusionMatrixToSDM
	(declare
		(assoc
			confusion_matrix (assoc)
			confusion_matrix_min_count 15
			expected_deviation (null)
		)

		(declare (assoc
			total_predictions
				(apply "+" (values
					(map
						(lambda (apply "+" (values (current_value))))
						confusion_matrix
					)
				))
		))

		;output null if the total count is too small
		(if (< total_predictions confusion_matrix_min_count)
			(conclude (null))
		)

		(declare (assoc
			;Using n+1, n+2, or n+.5 are all possible considerations of Laplacian smoothing to apply a Bayesian approach for
			;estimating the probability of having no incorrect predictions.  We chose .5 assuming the Jeffreys prior approach.
			smallest_prob (/ 1 (+ 0.5 total_predictions))
			;max accuracy is 1 - smallest_probability
			max_accuracy (- 1 (/ 1 (+ 2 total_predictions)))
			predictions_per_class_map
				(map
					(lambda (apply "+" (values (current_value))) )
					confusion_matrix
				)
			leftover_confusion_matrix (assoc)
			leftover_unknown_class_deviation (null)
			valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")) )
		))

		(declare (assoc
			;map of class -> accuracy of random guessing
			rand_guess_accuracy_map (map (lambda (/ (current_value) total_predictions)) predictions_per_class_map)
			all_classes_map
				(compute_on_contained_entities (list
					(query_value_masses
						feature
						(if valid_weight_feature weight_feature)
						(or
							(not (contains_index !nominalsMap feature))
							(contains_index !numericNominalFeaturesMap feature)
						)
					)
				))
		))

		;filter out counts below threshold in confusion matrix and store as probabilities correct instead of counts
		;leaving only those predicted classes that had enough predictions
		(call !ConvertAndReduceConfusionMatrix)

		(if (= 0 (size confusion_matrix))
			(conclude (null))
		)

		(declare (assoc num_classes (size all_classes_map) ))

		;average all probabilities for a class that are same as or more than the predicted class probability
		(declare (assoc
			prob_match_or_indistinguishable_map
				(map
					(lambda (let
						(assoc predicted_class_prob (+ (or (get (current_value 1) (current_index 1)))) )
						(declare (assoc
							avg_probs_same_or_larger_than_predicted
								(filter
									(lambda (>= (current_value) predicted_class_prob))
									(values
										(append (zip (indices all_classes_map) 0) (current_value 1))
									)
								)
						))
						(/ (apply "+" avg_probs_same_or_larger_than_predicted) (size avg_probs_same_or_larger_than_predicted))
					))
					confusion_matrix
				)
		))

		;indistinguishable accuracy matrix
		;Clamps predicted probabilities to random guesses
		(declare (assoc guessing_accuracy_matrix (call !ClampSDMProbabilities) ))

		;compute the full deviation matrix
		(declare (assoc
			deviation_matrix
				(map
					(lambda (let
						(assoc
							predicted_class (current_index 1)
							;probability of correct predicted class
							class_probability (get (current_value 1) (current_index 1))
							;total probability of the row
							total_probability (apply "+" (values (current_value 1)) )
						)

						;normalize each prediction probability by iterating over all the predictions
						;in the row and dividing by total_probability
						(map
							(lambda
								(max
									(- 1 (/ (min class_probability (current_value)) total_probability))
									smallest_prob
								)
							)
							(current_value)
						)
					))
					guessing_accuracy_matrix
				)
		))

		;store default class deviations for any classes that are not in the sparse confusion matrix
		(declare (assoc
			leftover_class_deviation_map
				(filter (map
					(lambda
						;only need default if a class isn't in the sparse confusion matrix
						(if (< (size (current_value)) num_classes)
							(first (values
								(remove (get deviation_matrix (current_index)) (indices (current_value)))
							))
						)
					)
					confusion_matrix
				))
		))

		;SDM is always output as a tuple of: [matrix unknown_class_deviation]
		(list
			(call !FormatSDMForOutput)
			(if leftover_unknown_class_deviation
				;if there's a leftover_unknown_class_deviation, output the SDM as a list (pair)
				leftover_unknown_class_deviation

				;if there is only one class trained, set the unknown deviation to be max possible value
				(= [1] (values rand_guess_accuracy_map))
				max_accuracy

				;else just output the expected deviation
				expected_deviation
			)
		)
	)

	;Edits deviation_matrix for output by filtering out deviations that correspond to counts that aren't in the sparse confusion matrix
	;and return tuples with the default class deviation for classes that have those computed
	#!FormatSDMForOutput
	(map
		(lambda
			;if there is a default deviation for the class, output a tuple of [sparse deviation map, default class deviation]
			(if (contains_index leftover_class_deviation_map (current_index))
				(list
					(keep (current_value 1) (indices (get confusion_matrix (current_index 1))) )
					(get leftover_class_deviation_map (current_index 1))
				)

				;just output the sdm assoc
				(keep (current_value) (indices (get confusion_matrix (current_index))) )
			)
		)
		deviation_matrix
	)

	;compute the "leftover" confusion matrix of class counts that did not have statistical significance
	#!ComputeLeftoverConfusionMatrix
	(seq
		(assign (assoc
			leftover_confusion_matrix
				(map
					(lambda (let
						(assoc
							predicted_class (current_index 1)
							row_map (current_value 1)
						)
						;leave entire row if predicted class doesn't have enough samples
						(if
							(or
								(= (null) (get row_map predicted_class))
								(< (get row_map predicted_class) confusion_matrix_min_count)
							)
							row_map

							;else only leave those classes that have counts but not enough samples
							(filter
								(lambda
									(and
										(< (current_value) confusion_matrix_min_count)
										(!= 0 (current_value))
									)
								)
								row_map
							)
						)
					))
					confusion_matrix
				)
		))

		;remove classes with empty rows by leaving only those with non-empty rows
		(assign (assoc
			leftover_confusion_matrix (filter (lambda (size (current_value))) leftover_confusion_matrix )
		))
	)

	;Helper method for computing SDM, called by ConfusionMatrixToSDM, filters out counts below threshold and stores as probabilities correct instead.
	;leaves only those predicted classes that had enough predictions.
	;Also computes the fallback residuals if there are any counts that didn't have enough statistical significance.
	#!ConvertAndReduceConfusionMatrix
	(seq
		(call !ComputeLeftoverConfusionMatrix)

		(declare (assoc
			total_leftover_correct_predictions
				(apply "+" (values
					(map (lambda (+ (or (get (current_value) (current_index))))) leftover_confusion_matrix)
				))
			total_leftover_all_predictions
				(apply "+" (values
					(map
						(lambda (apply "+" (values (current_value))))
						leftover_confusion_matrix
					)
				))
		))

		(assign (assoc
			confusion_matrix
				;current_index is the class being predicted
				;current_value is an assoc of class -> number predictions
				(map
					(lambda (let
						(assoc
							total_class_predictions (apply "+" (values (current_value 1)))
							predicted_class (current_index 1)
						)
						;convert counts to percent accuracy by dividing each count by total_class_predictions
						;filter out any entries where there weren't enough counts
						(filter (map
							(lambda
								(if (>= (current_value) confusion_matrix_min_count)
									(/ (current_value) total_class_predictions)

									;if the predicted class (diagonal) doesn't have enough, represent it with a 0 instead of filtering it out
									(= (current_index) predicted_class)
									0
								)
							)
							;ensure the predicted class is represented in the row even if it has no counts
							;since the values on the diagonal should all be present
							(if (contains_index (current_value) predicted_class)
								(current_value)
								(append (current_value) (associate predicted_class 0))
							)
						))
					))
					confusion_matrix
				)
		))

		(declare (assoc
			weighted_accuracy_map
				;weighted accuracy for each class is its predicted probability * random guess accuracy
				(map
					(lambda (let
						(assoc predicted_class_prob (get (current_value 1) (current_index 1)))
						(* predicted_class_prob (get rand_guess_accuracy_map (current_index)) )
					))
					confusion_matrix
				)
		))
		(declare (assoc avg_random_accuracy (apply "+" (values weighted_accuracy_map)) ))

		(assign (assoc
			leftover_unknown_class_deviation
				;fallback #1, if there are enough leftover predictions, deviation is 1 - correct leftovers / total leftovers
				(if (>= total_leftover_correct_predictions confusion_matrix_min_count)
					(- 1 (/ total_leftover_correct_predictions total_leftover_all_predictions) )

					;else if there aren't enough leftover counts to compute unknown class deviation, use weighted random chance
					(> total_leftover_all_predictions total_leftover_correct_predictions)
					(let
						(assoc
							non_sdm_classes (indices (remove all_classes_map (indices confusion_matrix)) )
						)
						;fallback #2, if there are classes in the dataset that weren't in the sdm, use random guess probability of those classes
						(if (size non_sdm_classes)
							(let
								(assoc total_count (apply "+" (values all_classes_map)) )

								;rand guess prob of classes not in sdm : 1 - sum of prob^2
								(- 1
									(apply "+"
										(map
											(lambda
												(pow
													(/ (get all_classes_map (current_value)) total_count)
													2
												)
											)
											non_sdm_classes
										)
									)
								)
							)

							;else fallback #3, use the average weighted random guess accuracy from the confusion matrix
							;deviation = 1 - average accuracy
							(- 1 avg_random_accuracy)
						)
					)

					;else value remains as null if there are no leftover counts
					(null)
				)
		))

		;ensure unknown class deviation isn't 0 by setting the floor to be the smallest possible probability
		(if (!= (null) leftover_unknown_class_deviation)
			(assign (assoc
				leftover_unknown_class_deviation (max smallest_prob leftover_unknown_class_deviation)
			))
		)

		;average accuracy of 0 means there are no (or not enough significant) counts for any of the predicted classes
		(if (= 0 avg_random_accuracy)
			(assign (assoc confusion_matrix (assoc) ))
		)
	)

	;helper method for computing SDM that clamps probabilities for the predicted classes to be no worse than random guessing
	#!ClampSDMProbabilities
	(declare
		(assoc
			guessing_accuracy_matrix
				;diagonal values are the probability of the match
				;all other classes are their probability without exceeding the predicted class probability (corresponding diagonal value)
				(map
					(lambda (let
						(assoc
							predicted_class (current_index 1)
							row_map (current_value 1)
						)
						(map
							(lambda
								(if (= predicted_class (current_index))
									(get prob_match_or_indistinguishable_map (current_index))

									;all other classes can't exceed the predicted class's probability
									(min
										(get prob_match_or_indistinguishable_map predicted_class)
										(+ (or (get row_map (current_index))))
									)
								)
							)
							;iterate over all_classes since every row needs to have a value for every class even if it's 0
							all_classes_map
						)
					))
					confusion_matrix
				)
		)

		;guessing clamped accuracy
		;limit max accuracy of predicted classes to max of computed probability and random correct guess
		;limit min accuracy of other classes to min of computed probability and random wrong guess
		(map
			(lambda (let
				(assoc
					predicted_class (current_index 1)
					row_map (current_value 1)
				)

				(map
					(lambda
						(if (= predicted_class (current_index))
							(max (get row_map predicted_class) (get rand_guess_accuracy_map predicted_class))

							;set floor for accuracy using random matching probability
							(min
								(max smallest_prob (get row_map (current_index)))
								;probability of guessing wrong is 1 - random guess
								(- 1 (get rand_guess_accuracy_map predicted_class) )
							)
						)
					)
					row_map
				)
			))
			guessing_accuracy_matrix
		)
	)


)
