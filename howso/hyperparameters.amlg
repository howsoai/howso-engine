;Contains helper methods for hyperparameter maintenance.
(null

	; contains, p, k, dt, gridSearchError, etc
	#!BackupAnalyzedHyperparameters
	(assign (assoc
		previous_analyzed_hp_map analyzed_hp_map
		baseline_hyperparameter_map analyzed_hp_map
	))

	;updates baseline_hyperparameter_map
	#!KeepOrRevertHyperparameters
	(if (<= (get previous_analyzed_hp_map "gridSearchError") (get analyzed_hp_map "gridSearchError"))
		(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

		;else update with analyzed
		(assign (assoc baseline_hyperparameter_map analyzed_hp_map))
	)

	;updates baseline_hyperparameter_map
	#!UpdateHyperparameters
	(declare
		(assoc
			use_weights (null)
			feature_weights (null)
			use_deviations (null)
			feature_deviations (null)
			null_deviations (null)
			ordinal_feature_deviations (null)
			attribute_map (assoc)
			confusion_matrix_map (null)
		)

		(if (size confusion_matrix_map)
			(seq
				(assign (assoc
					feature_deviations
						(map
							;convert deviations for nominals that had a confusion matrix computed from a single value into an assoc
							;containing the nominal deviation as 'expected_deviation' and a sparse deviation matrix as 'sdm'
							(lambda
								(if (contains_index confusion_matrix_map (current_index))
									(let
										(assoc feature (current_index 1) )
										(declare (assoc
											sdm
												##SparseDeviationMatrix
												(call !ConfusionMatrixToSDM (assoc
													confusion_matrix (get confusion_matrix_map [feature "matrix"])
													feature feature
													expected_deviation (current_value 2)
												))
										))

										;output an assoc of sdm and expected deviation
										(if sdm
											(assoc
												"sdm" sdm
												"expected_deviation" (current_value 1)
											)

											;else there is no sdm, return just the value
											(current_value)
										)
									)

									;else leave deviation value as-is
									(current_value)
								)
							)
							;if there are shared deviations, don't store or compute SDM for deviations for the non-primary shared features
							(if (size !sharedDeviationsMap)
								(remove feature_deviations !sharedDeviationsNonPrimaryFeatures)
								feature_deviations
							)
						)
				))

				;append the shared deviations as a duplicate of their primary feature shared deviation
				(if (size !sharedDeviationsMap)
					(accum (assoc
						feature_deviations
							(map
								(lambda
									(get feature_deviations (get !sharedDeviationsMap (current_index)))
								)
								(zip !sharedDeviationsNonPrimaryFeatures)
							)
					))
				)
			)
		)

		(accum (assoc
			attribute_map
				(append
					;if not using weights, set them to 1, TODO: 24602: sets all featureWeights to (null) instead so the defaults can be handled internally
					(if (= .false use_weights)
						(assoc
							"featureWeights" (map 1 (zip !trainedFeatures))
						)

						(assoc)
					)
					(if feature_weights
						(assoc
							"featureWeights"
								(if (size !inactiveFeaturesMap)
									(append feature_weights (map 0 !inactiveFeaturesMap))
									feature_weights
								)
						)
						(assoc)
					)
					(if use_deviations
						(assoc
							"featureDeviations"
								;append null_deviations to feature_deviations
								(if (size null_deviations)
									(map
										(lambda
											;create a tuple of [deviation, value<->null uncertainty, null<->null uncertainty]
											(if (size (last (current_value)))
												;if the deviation is an assoc (nominal feature with SDM), ensure the result is a triple
												(if (~ (assoc) (first (current_value)))
													(append (list (get (current_value 1) (list 0 "sdm"))) (last (current_value)) )

													(append (first (current_value)) (last (current_value)) )
												)

												;else return the deviation value without the known-unkwnown uncertainties
												;an assoc means this is a SDM
												(if (~ (assoc) (first (current_value)))
													;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
													[(get (current_value 1) [0 "sdm"])]

													(first (current_value))
												)
											)
										)
										feature_deviations
										null_deviations
									)

									;else just store provided deviations, but pull the sdm out to store as-is
									(map
										(lambda
											;an assoc means this is a SDM
											(if (~ (assoc) (current_value))
												;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
												[(get (current_value 1) "sdm")]

												(current_value)
											)
										)
										feature_deviations
									)
								)
						)

						;if not using deviations but provided null uncertainties, use those as deviations
						(size null_deviations)
						(assoc
							"featureDeviations"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (replace (current_value)))) null_deviations)
						)

						(assoc)
					)
					(if (size ordinal_feature_deviations)
						(assoc "featureOrdinalDeviations" ordinal_feature_deviations)
						(assoc)
					)

					;always store a copy of feature deviations during analyze flow, to be removed once analyze is done
					(if feature_deviations
						(assoc
							"featureResiduals"
								(map
									(lambda
										(if (~ 0 (current_value))
											(current_value)

											;must be a nominal
											(~ (assoc) (current_value))
											(get (current_value) "expected_deviation")

											;else fall back to null, this should never happen
											(null)
										)
									)
									feature_deviations
								)
						)
						(assoc)
					)

					;null uncertainties store a tuple of [null, value<->null uncertainty, null<->null uncertainty]
					(if (size null_deviations)
						(assoc
							"nullUncertainties"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (current_value))) null_deviations)
						)
						(assoc)
					)
				)
		))

		(accum (assoc baseline_hyperparameter_map attribute_map ))
	)

	;write baseline_hyperparameter_map out to the trainee's !hyperparameterMetadataMap
	;null action feature assumes targetless hyperparameters
	#!SetHyperparameters
	(seq
		(if derived_auto_analyzed
			(accum (assoc baseline_hyperparameter_map (assoc "derivedAutoAnalyzed" .true) ))
		)

		(declare (assoc
			target_mode
				(if action_feature
					["targeted" action_feature]
					["targetless"]
				)
			; param paths are: [targeted/less [action_feature] context_key weight_feature]
			context_key_index (if action_feature 2 1)
		))

		(if (not (contains_value !hyperparameterParamPaths (append target_mode context_features_key weight_feature) ) )
			(let
				(assoc
					;check if any hyperparameters exist that also match this action_feature and weight_feature
					;if any exist that were derived_auto_analyzed, remove them because that means these new hyperparameters supercede them
					old_params_key_to_remove
						(first (filter
							(lambda (and
								(get !hyperparameterMetadataMap (append (current_value) "derivedAutoAnalyzed"))
								;check if it matches with removed context key
								(= (remove (current_value) context_key_index) (append target_mode weight_feature) )
							))
							!hyperparameterParamPaths
						))
				)

				;remove old path befor adding the new one
				(if (size old_params_key_to_remove)
					(seq
						(assign_to_entities (assoc
							!hyperparameterParamPaths (filter (lambda (!= old_params_key_to_remove (current_value)) ) !hyperparameterParamPaths)
						))

						;remove the old context features set
						(assign_to_entities (assoc
							!hyperparameterMetadataMap
								(set
									!hyperparameterMetadataMap
									target_mode
									(remove (get !hyperparameterMetadataMap target_mode) (get old_params_key_to_remove context_key_index))
								)
							!hyperparameterParamPaths (list (append target_mode context_features_key weight_feature))
						))
					)

					;else add the new path
					(accum_to_entities (assoc
						!hyperparameterParamPaths (list (append target_mode context_features_key weight_feature))
					))
				)
			)
		)

		;add subtrainee ID
		(if deviation_subtrainee_name
			(assign (assoc
				baseline_hyperparameter_map (append baseline_hyperparameter_map {"subtraineeName" deviation_subtrainee_name})
			))
		)

		(if (= (get baseline_hyperparameter_map ["paramPath" 0]) ".default")
			;updating default hyperparam set with featuredeviations
			(assign_to_entities (assoc !defaultHyperparameters baseline_hyperparameter_map ))

			;update the appropriate hyperparameter set
			(assign_to_entities (assoc
				!hyperparameterMetadataMap (set !hyperparameterMetadataMap (get baseline_hyperparameter_map "paramPath") baseline_hyperparameter_map)
			))
		)
		(accum_to_entities (assoc !revision 1))
	)

	;updates baseline_hyperparameter_map
	;uses provided baseline_hyperparameter_map to compute the dataset MAE (!gridSerachError), if computed error is less than current/y stored error,
	;updates baseline_hyperparameter_map with the new error value, otherwise reverts it back to previous_analyzed_hp_map
	#!TestAccuracyAndKeepOrRevertHyperparameters
	(seq
		;re-set the defined random seed to run gridsearch the same way as it was run above
		(set_rand_seed sampling_random_seed)

		;run through one pass using feature weights to see if they should be used
		(assign (assoc
			dataset_mae (call !ComputeResidualForParameters)
		))

		;if previous pass did better than this pass, revert baseline_hyperparameter_map
		(if (>= dataset_mae (get baseline_hyperparameter_map "gridSearchError"))
			(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

			;else keep update current hyperparams with new error value and back them up
			(seq
				(assign (assoc
					baseline_hyperparameter_map (set baseline_hyperparameter_map "gridSearchError" dataset_mae)
				))
				(assign (assoc previous_analyzed_hp_map baseline_hyperparameter_map))
			)
		)
	)

	;use rewrite to update all hyperparameters sets with the new featureDomainAttributes
	#!UpdateHyperparametersWithFeatureDomainAttributes
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(seq
						;hp already have featureDomainAttributes defined, overwrite the counts and bounds
						(if (!= (null) (get (current_value) "featureDomainAttributes"))
							(let
								(assoc previous_hp_feature_limits_map (get (current_value 1) "featureDomainAttributes") )

								;smartly overwrite previous values with the newly computed ones
								(assign (assoc
									feature_limits_map
										(map
											(lambda (let
												(assoc
													previous_value (first (current_value 1))
													new_value (last (current_value 1))
												)

												;if both are null, keep them as null
												(if (= (null) previous_value new_value)
													(null)

													;if either value is missing from either map, keep whichever isn't null
													(or (= (null) previous_value) (= (null) new_value) )
													(or previous_value new_value)

													;else overwrite the value with the new one
													new_value
												)
											))
											previous_hp_feature_limits_map
											feature_limits_map
										)
								))
							)
						)

						;append the updated feature_limits_map to this hp map
						(append (current_value) (assoc "featureDomainAttributes" feature_limits_map) )
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update all deviations in hyperparemeters with user specified errors
	#!UpdateHyperparametersWithUserErrors
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					;hp already have featureDeviations defined, overwrite where necessary
					(if (!= (null) (get (current_value) "featureDeviations"))
						(let
							(assoc deviations_map (get (current_value 1) "featureDeviations") )

							(map
								(lambda (let
									(assoc
										deviation (get deviations_map (current_index 1))
										user_error_value (current_value 1)
										feature (current_index 1)
									)

									(declare (assoc
										deviation_value
											;set to max of user specified error and stored deviation in the map
											(if (!= (null) deviation)
												;if deviation is a tuple, update the first value
												(if (= (list) (get_type deviation))
													(set deviation 0 (max user_error_value (first deviation)) )
													;else just update the value itself
													(max user_error_value deviation)
												)
											)
									))

									;if deviation is null, that means we aren't using deviations so keep it as a null
									(if (!= (null) deviation_value)
										(assign (assoc
											deviations_map (set deviations_map feature deviation_value)
										))
									)
								))
								!userSpecifiedFeatureErrorsMap
							)

							;append the updated deviations_map to this hp map
							(append (current_value) (assoc "featureDeviations" deviations_map) )
						)

						(current_value)
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update hyperparameter map for newly added inactive feature
	; hp_map: the hp map to be updated, should be either !defaultHyperparameters or !hyperparameterMetadataMap
	#!UpdateHyperparametersWithNewFeature
	(declare
		(assoc hp_map (assoc) )

		(declare (assoc num_cases (call !GetNumTrainingCases) ))

		(rewrite
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(let
						(assoc
							feature_weights_map (get (current_value 1) "featureWeights")
							feature_deviations_map (get (current_value 1) "featureDeviations")
						)

						(if (!= (null) feature_weights_map)
							(assign (assoc feature_weights_map (append feature_weights_map (associate feature 0)) ))
						)

						(if (size feature_deviations_map)
							(assign (assoc
								feature_deviations_map
									;new feature deviation is smallest possible value (see !CacheFeatureMinGapAndResidual for details )
									(set feature_deviations_map feature (/ 1 (+ 0.5 num_cases)) )
							))
						)

						(append (current_value) (assoc
							"featureWeights" feature_weights_map
							"featureDeviations" feature_deviations_map
						))
					)

					;else return
					(current_value)
				)
			)
			hp_map
		)
	)


	#!GetHyperparameters
	(declare
		(assoc weight_feature ".none")

		;if only one set of analyzed params, return them
		(if (= 1 (size !hyperparameterParamPaths))
			(conclude (get !hyperparameterMetadataMap (first !hyperparameterParamPaths)))

			(= 0 (size !hyperparameterParamPaths))
			(seq
				(if (and
						(not !autoAnalyzeEnabled )
						(>= (call !GetNumTrainingCases) 2)
						;don't need to add this warning if it already exists (this can cause lots of lock contention in an untrained Trainee)
						(not (contains_index
							warnings
								(concat
									"There are no cached hyperparameters in this trainee. "
									"This operation was executed using a set of predefined default hyperparameters. "
									"Please run `analyze` or enable auto-analysis with `set_auto_analyze_params`."
								)
						))
					)
					(accum (assoc
						warnings
							(associate (concat
								"There are no cached hyperparameters in this trainee. "
								"This operation was executed using a set of predefined default hyperparameters. "
								"Please run `analyze` or enable auto-analysis with `set_auto_analyze_params`."
							))
					))
				)
				;if no params, use defaults
				(conclude !defaultHyperparameters)
			)
		)

		;there are multiple sets of analyze params, we must determine the best
		(declare (assoc
			context_key
				(if (or (= context_features (null)) (= context_features (list)))
					!trainedFeaturesContextKey

					;else context_features were passed
					(call !BuildContextFeaturesKey (assoc context_features context_features))
				)
		))

		;if feature is specified as "", this will default to ["targetless"] since "" can't be a targeted action feature
		(declare (assoc
			target_mode
				(if (or (= (null) feature) (not (contains_index !hyperparameterMetadataMap ["targeted" feature])) )
					(if (contains_index !hyperparameterMetadataMap "targetless")
						["targetless"]

						;else just use one of the targeted analyzed hyperparam sets
						["targeted" (first (indices (get !hyperparameterMetadataMap "targeted")))]
					)

					["targeted" feature]
				)
		))


		;if we have completely correct HPs, return them
		(if (contains_index !hyperparameterMetadataMap (append target_mode context_key weight_feature))
			(conclude (get !hyperparameterMetadataMap (append target_mode context_key weight_feature)) )
		)

		;we don't have the exact HPs, determine best context_key
		(let
			(assoc
				;sort context keys in order of decreasing length
				context_key_options
					(sort
						(lambda (< (size (current_value)) (size (current_value 1))))
						(indices (get !hyperparameterMetadataMap target_mode) )
					)
			)

			;naively set the context to the longest option
			(assign (assoc context_key (first context_key_options) ))


			(while (< (current_index) (size context_key_options))
				(assign (assoc candidate_context_key (get context_key_options (current_index 1)) ))

				(if (contains_index !hyperparameterMetadataMap (append target_mode candidate_context_key weight_feature))
					(conclude
						(assign (assoc context_key candidate_context_key))
					)

					(contains_index !hyperparameterMetadataMap (append target_mode candidate_context_key ".none"))
					(assign (assoc context_key candidate_context_key ))
				)
			)
		)

		;if we have the correct weight for the action and context, return it
		(if (contains_index !hyperparameterMetadataMap (append target_mode context_key weight_feature))
			(get !hyperparameterMetadataMap (append target_mode context_key weight_feature))

			;no case weight
			(contains_index !hyperparameterMetadataMap (append target_mode context_key ".none"))
			(get !hyperparameterMetadataMap (append target_mode context_key ".none"))

			;else the case_weight and ".none" isn't in the map, return the default params
			!defaultHyperparameters
		)
	)

	;builds a string key based on context feature list
	#!BuildContextFeaturesKey
	(apply "concat" (weave (sort context_features) "."))


	;return the full internal parameters map if no parameters are specified.
	;if any of the parameters are specified, then GetHyperparameters is called, which uses the specified parameters to find the most suitable set of hyperparameters to return
	;{read_only .true idempotent .true}
	#get_params
	(declare
		;returns {
		; 	type "assoc"
		;	additional_indices .false
		; 	indices {
		; 		"hyperparameter_map" {any_of [{ref "HyperparameterMap"} {ref "HyperparameterMapFull"}] description "The full map of hyperparameters or a specific map of hyperparameters if any parameters were given"}
		; 		"default_hyperparameter_map" {ref "HyperparameterMap" description "The map of default hyperparameters"}
		; 		"auto_analyze_enabled" {type "boolean" description "Flag indicating of auto-analysis is enabled."}
		; 		"analyze_threshold" {type "number" description "The number of cases at which the auto-analysis is triggered."}
		; 		"analyze_growth_factor" {type "number" description "The scalar rate at which the number of cases to trigger an auto-analysis grows with each iteration"}
		;		"numerical_precision" {ref "NumericalPrecision" description "Parameter controlling the tradeoff of precision of computations for speed."}
		; 	}
		; }
		(assoc
			;{type "string"}
			;the target feature of the desired hyperparameters, when specified as a feature name, outputs the matching "targeted" hyperparameters.
			;	When empty string "" will output "targetless" hyperparameters. When unspecified defaults to whatever hyperparameters were analyzed,
			;	prioritizing "targetless" hyperparameters if multiple parameters exist.
			action_feature (null)
			;{type "list" values "string"}
			;the set of context features used for the desired hyperparameters
			context_features (null)
			;{type "string"}
			;the weight feature used in the calculation of the desired hyperparameters
			weight_feature (null)
		)
		(call !ValidateParameters)

		(declare (assoc
			internal_parameters_map
				(assoc
					"hyperparameter_map"
						(if (= (null) action_feature context_features weight_feature)
							!hyperparameterMetadataMap

							;else one of these parameters were specified
							(call !GetHyperparameters
								(append
									(assoc
										feature action_feature
										context_features context_features
									)
									;don't pass weight_feature in if it wasn't specified,
									;allowing GetHyperparameters to use its defaults
									(if weight_feature (assoc weight_feature weight_feature) {})
								)
							)
						)

					"default_hyperparameter_map" !defaultHyperparameters
					"numerical_precision" (if !numericalPrecisionFastest "fastest" !numericalPrecision)
				)
		))

		(if !autoAnalyzeEnabled
			(accum (assoc
				internal_parameters_map
					(assoc
						"auto_analyze_enabled" !autoAnalyzeEnabled
						"analyze_threshold" !autoAnalyzeThreshold
						"analyze_growth_factor" !autoAnalyzeGrowthFactorAmount
					)
			))
		)

		(call !Return (assoc payload internal_parameters_map))
	)

	;sets internal hyperparameters
	;{idempotent .true}
	#set_params
	(declare
		(assoc
			;{ref "HyperparameterMapFull"}
			;must have at least an target_mode (e.g., "targetless") -> a contexts key -> weight feature -> k, p and dt provided.
			;	example:
			;   {
			;	  	"targetless" { "featureA.featureB.": { ".none" : { "k" : number, "p" : number, "dt": number }}},
			;		"targeted" : { "featureA" : { "featureB.featureC.": { ".none" : { "k" : number, "p" : number, "dt": number }}}},
			;			...
			;	}
			hyperparameter_map (null)
			;{ref "HyperparameterMap"}
			;an assoc of hyperparameters to use when no others are available must contain k, p, and dt.
			default_hyperparameter_map (null)
			;{type "boolean"}
			;flag, default is false. when true, returns when it's time for dataset to be analyzed again.
			auto_analyze_enabled (null)
			;{type "number"}
			;stores the threshold for the number of cases at which the dataset should be re-analyzed. dataset default is 100.
			analyze_threshold (null)
			;{type "number"}
			;the factor by which to increase the analyze threshold every time the dataset grows to the current threshold size
			;	dataset default value is the universal scaling factor e
			analyze_growth_factor (null)
			;{ref "NumericalPrecision"}
			;enum, acceptable values are:
			;	null or "recompute_precise" : default value, will use fast computation for finding similar cases but recompute their exact similarities and influences precisely
			;	"precise" : will always use high precision computation for finding similar cases and computing similarities and influences
			;	"fast" : will always use a fast approach for all computations which will use faster, but lower precision numeric operations
			;	"fastest": same as "fast" but will additionally use a faster approach specific for generative reacts
			numerical_precision (null)
		)
		(call !ValidateParameters)


		(if (!= (null) default_hyperparameter_map)
			(seq
				(accum (assoc default_hyperparameter_map {"paramPath" [".default"]} ))
				(assign_to_entities (assoc !defaultHyperparameters default_hyperparameter_map) )
			)
		)

		;the passed in hyperparameters must at least have the basic attributes defined correctly
		;iterate over action features
		(if (!= (null) hyperparameter_map)
			(let
				(assoc
					param_paths []
					keys []
				)

				;populate all provided param_paths from the specified hyperparameter_map by appending all the indices recursively
				#!RecursivelyAccumulateParamPaths
				(map
					(lambda
						(if (and
								(contains_index (current_value) "k")
								(contains_index (current_value) "p")
								(contains_index (current_value) "dt")
							)
							(accum (assoc param_paths [(append keys (current_index 2))] ))

							(call !RecursivelyAccumulateParamPaths (assoc
								keys (append keys (current_index 1))
								hyperparameter_map (current_value 1)
							))
						)
					)
					hyperparameter_map
				)

				(assign_to_entities (assoc
					!hyperparameterMetadataMap hyperparameter_map
					!hyperparameterParamPaths param_paths
				))
			)
		)

		(declare (assoc
			fastest
				;if numerical_precision is specified, set boolean to true if it's 'fastest', otherwise leave value as-is
				(if (!= (null) numerical_precision)
					(= "fastest" numerical_precision)
					!numericalPrecisionFastest
				)

			;change the actual stored numerical_precision from 'fastest' to 'fast'
			stored_numerical_precision (if (= "fastest" numerical_precision) "fast" numerical_precision)
		))

		(assign_to_entities (assoc
			!autoAnalyzeEnabled (if (!= (null) auto_analyze_enabled) auto_analyze_enabled !autoAnalyzeEnabled)
			!autoAnalyzeThreshold (if (!= (null) analyze_threshold) analyze_threshold !autoAnalyzeThreshold)
			!autoAnalyzeGrowthFactorAmount (if (!= (null) analyze_growth_factor) analyze_growth_factor  !autoAnalyzeGrowthFactorAmount)
			!numericalPrecision (if stored_numerical_precision stored_numerical_precision !numericalPrecision)
			!numericalPrecisionFastest fastest
		))

		(accum_to_entities (assoc !revision 1))
		(call !Return)
	)

	;resets all hyperparameters and thresholds back to original values, while leaving feature definitions alone
	;{idempotent .true}
	#reset_params
	(seq
		;remove dynamic deviation trainees
		(map
			(lambda (let
				(assoc
					subtrainee (get !hyperparameterMetadataMap (append (current_value 1) "subtraineeName"))
				)
				(if subtrainee
					(call delete_subtrainee (assoc path [subtrainee] ))
				)
			))
			!hyperparameterParamPaths
		)

		(assign_to_entities (assoc
			!autoAnalyzeEnabled .false
			!autoAnalyzeThreshold 100
			!autoAnalyzeGrowthFactorAmount 7.3890561
			!numericalPrecision (null)
			!numericalPrecisionFastest .false
			!defaultNumSamples 100
			!hyperparameterMetadataMap (assoc)
			!defaultHyperparameters
				(assoc
					"k" 8
					"p" 0.1
					"dt" -1
					"featureWeights" (null)
					"featureDeviations" (null)
					"paramPath" [".default"]
				)
		))
		(accum_to_entities (assoc !revision 1))
		(call !Return)
	)

	;sets the dataset to auto-analyze by tracking its size and notifying the clients in train responses when it should be analyzed
	;{idempotent .true}
	#set_auto_analyze_params
	(declare
		(assoc
			;{type "boolean"}
			;flag, default is false. when true, returns when it's time for dataset to be analyzed again.
			auto_analyze_enabled .false
			;{type "number"}
			;stores the threshold for the number of cases at which the dataset should be re-analyzed. default of 100.
			analyze_threshold 100
			;{type "number" exclusive_min 1.0}
			;the factor by which to increase the analyze threshold every time the dataset grows to the current threshold size
			;	default of using the universal scaling factor e^2
			analyze_growth_factor 7.3890561
			;{type "list" values "string"}
			;the features to use as contexts in the analysis
			context_features (null)
			;{type "list" values "string"}
			;the features that the analysis should target
			action_features (null)
			;{type "number" min 1}
			;number of cross validation folds to do. value of 1 does hold-one-out instead of k-fold
			k_folds 1
			;{type "boolean"}
			;flag, if true will not do any search over k, p, and dt parameters, but still may compute feature residuals
			; depending on other parameters.
			bypass_hyperparameter_analysis .false
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature residuals
			bypass_calculate_feature_residuals .false
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature weights
			bypass_calculate_feature_weights .false
			;{type ["boolean" "null"]}
			;whether to use deviations for LK metric in queries. When true forces the use
			;	of deviations, when false will not use deviations. If unspecified, the better performing option will be selected.
			use_deviations (null)
			;{type "number" min 2}
			;number of cases to use to approximate deviations and residuals for both targetless and targeted flows.
			;defaults to 1000 if unspecified.
			num_deviation_samples (null)
			;{type "number" min 2}
			;number of samples to use to compute feature probabilities, only applies to targetless flow.
			;If unspecified will be dynamically set based on number features and data characteristics.
			num_feature_probability_samples (null)
			;{type "number" min 2}
			;number of cases to sample used for grid search for the targeted flow. only applies for k_folds = 1. defaults to 1000.
			num_analysis_samples (null)
			;{type "number" min 2}
			;number of samples to use for analysis. the rest will be randomly held-out and not included in calculations
			analysis_sub_model_size (null)
			;{type "list" values ["number" "list"]}
			;list of values for k (number of cases making up the local space) to grid search during analysis
			;if a value is a list of values, treats the inner list as a tuple of: influence cutoff percentage, min K, max K and extra K.
			k_values (null)
			;{type "list" values "number"}
			;list of values for p (the parameter of the Lebesgue space) to grid search during analysis
			p_values (null)
			;{type "list" values ["number" "string"]}
			;list of values for dt (the distance transform) to grid search during analysis
			dt_values (null)
			;{type "string" enum ["single_targeted" "omni_targeted" "targetless"]}
			;enumeration, default is "single_targeted"
			;   "single_targeted" = analyze hyperparameters for the specified action_features
			;   "omni_targeted" = analyze hyperparameters for each action feature, using all other features as context_features. if action_features aren't specified, uses all context_features.
			;   "targetless" = analyze hyperparameters for all context features as possible action features, ignores action_features parameter
			targeted_model (null)
			;{type "string"}
			;name of feature whose values to use as case weights
			weight_feature ".case_weight"
			;{ref "UseCaseWeights"}
			;when true will scale influence weights by each case's weight_feature weight. if use_case_weights isn't specified, it will
			;	be true if auto ablation is enabled and false otherwise
			use_case_weights (null)
			;{type "list" values "string"}
			;list of features whose values to use to rebalance case weighting of the data and to store into weight_feature
			rebalance_features (null)
			;{type ["boolean" "null"]}
			;when true, the default, will compute and use a sparse deviation matrix (SDM) for each nominal feature in all similarity queries.
			;Enabling SDM will typically incur a small to moderate penalty on speed when using nominal features in inference in exchange for
			;yielding higher quality inference. The magnitude of the changes are dependent on relationships among the data and the task at hand.
			use_sdm (null)
			;{type "number" min 0}
			;Percent threshold used to dynamically limit the number of samples used to determine feature probabilities, defaults to 0.5%
			;When set to 0 will use all num_feature_probability_samples
			convergence_threshold (null)
			;{type "number" min 1}
			;Rate of increasing the size of each subsequent sample used to dynamically limit the total number of samples used to determine feature probabilities.
			;defaults to a rate of 1.05, increasing by 5% until the delta between residuals is less than 'convergence_threshold'.
			convergence_samples_growth_rate (null)
			;{type "number" min 1}
			;The minimum size of the first batch of cases used when dynamically sampling robust residuals used to determine feature probabilities
			;	Default of 5000
			convergence_min_size 5000
			;{type "boolean"}
			;when true, used by reduce_data flow to simplify analyze flow by skipping computation of feature weights
			reduce_only .false
		)
		(call !ValidateParameters)

		(if (and
				(size action_features)
				(= (size context_features) 0)
			)
			(conclude
				(call !Return (assoc
					errors ["`context_features` must be specified when `action_features` is specified."]
				))
			)
		)

		(declare (assoc num_cases (call !GetNumTrainingCases) ))

		;if the dataset is already larger than the specified analyze_threshold, set the analyze_threshold to a valid value nearest the current
		;number of cases in the dataset without going over
		(if
			(and
				(!= (null) analyze_threshold)
				(> num_cases analyze_threshold)
			)
			(seq
				;keep increasing the analysis_threshold by the growth_factor_amount until it's bigger than the current number of cases
				;and then decrease it back down so that it's just below
				(while (> num_cases analyze_threshold)
					(assign (assoc analyze_threshold (* analyze_threshold analyze_growth_factor)))
				)

				(assign (assoc analyze_threshold (/ analyze_threshold analyze_growth_factor )))
			)
		)

		(assign_to_entities (assoc
			!autoAnalyzeEnabled auto_analyze_enabled
			!autoAnalyzeThreshold analyze_threshold
			!autoAnalyzeGrowthFactorAmount analyze_growth_factor
		))

		;if any parameters are specified, store them
		(if (or
				context_features
				action_features
				(!= 1 k_folds)
				bypass_hyperparameter_analysis
				bypass_calculate_feature_residuals
				bypass_calculate_feature_weights
				use_deviations
				num_deviation_samples
				k_values
				p_values
				dt_values
				targeted_model
				num_analysis_samples
				num_feature_probability_samples
				analysis_sub_model_size
				(!= ".case_weight" weight_feature)
				use_case_weights
				rebalance_features
				(!= (null) use_sdm)
				convergence_threshold
				convergence_samples_growth_rate
				convergence_min_size
				reduce_only
			)
			(seq
				(if (= (null) targeted_model)
					(assign (assoc
						targeted_model
							(if (= 0 (size action_features))
								"targetless"

								(= 1 (size action_features))
								"single_targeted"

								"omni_targeted"
							)
					))
				)
				(assign_to_entities (assoc
					!savedAnalyzeParameterMap
						(filter (assoc
							"context_features" context_features
							"action_features" action_features
							"k_folds" k_folds
							"bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
							"bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
							"bypass_calculate_feature_weights" bypass_calculate_feature_weights
							"use_deviations"  use_deviations
							"num_deviation_samples" num_deviation_samples
							"k_values" k_values
							"p_values" p_values
							"dt_values" dt_values
							"targeted_model" targeted_model
							"num_analysis_samples" num_analysis_samples
							"num_feature_probability_samples" num_feature_probability_samples
							"analysis_sub_model_size" analysis_sub_model_size
							"weight_feature" weight_feature
							"use_case_weights" use_case_weights
							"rebalance_features" rebalance_features
							"use_sdm" use_sdm
							"convergence_threshold" convergence_threshold
							"convergence_samples_growth_rate" convergence_samples_growth_rate
							"convergence_min_size" convergence_min_size
							"reduce_only" reduce_only
						))
				))
			)
		)

		(accum_to_entities (assoc !revision 1))

		(call !Return)
	)

	;get auto-ablation parameters set by #set_auto_ablation_params
	;{read_only .true idempotent .true}
	#get_auto_ablation_params
	(declare
		;returns {ref "GetAutoAblationParamsResponse"}
		(assoc)


		(call !Return (assoc
			payload
				(assoc
					auto_ablation_enabled !autoAblationEnabled
					auto_ablation_weight_feature !autoAblationWeightFeature
					min_num_cases !autoAblationMinNumCases
					max_num_cases !autoAblationMaxNumCases
					auto_ablation_influence_weight_entropy_threshold !autoAblationInfluenceWeightEntropyThreshold
					reduce_data_influence_weight_entropy_threshold !reduceDataInfluenceWeightEntropyThreshold
					reduce_max_cases !postReduceMaxCases
					abs_threshold_map !autoAblationAbsThresholdMap
					delta_threshold_map !autoAblationDeltaThresholdMap
					rel_threshold_map !autoAblationRelThresholdMap
					exact_prediction_features !autoAblationExactPredictionFeatures
					tolerance_prediction_threshold_map !autoAblationTolerancePredictionThresholdMap
					relative_prediction_threshold_map !autoAblationRelativePredictionThresholdMap
					residual_prediction_features !autoAblationResidualPredictionFeatures
					conviction_upper_threshold !autoAblationConvictionUpperThreshold
					conviction_lower_threshold !autoAblationConvictionLowerThreshold
					influence_weight_entropy_sample_size !autoAblationInfluenceWeightEntropySampleSize
				)
		))
	)

	;sets the dataset to auto-ablate by tracking its size and training certain cases as weights
	;{idempotent .true}
	#set_auto_ablation_params
	(declare
		(assoc
			;{type "boolean"}
			;flag, default is false. when true, any enabled ablation techniques will be run at during training.
			auto_ablation_enabled .false
			;{type "string"}
			;the weight feature that should be used when ablating.
			auto_ablation_weight_feature ".case_weight"
			;{type "number"}
			;stores the threshold for the minimum number of cases at which the dataset should auto-ablate.
			;This is also the minimum number of cases that calls to reduce_data will reduce the training data down to.
			;	default of 10000.
			min_num_cases 10000
			;{type "number"}
			;stores the threshold for the number of cases at which the dataset should automatically reduce data.
			;	default of 200,000.
			max_num_cases 200000
			;{type "number"}
			;the influence weight entropy quantile that a case must be beneath in order to be trained.
			;	default of 1/e^2.
			auto_ablation_influence_weight_entropy_threshold 0.135335283
			;{type "number"}
			;the influence weight entropy quantile that a case must be beneath in order to not be removed.
			;	default of 1-1/e.
			reduce_data_influence_weight_entropy_threshold 0.632120559
			;{type "number"}
			;stores the maximum number of cases that may remain after a call to reduce_data.
			;	default of 50,000.
			reduce_max_cases 50000
			;{type "number"}
			;maximum number of cases to sample without replacement for computing the influence weight entropy threshold
			; default of 2000
			influence_weight_entropy_sample_size 2000
			;{type "list" values "string"}
			;list of features. for each of the features specified, will ablate a case if the prediction
			;	matches exactly.
			exact_prediction_features (null)
			;{type "assoc" additional_indices {type "list" min_size 2 max_size 2}}
			;assoc of feature -> [MIN, MAX]. for each of the features specified, will
			;	ablate a case if the prediction >= (case value - MIN) and the prediction <= (case value + MAX)
			tolerance_prediction_threshold_map (null)
			;{type "assoc" additional_indices "number"}
			;assoc of feature -> PERCENT. for each of the features specified, will
			;	ablate a case if abs(prediction - case value) / prediction <= PERCENT
			relative_prediction_threshold_map (null)
			;{type "list" values "string"}
			;list of features. for each of the features specified, will ablate a case if
			;	abs(prediction - case value) <= feature residual
			residual_prediction_features (null)
			;{type "number"}
			;the conviction value below which cases will be ablated
			conviction_upper_threshold (null)
			;{type "number"}
			;the conviction value above which cases will be ablated
			conviction_lower_threshold (null)
			;{type "number" min 1}
			;the number of cases to ablate between analyses and influence weight entropy recalculation
			batch_size 2000
			;{type "number"}
			;the number of ablated cases to compute influence weights for distribution at a time
			ablated_cases_distribution_batch_size 100
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; absolute thresholds will cause ablation to stop when any of the measure values for any of
			; the features for which a threshold is defined go above the threshold (in the case of rmse and
			; mae) or below the threshold (otherwise).
			abs_threshold_map (assoc)
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; delta thresholds will cause ablation to stop when the delta between any of the measure values
			; for any of the features for which a threshold is defined and its previous value go above the threshold
			; (in the case of rmse and mae) or below the threshold (otherwise).
			delta_threshold_map (assoc)
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; relative thresholds will cause ablation to stop when the relative change between any of the
			; measure values for any of the features for which a threshold is defined and its previous value go
			; above the threshold (in the case of rmse and mae) or below the threshold (otherwise).
			rel_threshold_map (assoc)
		)
		(call !ValidateParameters)

		(if
			(or (< auto_ablation_influence_weight_entropy_threshold 0) (> auto_ablation_influence_weight_entropy_threshold 1))
			(assign (assoc auto_ablation_entropy_threshold_quantile 1.0))
		)

		(assign_to_entities (assoc
			!autoAblationEnabled auto_ablation_enabled
			!autoAblationWeightFeature auto_ablation_weight_feature
			!autoAblationMinNumCases min_num_cases
			!autoAblationMaxNumCases max_num_cases
			!autoAblationInfluenceWeightEntropySampleSize influence_weight_entropy_sample_size
			!autoAblationInfluenceWeightEntropyThreshold auto_ablation_influence_weight_entropy_threshold
			!reduceDataInfluenceWeightEntropyThreshold reduce_data_influence_weight_entropy_threshold
			!postReduceMaxCases reduce_max_cases
			!autoAblationExactPredictionFeatures exact_prediction_features
			!autoAblationTolerancePredictionThresholdMap tolerance_prediction_threshold_map
			!autoAblationRelativePredictionThresholdMap relative_prediction_threshold_map
			!autoAblationResidualPredictionFeatures residual_prediction_features
			!autoAblationConvictionUpperThreshold conviction_upper_threshold
			!autoAblationConvictionLowerThreshold conviction_lower_threshold
			!autoAblationAbsThresholdMap abs_threshold_map
			!autoAblationDeltaThresholdMap delta_threshold_map
			!autoAblationRelThresholdMap rel_threshold_map
			!ablationBatchSize batch_size
			!ablatedCasesDistributionBatchSize ablated_cases_distribution_batch_size
		))

		(accum_to_entities (assoc !revision 1))
		(call !Return)
	)

	;Convert confusion matrix (assoc class -> (assoc of class -> counts)) to sparse deviation matrix (SDM):
	;with the possible formats:
	; an assoc of assocs: (assoc of class -> (assoc of class -> deviation))
	;if there's a default_class_deviation, the deviation value to be used for any classes that didn't have any counts:
	; each row will be an assoc of list (pair) of: assoc and value:
	;  (assoc of class -> (list of: (assoc of class -> deviation), default_class_deviation))
	;
	;The SDM is output as a tuple (pair) in the format of: [ SDM unknown_class_deviation ]
	;where unknown_class_deviation is the deviation value to be used for any class that isn't defined in the SDM
	;
	;returns null if the the passed in confusion matrix does not have enough counts to be statistically significant.
	;
	;parameters:
	; confusion_matrix:  assoc of class -> assoc of class -> predicted count for each class.
	; feature: name of nominal feature
	; confusion_matrix_min_count: number of predictions a class should have for it to have an explicit deviation value.
	;	If the count is less than this value, the deviation will be in the combined deviation for the class. default value is 10
	; expected_deviation: value of expected deviation if sdm is not being referenced
	#!ConfusionMatrixToSDM
	(declare
		(assoc
			confusion_matrix (assoc)
			confusion_matrix_min_count 15
			expected_deviation (null)
		)

		(declare (assoc
			total_predictions
				(apply "+" (values
					(map
						(lambda (or (apply "+" (values (current_value))) 0) )
						confusion_matrix
					)
				))
		))

		;output null if the total count is too small
		(if (< total_predictions confusion_matrix_min_count)
			(conclude (null))
		)

		(declare (assoc
			;Using n+1, n+2, or n+.5 are all possible considerations of Laplacian smoothing to apply a Bayesian approach for
			;estimating the probability of having no incorrect predictions.  We chose .5 assuming the Jeffreys prior approach.
			smallest_prob (/ 1 (+ 0.5 total_predictions))
			;max accuracy is 1 - smallest_probability
			max_accuracy (- 1 (/ 1 (+ 0.5 total_predictions)))
			predictions_per_class_map
				(map
					(lambda (apply "+" (values (current_value))) )
					confusion_matrix
				)
			leftover_confusion_matrix (assoc)
			leftover_unknown_class_deviation (null)
			valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")) )
			feature_grouping
				(if (get !sharedDeviationsMap feature)
					(call !GetSharedDeviationGrouping (assoc feature_group_to_retrieve feature))
					[feature]
				)
		))

		(declare (assoc
			;map of class -> accuracy of random guessing
			rand_guess_accuracy_map (map (lambda (/ (current_value) total_predictions)) predictions_per_class_map)
		))

		;filter out counts below threshold in confusion matrix and store as probabilities correct instead of counts
		;leaving only those predicted classes that had enough predictions
		(call !ConvertAndReduceConfusionMatrix)

		(if (= 0 (size confusion_matrix))
			(conclude (null))
		)

		;pull the number of classes for this feature from !expectedValuesMap if it was cached, otherwise compute it here
		;if feature is in a shared deviation feature_grouping, counts the total number of unique classes from all the features in the group
		(declare (assoc
			num_classes
				(size (values
					(apply "append"
						(map
							(lambda
								(let
									(assoc
										feature_classes (indices (get !expectedValuesMap [weight_feature (current_value 2) "class_counts"]))
										current_feature (current_value 1)
									)
									(if (= 0 (size feature_classes))
										(indices
											(compute_on_contained_entities
												(query_value_masses
													current_feature
													(if valid_weight_feature weight_feature)
												)
											)
										)
										feature_classes
									)
								)
							)
							feature_grouping
						)
					)
					.true
				))
		))

		;average all probabilities for a class that are same as or more than the predicted class probability
		(declare (assoc
			prob_match_or_indistinguishable_map
				(map
					(lambda (let
						(assoc predicted_class_prob (+ (or (get (current_value 1) (current_index 1)))) )
						(declare (assoc
							avg_probs_same_or_larger_than_predicted
								(filter
									(lambda (>= (current_value) predicted_class_prob))
									(values (current_value 1))
								)
						))
						;if nothing is filtered out, average across all classes
						(if (= 0 predicted_class_prob)
							(/ (apply "+" avg_probs_same_or_larger_than_predicted) num_classes)

							(generalized_mean avg_probs_same_or_larger_than_predicted)
						)
					))
					confusion_matrix
				)
		))

		;indistinguishable accuracy matrix
		;Clamps predicted probabilities to random guesses
		(declare (assoc guessing_accuracy_matrix (call !ClampSDMProbabilities) ))

		;compute the full deviation matrix
		(declare (assoc
			deviation_matrix
				(map
					(lambda (let
						(assoc
							;probability of correct predicted class
							class_probability (get (current_value 1) (current_index 1))
							num_sparsified_values (- num_classes (size (current_value 1)))
						)

						;total probability of the row
						(declare (assoc
							total_probability
								;sum all the probabilities in the row
								;add the number of smallest_prob values equal to the number of sparsified values
								(if num_sparsified_values
									(+
										(apply "+" (values (current_value 1)) )
										(* num_sparsified_values smallest_prob)
									)

									;else sum up all the probabilities in the row as-is
									(apply "+" (values (current_value 1)) )
								)
						))

						;normalize each prediction probability by iterating over all the predictions
						;in the row and dividing by total_probability
						(map
							(lambda
								(max
									(- 1 (/ (min class_probability (current_value)) total_probability))
									smallest_prob
								)
							)
							(current_value)
						)
					))
					guessing_accuracy_matrix
				)
		))

		;store default class (row) deviations for any classes that are not in each row
		(declare (assoc
			leftover_class_deviation_map
				(filter (map
					(lambda (let
						(assoc
							num_sparsified_values (- num_classes (size (current_value 1)))
						)

						(if num_sparsified_values
							(- 1 (/
								smallest_prob
								;sum all the probabilities in the row
								;add the number of smallest_prob values equal to the number of sparsified values
								(+
									(apply "+" (values (current_value)) )
									(* num_sparsified_values smallest_prob)
								)

							))
						)
					))
					guessing_accuracy_matrix
				))
		))

		;SDM is always output as a tuple of: [matrix unknown_class_deviation]
		(list
			(call !FormatSDMForOutput)
			(if leftover_unknown_class_deviation
				;if there's a leftover_unknown_class_deviation, output the SDM as a list (pair)
				leftover_unknown_class_deviation

				;if there is only one class trained, set the unknown deviation to be max possible value
				(= [1] (values rand_guess_accuracy_map))
				max_accuracy

				;else just output the expected deviation
				expected_deviation
			)
		)
	)

	;Edits deviation_matrix for output by filtering out deviations that correspond to counts that aren't in the sparse confusion matrix
	;and return tuples with the default class deviation for classes that have those computed
	#!FormatSDMForOutput
	(map
		(lambda
			;if there is a default deviation for the class, output a tuple of [sparse deviation map, default class deviation]
			(if (contains_index leftover_class_deviation_map (current_index))
				[
					(current_value 1)
					(get leftover_class_deviation_map (current_index 1))
				]

				;just output the sdm assoc
				(current_value)
			)
		)
		deviation_matrix
	)

	;computes the "leftover" confusion matrix of class counts that did not have statistical significance
	;and stores it into leftover_confusion_matrix
	#!ComputeLeftoverConfusionMatrix
	(seq
		(assign (assoc
			leftover_confusion_matrix
				;remove classes with empty rows by leaving only those with non-empty rows
				(filter (lambda (size (current_value)))
					;iterate over rows of confusion matrix
					(map
						(lambda (let
							(assoc
								predicted_class (current_index 1)
								row_map (current_value 1)
							)
							;leave entire row if predicted class doesn't have enough samples
							(if
								(or
									(= (null) (get row_map predicted_class))
									(< (get row_map predicted_class) confusion_matrix_min_count)
								)
								row_map

								;else only leave those classes that have counts but not enough samples
								(filter
									(lambda
										(and
											(< (current_value) confusion_matrix_min_count)
											(!= 0 (current_value))
										)
									)
									row_map
								)
							)
						))
						confusion_matrix
					)
				)
		))
	)

	;Helper method for computing SDM, called by ConfusionMatrixToSDM, filters out counts below threshold and stores as probabilities correct instead.
	;leaves only those predicted classes that had enough predictions.
	;Also computes the fallback residuals if there are any counts that didn't have enough statistical significance.
	#!ConvertAndReduceConfusionMatrix
	(seq
		(call !ComputeLeftoverConfusionMatrix)

		(declare (assoc
			total_leftover_correct_predictions
				(apply "+" (values
					(map (lambda (+ (or (get (current_value) (current_index))))) leftover_confusion_matrix)
				))
			total_leftover_all_predictions
				(apply "+" (values
					(map
						(lambda (apply "+" (values (current_value))))
						leftover_confusion_matrix
					)
				))
		))

		(assign (assoc
			confusion_matrix
				;current_index is the class being predicted
				;current_value is an assoc of class -> number predictions
				(map
					(lambda (let
						(assoc
							total_class_predictions (apply "+" (values (current_value 1)))
							predicted_class (current_index 1)
						)
						;convert counts to percent accuracy by dividing each count by total_class_predictions
						;filter out any entries where there weren't enough counts
						(filter (map
							(lambda
								(if (>= (current_value) confusion_matrix_min_count)
									(/ (current_value) total_class_predictions)

									;if the predicted class (diagonal) doesn't have enough, represent it with a 0 instead of filtering it out
									(= (current_index) predicted_class)
									0
								)
							)
							;ensure the predicted class is represented in the row even if it has no counts
							;since the values on the diagonal should all be present
							(if (contains_index (current_value) predicted_class)
								(replace (current_value))
								(append (replace (current_value)) (associate predicted_class 0))
							)
						))
					))
					confusion_matrix
				)
		))

		(declare (assoc
			weighted_accuracy_map
				;weighted accuracy for each class is its predicted probability * random guess accuracy
				(map
					(lambda (let
						(assoc predicted_class_prob (get (current_value 1) (current_index 1)))
						(* predicted_class_prob (get rand_guess_accuracy_map (current_index)) )
					))
					confusion_matrix
				)
		))
		(declare (assoc avg_random_accuracy (apply "+" (values weighted_accuracy_map)) ))

		(assign (assoc
			leftover_unknown_class_deviation
				;fallback #1, if there are enough leftover predictions, deviation is 1 - correct leftovers / total leftovers
				(if (>= total_leftover_correct_predictions confusion_matrix_min_count)
					(- 1 (/ total_leftover_correct_predictions total_leftover_all_predictions) )

					;else if there aren't enough leftover counts to compute unknown class deviation, use weighted random chance
					(> total_leftover_all_predictions total_leftover_correct_predictions)
					(let
						(assoc all_classes_map (get !expectedValuesMap [weight_feature feature "class_counts"]) )
						(if (= 0 (size all_classes_map))
							(assign (assoc
								all_classes_map
									(compute_on_contained_entities
										(query_value_masses
											feature
											(if valid_weight_feature weight_feature)
										)
									)
							))
						)

						(declare (assoc
							non_sdm_classes (indices (remove all_classes_map (indices confusion_matrix)) )
						))
						;fallback #2, if there are classes in the dataset that weren't in the sdm, use random guess probability of those classes
						(if (size non_sdm_classes)
							(let
								(assoc total_count (apply "+" (values all_classes_map)) )

								;rand guess prob of classes not in sdm : 1 - sum of prob^2
								(- 1
									(apply "+"
										(map
											(lambda
												(pow
													(/ (get all_classes_map (current_value)) total_count)
													2
												)
											)
											non_sdm_classes
										)
									)
								)
							)

							;else fallback #3, use the average weighted random guess accuracy from the confusion matrix
							;deviation = 1 - average accuracy
							(- 1 avg_random_accuracy)
						)
					)

					;else value remains as null if there are no leftover counts
					(null)
				)
		))

		;ensure unknown class deviation isn't 0 by setting the floor to be the smallest possible probability
		(if (!= (null) leftover_unknown_class_deviation)
			(assign (assoc
				leftover_unknown_class_deviation (max smallest_prob leftover_unknown_class_deviation)
			))
		)

		;average accuracy of 0 means there are no (or not enough significant) counts for any of the predicted classes
		(if (= 0 avg_random_accuracy)
			(assign (assoc confusion_matrix (assoc) ))
		)
	)

	;helper method for computing SDM that clamps probabilities for the predicted classes to be no worse than random guessing
	#!ClampSDMProbabilities
	(declare
		(assoc
			guessing_accuracy_matrix
				;diagonal values are the probability of the match
				;all other classes are their probability without exceeding the predicted class probability (corresponding diagonal value)
				(map
					(lambda (let
						(assoc
							predicted_class (current_index 1)
							row_map (current_value 1)
						)
						(map
							(lambda
								(if (= predicted_class (current_index))
									(get prob_match_or_indistinguishable_map (current_index))

									;all other classes can't exceed the predicted class's probability
									(min
										(get prob_match_or_indistinguishable_map predicted_class)
										(+ (or (current_value)))
									)
								)
							)
							row_map
						)
					))
					confusion_matrix
				)
		)

		;guessing clamped accuracy
		;limit max accuracy of predicted classes to max of computed probability and random correct guess
		;limit min accuracy of other classes to min of computed probability and random wrong guess
		(map
			(lambda (let
				(assoc
					predicted_class (current_index 1)
					row_map (current_value 1)
				)

				(map
					(lambda
						(if (= predicted_class (current_index))
							(replace (max (get row_map predicted_class) (get rand_guess_accuracy_map predicted_class)))

							;set floor for accuracy using random matching probability
							(min
								(replace (max smallest_prob (current_value)))
								;probability of guessing wrong is 1 - random guess
								(- 1 (get rand_guess_accuracy_map predicted_class) )
							)
						)
					)
					row_map
				)
			))
			guessing_accuracy_matrix
		)
	)


)
