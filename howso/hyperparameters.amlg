;Contains helper methods for hyperparameter maintenance.
(null

	; contains, p, k, dt, gridSearchError, etc
	#!BackupAnalyzedHyperparameters
	(assign (assoc
		previous_analyzed_hp_map analyzed_hp_map
		baseline_hyperparameter_map analyzed_hp_map
	))

	;updates baseline_hyperparameter_map
	#!KeepOrRevertHyperparameters
	(if (<= (get previous_analyzed_hp_map "gridSearchError") (get analyzed_hp_map "gridSearchError"))
		(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

		;else update with analyzed
		(assign (assoc baseline_hyperparameter_map analyzed_hp_map))
	)

	;updates baseline_hyperparameter_map
	#!UpdateHyperparameters
	(declare
		(assoc
			use_weights (null)
			feature_weights (null)
			use_deviations (null)
			feature_deviations (null)
			null_deviations (null)
			ordinal_feature_deviations (null)
			attribute_map (assoc)
			confusion_matrix_map (null)
		)

		(if (size confusion_matrix_map)
			(assign (assoc
				feature_deviations
					(map
						;convert deviations for nominals that had a confusion matrix computed from a single value into an assoc
						;containing the nominal deviation as 'expected_deviation' and a sparse deviation matrix as 'sdm'
						(lambda
							(if (contains_index confusion_matrix_map (current_index))
								(let
									(assoc feature (current_index 1) )
									(declare (assoc
										sdm
											##SparseDeviationMatrix
											(call !ConfusionMatrixToSDM (assoc
												confusion_matrix (get confusion_matrix_map [feature "matrix"])
												feature feature
												expected_deviation (current_value 2)
											))
									))

									;output an assoc of sdm and expected deviation
									(if sdm
										(assoc
											"sdm" sdm
											"expected_deviation" (current_value 1)
										)

										;else there is no sdm, return just the value
										(current_value)
									)
								)

								;else leave deviation value as-is
								(current_value)
							)
						)
						feature_deviations
					)
			))
		)

		(accum (assoc
			attribute_map
				(append
					;if clearing weights, set them to null
					(if (= (false) use_weights)
						;if there are inactive features, we have to reset active features to 1s and inactives to 0s
						(if !inactiveFeaturesMap
							(assoc "featureWeights"
								(append
									(zip
										(indices (get baseline_hyperparameter_map "featureWeights"))
										1
									)
									!inactiveFeaturesMap
								)
							)

							;else null out the weights
							(assoc "featureWeights" (null))
						)

						(assoc)
					)
					(if feature_weights
						(assoc "featureWeights" feature_weights)
						(assoc)
					)
					(if use_deviations
						(assoc
							"featureDeviations"
								;append null_deviations to feature_deviations
								(if (size null_deviations)
									(map
										(lambda
											;create a tuple of [deviation, value<->null uncertainty, null<->null uncertainty]
											(if (size (last (current_value)))
												;if the deviation is an assoc (nominal feature with SDM), ensure the result is a triple
												(if (~ (assoc) (first (current_value)))
													(append (list (get (current_value 1) (list 0 "sdm"))) (last (current_value)) )

													(append (first (current_value)) (last (current_value)) )
												)

												;else return the deviation value without the known-unkwnown uncertainties
												;an assoc means this is a SDM
												(if (~ (assoc) (first (current_value)))
													;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
													[(get (current_value 1) [0 "sdm"])]

													(first (current_value))
												)
											)
										)
										feature_deviations
										null_deviations
									)

									;else just store provided deviations, but pull the sdm out to store as-is
									(map
										(lambda
											;an assoc means this is a SDM
											(if (~ (assoc) (current_value))
												;since sdm is a tuple, must wrap it in a list so the tuple itself is treated as the deviation
												[(get (current_value 1) "sdm")]

												(current_value)
											)
										)
										feature_deviations
									)
								)
						)

						;if not using deviations but provided null uncertainties, use those as deviations
						(size null_deviations)
						(assoc
							"featureDeviations"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (replace (current_value)))) null_deviations)
						)

						(assoc)
					)
					(if (size ordinal_feature_deviations)
						(assoc "featureOrdinalDeviations" ordinal_feature_deviations)
						(assoc)
					)

					;always store a copy of feature deviations during analyze flow, to be removed once analyze is done
					(if feature_deviations
						(assoc
							"featureResiduals"
								(map
									(lambda
										(if (~ 0 (current_value))
											(current_value)

											;must be a nominal
											(~ (assoc) (current_value))
											(get (current_value) "expected_deviation")

											;else fall back to null, this should never happen
											(null)
										)
									)
									feature_deviations
								)
						)
						(assoc)
					)

					;null uncertainties store a tuple of [null, value<->null uncertainty, null<->null uncertainty]
					(if (size null_deviations)
						(assoc
							"nullUncertainties"
								;prepend a null to represent the undefined feature deviation
								(map (lambda (append (list (null)) (current_value))) null_deviations)
						)
						(assoc)
					)
				)
		))

		(accum (assoc baseline_hyperparameter_map attribute_map ))
	)

	;write baseline_hyperparameter_map out to the model's !hyperparameterMetadataMap
	#!SetModelHyperParameters
	(seq
		(if derived_auto_analyzed
			(accum (assoc baseline_hyperparameter_map (assoc "derivedAutoAnalyzed" (true)) ))
		)

		(if (not (contains_value !hyperparameterParamPaths (list action_feature context_features_key robust_mode weight_feature)) )
			(let
				(assoc
					;check if any hyperparameters exist that also match this action_feature robust_mode and weight_feature
					;if any exist that were derived_auto_analyzed, remove them because that means these new hyperparameters supercede them
					old_params_key_to_remove
						(first (filter
							(lambda (and
								(get !hyperparameterMetadataMap (append (current_value) "derivedAutoAnalyzed"))
								(= (remove (current_value) 1) (list action_feature robust_mode weight_feature))
							))
							!hyperparameterParamPaths
						))
				)

				(if (size old_params_key_to_remove)
					(seq
						(assign_to_entities (assoc
							!hyperparameterParamPaths (filter (lambda (!= old_params_key_to_remove (current_value)) ) !hyperparameterParamPaths)
						))

						;remove the old context features set
						(accum_to_entities (assoc
							!hyperparameterMetadataMap
								(associate
									action_feature
										(remove (get !hyperparameterMetadataMap action_feature) (get old_params_key_to_remove 1))
								)
						))
					)
				)

				(accum_to_entities (assoc !hyperparameterParamPaths (list (list action_feature context_features_key robust_mode weight_feature)) ))
			)
		)

		(if (= (get baseline_hyperparameter_map ["paramPath" 0]) ".default")
			;updating default hyperparam set with featuredeviations
			(assign_to_entities (assoc !defaultHyperparameters baseline_hyperparameter_map) )

			;update the appropriate hyperparameter set
			(assign_to_entities (assoc !hyperparameterMetadataMap (set !hyperparameterMetadataMap (get baseline_hyperparameter_map "paramPath") baseline_hyperparameter_map)) )
		)
		(accum_to_entities (assoc !revision 1))
	)

	;updates baseline_hyperparameter_map
	;uses provided baseline_hyperparameter_map to compute the model MAE (!gridSerachError), if computed error is less than current/y stored error,
	;updates baseline_hyperparameter_map with the new error value, otherwise reverts it back to previous_analyzed_hp_map
	#!TestAccuracyAndKeepOrRevertHyperparameters
	(seq
		;re-set the defined random seed to run gridsearch the same way as it was run above
		(set_rand_seed sampling_random_seed)

		;run through one pass using feature weights to see if they should be used
		(assign (assoc
			model_mae (call !ComputeModelResidualForParameters (assoc targetless (= targeted_model "targetless")))
		))

		;if previous pass did better than this pass, revert baseline_hyperparameter_map
		(if (>= model_mae (get baseline_hyperparameter_map "gridSearchError"))
			(assign (assoc baseline_hyperparameter_map previous_analyzed_hp_map))

			;else keep update current hyperparams with new error value and back them up
			(seq
				(assign (assoc
					baseline_hyperparameter_map (set baseline_hyperparameter_map "gridSearchError" model_mae)
				))
				(assign (assoc previous_analyzed_hp_map baseline_hyperparameter_map))
			)
		)
	)

	;use rewrite to update all hyperparameters sets with the new featureDomainAttributes
	#!UpdateHyperparametersWithFeatureDomainAttributes
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(seq
						;hp already have featureDomainAttributes defined, overwrite the counts and bounds
						(if (!= (null) (get (current_value) "featureDomainAttributes"))
							(let
								(assoc previous_hp_feature_limits_map (get (current_value 1) "featureDomainAttributes") )

								;smartly overwrite previous values with the newly computed ones
								(assign (assoc
									feature_limits_map
										(map
											(lambda (let
												(assoc
													previous_value (first (current_value 1))
													new_value (last (current_value 1))
												)

												;if both are null, keep them as null
												(if (= (null) previous_value new_value)
													(null)

													;if either value is missing from either map, keep whichever isn't null
													(or (= (null) previous_value) (= (null) new_value) )
													(or previous_value new_value)

													;else overwrite the value with the new one
													new_value
												)
											))
											previous_hp_feature_limits_map
											feature_limits_map
										)
								))
							)
						)

						;append the updated feature_limits_map to this hp map
						(append (current_value) (assoc "featureDomainAttributes" feature_limits_map) )
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update all deviations in hyperparemeters with user specified errors
	#!UpdateHyperparametersWithUserErrors
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			;if this is a hp assoc, modify it
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					;hp already have featureDeviations defined, overwrite where necessary
					(if (!= (null) (get (current_value) "featureDeviations"))
						(let
							(assoc deviations_map (get (current_value 1) "featureDeviations") )

							(map
								(lambda (let
									(assoc
										deviation (get deviations_map (current_index 1))
										user_error_value (current_value 1)
										feature (current_index 1)
									)

									(declare (assoc
										deviation_value
											;set to max of user specified error and stored deviation in the map
											(if (!= (null) deviation)
												;if deviation is a tuple, update the first value
												(if (= (list) (get_type deviation))
													(set deviation 0 (max user_error_value (first deviation)) )
													;else just update the value itself
													(max user_error_value deviation)
												)
											)
									))

									;if deviation is null, that means we aren't using deviations so keep it as a null
									(if (!= (null) deviation_value)
										(assign (assoc
											deviations_map (set deviations_map feature deviation_value)
										))
									)
								))
								!userSpecifiedFeatureErrorsMap
							)

							;append the updated deviations_map to this hp map
							(append (current_value) (assoc "featureDeviations" deviations_map) )
						)

						(current_value)
					)

					(current_value)
				)
			)
			hp_map
		)
	)

	;update hyperparameter map for newly added feature
	; hp_map: the hp map to be updated, should be either !defaultHyperparameters or !hyperparameterMetadataMap
	#!UpdateHyperparametersWithNewFeature
	(declare
		(assoc hp_map (assoc) )

		(rewrite
			(lambda
				(if (and (= (assoc) (get_type (current_value))) (contains_index (current_value) "k") )
					(let
						(assoc
							feature_weights_map (get (current_value 1) "featureWeights")
							feature_deviations_map (get (current_value 1) "featureDeviations")
						)

						(if (!= (null) feature_weights_map)
							(assign (assoc feature_weights_map (append feature_weights_map (associate feature 1)) ))

							;else no weights, assign all active features weight 1
							(assign (assoc
								feature_weights_map
									(append
										(zip (append !trainedFeatures feature) 1)
										;prevent appending null to an assoc
										(if !inactiveFeaturesMap !inactiveFeaturesMap (assoc))
									)
							))
						)

						(if (!= (null) feature_deviations_map)
							(assign (assoc feature_deviations_map (set feature_deviations_map feature min_deviation_value) ))
						)

						(append (current_value) (assoc
							"featureWeights" feature_weights_map
							"featureDeviations" feature_deviations_map
						))
					)

					;else return
					(current_value)
				)
			)
			hp_map
		)
	)


	#!GetHyperparameters
	(declare
		(assoc
			mode "robust"
			weight_feature ".none"
		)

		(if (= 0 (size !hyperparameterParamPaths))
			(seq
				(if (and (not !autoAnalyzeEnabled ) (>= (call !GetNumTrainingCases) 2))
					(accum (assoc
						warnings
							(associate (concat
								"There are no cached hyperparameters in this trainee. "
								"This operation was executed using a set of predefined default hyperparameters. "
								"Please run analyze() with your desired parameters."
							))
					))
				)
				;if no params, use defaults
				(conclude !defaultHyperparameters)
			)

			(= 1 (size !hyperparameterParamPaths))
			;if only one set of analyzed params, return them
			(conclude (get !hyperparameterMetadataMap (first !hyperparameterParamPaths)))
		)

		;there are multiple sets of analyze params, we must determine the best
		(declare (assoc
			context_key
				(if (or (= context_features (null)) (= context_features (list)))
					!trainedFeaturesContextKey

					;else context_features were passed
					(call !BuildContextFeaturesKey (assoc context_features context_features))
				)
		))


		;determine value for feature
		(if (or (= (null) feature) (not (contains_index !hyperparameterMetadataMap feature)))
			(assign (assoc
				feature
					(if (contains_index !hyperparameterMetadataMap ".targetless")
						".targetless"

						;else just use one of the targeted analyzed hyperparam sets
						(first (indices !hyperparameterMetadataMap))
					)
			))
		)

		;if we have completely correct HPs, return them
		(if (contains_index !hyperparameterMetadataMap (list feature context_key mode weight_feature))
			(conclude (get !hyperparameterMetadataMap (list feature context_key mode weight_feature)) )

			(declare (assoc other_mode (if (= mode "robust") "full" "robust") ))
		)

		;if we have the correct HPs, with the alternate mode, return them
		(if (contains_index !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))
			(conclude (get !hyperparameterMetadataMap (list feature context_key other_mode weight_feature)) )
		)

		;we don't have the exact HPs, determine best context_key
		(let
			(assoc
				;sort context keys in order of increasing length
				context_key_options
					(sort
						(lambda (> (size (current_value)) (size (current_value 1))))
						(indices (get !hyperparameterMetadataMap feature) )
					)

				correct_mode (false)
				correct_weight (false)
				iterator 0
			)

			;naively set the context to the longest option
			(assign (assoc context_key (last context_key_options) ))


			(while (< iterator (size context_key_options))
				(assign (assoc candidate_context_key (get context_key_options iterator) ))

				(if (contains_index !hyperparameterMetadataMap (list feature candidate_context_key mode weight_feature))
					;correct mode and weight
					(assign (assoc
						context_key candidate_context_key
						iterator (size context_key_options)
						correct_mode (true)
						correct_weight (true)
					))

					(contains_index !hyperparameterMetadataMap (list feature candidate_context_key other_mode weight_feature))
					;incorrect mode, correct weight
					(if (not correct_weight)
						(assign (assoc
							context_key candidate_context_key
							correct_mode (true)
							correct_weight (false)
						))
					)

					(contains_index !hyperparameterMetadataMap (list feature candidate_context_key mode ".none"))
					;correct mode, default weight
					(if (and (not correct_mode) (not correct_weight))
						(assign (assoc
							context_key candidate_context_key
							correct_mode (true)
							correct_weight (false)
						))
					)
				)

				(accum (assoc iterator 1 ))
			)
		)

		;if we have the correct mode and weight for the action and context, return it
		(if (contains_index !hyperparameterMetadataMap (list feature context_key mode weight_feature))
			(get !hyperparameterMetadataMap (list feature context_key mode weight_feature))

			;if we have the correct weight for the action and context, return it
			(contains_index !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))
			(get !hyperparameterMetadataMap (list feature context_key other_mode weight_feature))

			;only correct mode, no case weight
			(contains_index !hyperparameterMetadataMap (list feature context_key mode ".none"))
			(get !hyperparameterMetadataMap (list feature context_key mode ".none"))

			;in correct mode, no case weight, just feature is right basically
			(contains_index !hyperparameterMetadataMap (list feature context_key other_mode ".none"))
			(get !hyperparameterMetadataMap (list feature context_key other_mode ".none"))

			;else the case_weight and ".none" isn't in the map, return the default params
			!defaultHyperparameters
		)
	)

	;builds a string key based on context feature list
	#!BuildContextFeaturesKey
	(apply "concat" (weave (sort context_features) "."))


	;return the full internal parameters map if no parameters are specified.
	;if any of the parameters are specified, then GetHyperparameters is called, which uses the specified parameters to find the most suitable set of hyperparameters to return
	;{read_only (true) idempotent (true)}
	#get_params
	(declare
		;returns {
		; 	type "assoc"
		;	additional_indices (false)
		; 	indices {
		; 		"hyperparameter_map" {any_of [{ref "HyperparameterMap"} {ref "HyperparameterMapTree"}] description "The full map of hyperparameters or a specific map of hyperparameters if any parameters were given"}
		; 		"default_hyperparameter_map" {ref "HyperparameterMap" description "The map of default hyperparameters"}
		; 		"auto_analyze_enabled" {type "boolean" description "Flag indicating of auto-analysis is enabled."}
		; 		"analyze_threshold" {type "number" description "The number of cases at which the auto-analysis is triggered."}
		; 		"analyze_growth_factor" {type "number" description "The scalar rate at which the number of cases to trigger an auto-analysis grows with each iteration"}
		; 	}
		; }
		(assoc
			;{type "string"}
			;the target feature of the desired hyperparameters
			action_feature (null)
			;{type "list" values "string"}
			;the set of context features used for the desired hyperparameters
			context_features (null)
			;{type "string" enum ["robust" "full"]}
			;the method of calculation used to find the desired hyperparameters
			mode (null)
			;{type "string"}
			;the weight feature used in the calculation of the desired hyperparameters
			weight_feature (null)
		)
		(call !ValidateParameters)

		(declare (assoc
			internal_parameters_map
				(assoc
					"hyperparameter_map"
						(if (= (null) action_feature context_features mode weight_feature)
							!hyperparameterMetadataMap

							;else one of these parameters were specified
							(call !GetHyperparameters
								(append
									(assoc
										feature action_feature
										context_features context_features
									)
									;don't pass mode or weight_feature in if they weren't specified,
									;allowing GetHyperparameters to use its defaults
									(if mode (assoc mode mode) (assoc))
									(if weight_feature (assoc weight_feature weight_feature) (assoc))
								)
							)
						)

					"default_hyperparameter_map" !defaultHyperparameters
				)
		))

		(if !autoAnalyzeEnabled
			(accum (assoc
				internal_parameters_map
					(assoc
						"auto_analyze_enabled" !autoAnalyzeEnabled
						"analyze_threshold" !autoAnalyzeThreshold
						"analyze_growth_factor" !autoAnalyzeGrowthFactorAmount
					)
			))
		)

		(call !Return (assoc payload internal_parameters_map))
	)

	;sets internal hyperparameters
	;{idempotent (true)}
	#set_params
	(declare
		(assoc
			;{ref "HyperparameterMapTree"}
			;must have at least an action feature (e.g., .targetless) -> a contexts key -> robust -> k, p and dt provided.
			;	example:
			;   {
			;	  	".targetless" { "featureA.featureB.": { "robust" : { "k" : number, "p" : number, "dt": number }}},
			;		"featureA" : { "featureB.featureC.": { "full" : { "k" : number, "p" : number, "dt": number }}},
			;			...
			;	}
			hyperparameter_map (null)
			;{ref "HyperparameterMap"}
			;an assoc of hyperparameters to use when no others are available must contain k, p, and dt.
			default_hyperparameter_map (null)
			;{type "boolean"}
			;flag, default is false. when true, returns when it's time for model to be analyzed again.
			auto_analyze_enabled (false)
			;{type "number"}
			;stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
			analyze_threshold 100
			;{type "number"}
			;the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
			;	default of two orders of magnitude using the universal scaling factor e
			analyze_growth_factor 7.389056
		)
		(call !ValidateParameters)

		(declare (assoc
			;local var
			bad_param (false)
		))

		(if (!= (null) default_hyperparameter_map)
			(if (or
					(not (contains_index default_hyperparameter_map "p"))
					(not (contains_index default_hyperparameter_map "k"))
					(not (contains_index default_hyperparameter_map "dt"))
				)
				(assign (assoc bad_param (true) ))

				(seq
					(accum (assoc default_hyperparameter_map (assoc "paramPath" (list ".default")) ))
					(assign_to_entities (assoc !defaultHyperparameters default_hyperparameter_map) )
				)
			)
		)

		;the passed in hyperparameters must at least have the basic attributes defined correctly
		;iterate over action features
		(if (!= (null) hyperparameter_map)
			(let
				(assoc param_paths (list))
				(map
					(lambda (if
						(= 0 (size (current_value)))
						(assign (assoc bad_param (true)))
						;else iterate over context feature keys
						(map
							(lambda (if
								(= 0 (size (current_value)))
								(assign (assoc bad_param (true)))
								;else iterate over robust / full
								(map
									(lambda (if
										(= 0 (size (current_value)))
										(assign (assoc bad_param (true)))
										;else iterate over case weights
										(map
											(lambda
												(if (or
														(not (contains_index (current_value) "p"))
														(not (contains_index (current_value) "k"))
														(not (contains_index (current_value) "dt"))
													)
													(assign (assoc bad_param (true)))

													;else this HP assoc is good enough
													(assign (assoc param_paths (append param_paths (list (list (current_index 6) (current_index 5) (current_index 4) (current_index 3))) ) ))
												)
											)
											(current_value)
										)
									))
									(current_value)
								)
							))
							(current_value)
						)
					))
					hyperparameter_map
				)
				(if (not bad_param)
					(assign_to_entities (assoc
						!hyperparameterMetadataMap hyperparameter_map
						!hyperparameterParamPaths param_paths
					))
				)
			)
		)

		;return failure, invalid hyperparameter_map passed in
		(if bad_param (conclude
			(call !Return (assoc
				errors (list "Failed to set parameters: invalid parameters specified.")
			))
		))

		(assign_to_entities (assoc
			!autoAnalyzeEnabled auto_analyze_enabled
			!autoAnalyzeThreshold analyze_threshold
			!autoAnalyzeGrowthFactorAmount analyze_growth_factor
		))

		(accum_to_entities (assoc !revision 1))

		(call !Return)
	)

	;resets all hyperparameters and thresholds back to original values, while leaving feature definitions alone
	;{idempotent (true)}
	#reset_params
	(seq
		(assign_to_entities (assoc
			!numericalPrecision (null)
			!defaultNumSamples 100
			!hyperparameterMetadataMap (assoc)
			!defaultHyperparameters
				(assoc
					"k" 8
					"p" 0.1
					"dt" -1
					"featureWeights" (null)
					"featureDeviations" (null)
				)
		))
		(accum_to_entities (assoc !revision 1))
		(call !Return)
	)

	;sets the model to auto-analyze by tracking its size and notifying the clients in train responses when it should be analyzed
	;{idempotent (true)}
	#set_auto_analyze_params
	(declare
		(assoc
			;{type "boolean"}
			;flag, default is false. when true, returns when it's time for model to be analyzed again.
			auto_analyze_enabled (false)
			;{type "number"}
			;stores the threshold for the number of cases at which the model should be re-analyzed. default of 100.
			analyze_threshold 100
			;{type "number" exclusive_min 1.0}
			;the factor by which to increase the analyze threshold everytime the model grows to the current threshold size
			;	default of two orders of magnitude using the universal scaling factor e
			analyze_growth_factor 7.389056
			;parameter for analyze
			;{type "list" values "string"}
			context_features (null)
			;{type "list" values "string"}
			action_features (null)
			;{type "number" min 1}
			;number of cross validation folds to do. value of 1 does hold-one-out instead of k-fold
			k_folds 1
			;{type "boolean"}
			;flag, if true will not do any search over k, p, and dt parameters, but still may compute feature residuals
			; depending on other parameters.
			bypass_hyperparameter_analysis (false)
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature residuals
			bypass_calculate_feature_residuals (false)
			;{type "boolean"}
			;flag, if set to true will skip the computation of feature weights
			bypass_calculate_feature_weights (false)
			;{type ["boolean" "null"]}
			;whether to use deviations for LK metric in queries. When true forces the use
			;	of deviations, when false will not use deviations. If unspecified, the better performing option will be selected.
			use_deviations (null)
			;{type "number" min 2}
			;number of cases to use to approximate residuals
			num_samples (null)
			;{type "number" min 2}
			;number of cases to sample during analysis. only applies for k_folds = 1
			num_analysis_samples (null)
			;{type "number" min 2}
			;number of samples to use for analysis. the rest will be randomly held-out and not included in calculations
			analysis_sub_model_size (null)
			;{type "list" values "number"}
			;list of values for k (the number of cases making up a local model) to grid search during analysis
			k_values (null)
			;{type "list" values "number"}
			;list of values for p (the parameter of the Lebesgue space) to grid search during analysis
			p_values (null)
			;{type "list" values ["number" "string"]}
			;list of values for dt (the distance transform) to grid search during analysis
			dt_values (null)
			;{type "string" enum ["single_targeted" "omni_targeted" "targetless"]}
			;enumeration, default is "single_targeted"
			;   "single_targeted" = analyze hyperparameters for the specified action_features
			;   "omni_targeted" = analyze hyperparameters for each action feature, using all other features as context_features. if action_features aren't specified, uses all context_features.
			;   "targetless" = analyze hyperparameters for all context features as possible action features, ignores action_features parameter
			targeted_model (null)
			;{type "string"}
			;name of feature whose values to use as case weights
			weight_feature ".case_weight"
			;{ref "UseCaseWeights"}
			;when true will scale influence weights by each case's weight_feature weight. if use_case_weights isn't specified, it will
			;	be true if auto ablation is enabled and false otherwise
			use_case_weights (null)
			;{type ["boolean" "null"]}
			;whether to use inverse residuals as feature weights. If unspecified, inverse residuals will be used as weights for
			; targetless params, otherwise this method will not be used.
			inverse_residuals_as_weights (null)
		)
		(call !ValidateParameters)

		(if (and
				(size action_features)
				(= (size context_features) 0)
			)
			(conclude
				(call !Return (assoc
					errors ["`context_features` must be specified when `action_features` is specified."]
				))
			)
		)

		(declare (assoc num_cases (call !GetNumTrainingCases) ))

		;if the model is already larger than the specified analyze_threshold, set the analyze_threshold to a valid value nearest the current
		;number of cases in the model without going over
		(if
			(and
				(!= (null) analyze_threshold)
				(> num_cases analyze_threshold)
			)
			(seq
				;keep increasing the analysis_threshold by the growth_factor_amount until it's bigger than the current number of cases
				;and then decrease it back down so that it's just below
				(while (> num_cases analyze_threshold)
					(assign (assoc analyze_threshold (* analyze_threshold analyze_growth_factor)))
				)

				(assign (assoc analyze_threshold (/ analyze_threshold analyze_growth_factor )))
			)
		)

		(accum_to_entities (assoc !revision 1))

		(assign_to_entities (assoc
			!autoAnalyzeEnabled auto_analyze_enabled
			!autoAnalyzeThreshold analyze_threshold
			!autoAnalyzeGrowthFactorAmount analyze_growth_factor
		))

		(if (!= (null) context_features)
			(assign_to_entities (assoc
				!savedAnalyzeParameterMap
					(assoc
						"context_features" context_features
						"action_features" action_features
						"k_folds" k_folds
						"bypass_hyperparameter_analysis" bypass_hyperparameter_analysis
						"bypass_calculate_feature_residuals" bypass_calculate_feature_residuals
						"bypass_calculate_feature_weights" bypass_calculate_feature_weights
						"use_deviations"  use_deviations
						"num_samples" num_samples
						"k_values" k_values
						"p_values" p_values
						"dt_values" dt_values
						"targeted_model" targeted_model
						"num_analysis_samples" num_analysis_samples
						"analysis_sub_model_size" analysis_sub_model_size
						"inverse_residuals_as_weights" inverse_residuals_as_weights
						"weight_feature" weight_feature
						"use_case_weights" use_case_weights
					)
			))
		)

		(call !Return)
	)

	;get auto-ablation parameters set by #set_auto_ablation_params
	;{read_only (true) idempotent (true)}
	#get_auto_ablation_params
	(declare
		;returns {ref "GetAutoAblationParamsResponse"}
		(assoc)


		(call !Return (assoc
			payload
				(assoc
					auto_ablation_enabled !autoAblationEnabled
					auto_ablation_weight_feature !autoAblationWeightFeature
					minimum_num_cases !autoAblationMinNumCases
					influence_weight_entropy_threshold !autoAblationInfluenceWeightEntropyThreshold
					abs_threshold_map !autoAblationAbsThresholdMap
					delta_threshold_map !autoAblationDeltaThresholdMap
					rel_threshold_map !autoAblationRelThresholdMap
					exact_prediction_features !autoAblationExactPredictionFeatures
					tolerance_prediction_threshold_map !autoAblationTolerancePredictionThresholdMap
					relative_prediction_threshold_map !autoAblationRelativePredictionThresholdMap
					residual_prediction_features !autoAblationResidualPredictionFeatures
					conviction_upper_threshold !autoAblationConvictionUpperThreshold
					conviction_lower_threshold !autoAblationConvictionLowerThreshold
				)
		))
	)

	;sets the model to auto-ablate by tracking its size and training certain cases as weights
	;{idempotent (true)}
	#set_auto_ablation_params
	(declare
		(assoc
			;{type "boolean"}
			;flag, default is false. when true, any enabled ablation techniques will be run at during training.
			auto_ablation_enabled (false)
			;{type "string"}
			;the weight feature that should be used when ablating.
			auto_ablation_weight_feature ".case_weight"
			;{type "number"}
			;stores the threshold for the minimum number of cases at which the model should auto-ablate.
			;	default of 1000.
			minimum_num_cases 1000
			;{type "number"}
			;the influence weight entropy quantile that a case must be beneath in order to be trained.
			;	default of 0.6.
			influence_weight_entropy_threshold 0.15
			;{type "list" values "string"}
			;list of features. for each of the features specified, will ablate a case if the prediction
			;	matches exactly.
			exact_prediction_features (null)
			;{type "assoc" additional_indices {type "list" min_size 2 max_size 2}}
			;assoc of feature -> [MIN, MAX]. for each of the features specified, will
			;	ablate a case if the prediction >= (case value - MIN) and the prediction <= (case value + MAX)
			tolerance_prediction_threshold_map (null)
			;{type "assoc" additional_indices "number"}
			;assoc of feature -> PERCENT. for each of the features specified, will
			;	ablate a case if abs(prediction - case value) / prediction <= PERCENT
			relative_prediction_threshold_map (null)
			;{type "list" values "string"}
			;list of features. for each of the features specified, will ablate a case if
			;	abs(prediction - case value) <= feature residual
			residual_prediction_features (null)
			;{type "number"}
			;the conviction value below which cases will be ablated
			conviction_upper_threshold (null)
			;{type "number"}
			;the conviction value above which cases will be ablated
			conviction_lower_threshold (null)
			;{type "number" min 1}
			;the number of cases to ablate between analyses and influence weight entropy recalculation
			batch_size 2000
			;{type "number"}
			;the number of ablated cases to compute influence weights for distribution at a time
			ablated_cases_distribution_batch_size 100
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; absolute thresholds will cause ablation to stop when any of the measure values for any of
			; the features for which a threshold is defined go above the threshold (in the case of rmse and
			; mae) or below the threshold (otherwise).
			abs_threshold_map (assoc)
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; delta thresholds will cause ablation to stop when the delta between any of the measure values
			; for any of the features for which a threshold is defined and its previous value go above the threshold
			; (in the case of rmse and mae) or below the threshold (otherwise).
			delta_threshold_map (assoc)
			;{ref "AblationThresholdMap"}
			;a map of measure names (any of the prediction stats) to a map of feature names to threshold value.
			; relative thresholds will cause ablation to stop when the relative change between any of the
			; measure values for any of the features for which a threshold is defined and its previous value go
			; above the threshold (in the case of rmse and mae) or below the threshold (otherwise).
			rel_threshold_map (assoc)
		)
		(call !ValidateParameters)

		(if
			(or (< influence_weight_entropy_threshold 0) (> influence_weight_entropy_threshold 1))
			(assign (assoc auto_ablation_entropy_threshold_quantile 1.0))
		)

		(accum_to_entities (assoc !revision 1))

		(assign_to_entities (assoc
			!autoAblationEnabled auto_ablation_enabled
			!autoAblationWeightFeature auto_ablation_weight_feature
			!autoAblationMinNumCases minimum_num_cases
			!autoAblationInfluenceWeightEntropyThreshold influence_weight_entropy_threshold
			!autoAblationExactPredictionFeatures exact_prediction_features
			!autoAblationTolerancePredictionThresholdMap tolerance_prediction_threshold_map
			!autoAblationRelativePredictionThresholdMap relative_prediction_threshold_map
			!autoAblationResidualPredictionFeatures residual_prediction_features
			!autoAblationConvictionUpperThreshold conviction_upper_threshold
			!autoAblationConvictionLowerThreshold conviction_lower_threshold
			!autoAblationAbsThresholdMap abs_threshold_map
			!autoAblationDeltaThresholdMap delta_threshold_map
			!autoAblationRelThresholdMap rel_threshold_map
			!ablationBatchSize batch_size
			!ablatedCasesDistributionBatchSize ablated_cases_distribution_batch_size
		))

		(call !Return)
	)

	;Convert confusion matrix (assoc class -> (assoc of class -> counts)) to sparse deviation matrix (SDM):
	;with the possible formats:
	; an assoc of assocs: (assoc of class -> (assoc of class -> deviation))
	;if there's a default_class_deviation, the deviation value to be used for any classes that didn't have any counts:
	; each row will be an assoc of list (pair) of: assoc and value:
	;  (assoc of class -> (list of: (assoc of class -> deviation), default_class_deviation))
	;
	;The SDM is output as a tuple (pair) in the format of: [ SDM unknown_class_deviation ]
	;where unknown_class_deviation is the deviation value to be used for any class that isn't defined in the SDM
	;
	;returns null if the the passed in confusion matrix does not have enough counts to be statistically significant.
	;
	;parameters:
	; confusion_matrix:  assoc of class -> assoc of class -> predicted count for each class.
	; feature: name of nominal feature
	; confusion_matrix_min_count: number of predictions a class should have for it to have an explicit deviation value.
	;	If the count is less than this value, the deviation will be in the combined deviation for the class. default value is 10
	; expected_deviation: value of expected deviation if sdm is not being referenced
	#!ConfusionMatrixToSDM
	(declare
		(assoc
			confusion_matrix (assoc)
			confusion_matrix_min_count 15
			expected_deviation (null)
		)

		(declare (assoc
			total_predictions
				(apply "+" (values
					(map
						(lambda (or (apply "+" (values (current_value))) 0) )
						confusion_matrix
					)
				))
		))

		;output null if the total count is too small
		(if (< total_predictions confusion_matrix_min_count)
			(conclude (null))
		)

		(declare (assoc
			;Using n+1, n+2, or n+.5 are all possible considerations of Laplacian smoothing to apply a Bayesian approach for
			;estimating the probability of having no incorrect predictions.  We chose .5 assuming the Jeffreys prior approach.
			smallest_prob (/ 1 (+ 0.5 total_predictions))
			;max accuracy is 1 - smallest_probability
			max_accuracy (- 1 (/ 1 (+ 0.5 total_predictions)))
			predictions_per_class_map
				(map
					(lambda (apply "+" (values (current_value))) )
					confusion_matrix
				)
			leftover_confusion_matrix (assoc)
			leftover_unknown_class_deviation (null)
			valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")) )
		))

		(declare (assoc
			;map of class -> accuracy of random guessing
			rand_guess_accuracy_map (map (lambda (/ (current_value) total_predictions)) predictions_per_class_map)
		))

		;filter out counts below threshold in confusion matrix and store as probabilities correct instead of counts
		;leaving only those predicted classes that had enough predictions
		(call !ConvertAndReduceConfusionMatrix)

		(if (= 0 (size confusion_matrix))
			(conclude (null))
		)

		(declare (assoc num_classes (size (get !expectedValuesMap [weight_feature feature "class_counts"])) ))
		(if (= 0 num_classes)
			(assign (assoc
				num_classes
					(size
						(compute_on_contained_entities (list
							(query_value_masses
								feature
								(if valid_weight_feature weight_feature)
								(or
									(not (contains_index !nominalsMap feature))
									(contains_index !numericNominalFeaturesMap feature)
								)
							)
						))
					)
			))
		)

		;average all probabilities for a class that are same as or more than the predicted class probability
		(declare (assoc
			prob_match_or_indistinguishable_map
				(map
					(lambda (let
						(assoc predicted_class_prob (+ (or (get (current_value 1) (current_index 1)))) )
						(declare (assoc
							avg_probs_same_or_larger_than_predicted
								(filter
									(lambda (>= (current_value) predicted_class_prob))
									(values (current_value 1))
								)
						))
						;if nothing is filtered out, average across all classes
						(if (= 0 predicted_class_prob)
							(/ (apply "+" avg_probs_same_or_larger_than_predicted) num_classes)

							(/ (apply "+" avg_probs_same_or_larger_than_predicted) (size avg_probs_same_or_larger_than_predicted))
						)
					))
					confusion_matrix
				)
		))

		;indistinguishable accuracy matrix
		;Clamps predicted probabilities to random guesses
		(declare (assoc guessing_accuracy_matrix (call !ClampSDMProbabilities) ))

		;compute the full deviation matrix
		(declare (assoc
			deviation_matrix
				(map
					(lambda (let
						(assoc
							;probability of correct predicted class
							class_probability (get (current_value 1) (current_index 1))
							num_sparsified_values (- num_classes (size (current_value 1)))
						)

						;total probability of the row
						(declare (assoc
							total_probability
								;sum all the probabilities in the row
								;add the number of smallest_prob values equal to the number of sparsified values
								(if num_sparsified_values
									(+
										(apply "+" (values (current_value 1)) )
										(* num_sparsified_values smallest_prob)
									)

									;else sum up all the probabilities in the row as-is
									(apply "+" (values (current_value 1)) )
								)
						))

						;normalize each prediction probability by iterating over all the predictions
						;in the row and dividing by total_probability
						(map
							(lambda
								(max
									(- 1 (/ (min class_probability (current_value)) total_probability))
									smallest_prob
								)
							)
							(current_value)
						)
					))
					guessing_accuracy_matrix
				)
		))

		;store default class (row) deviations for any classes that are not in each row
		(declare (assoc
			leftover_class_deviation_map
				(filter (map
					(lambda (let
						(assoc
							num_sparsified_values (- num_classes (size (current_value 1)))
						)

						(if num_sparsified_values
							(- 1 (/
								smallest_prob
								;sum all the probabilities in the row
								;add the number of smallest_prob values equal to the number of sparsified values
								(+
									(apply "+" (values (current_value)) )
									(* num_sparsified_values smallest_prob)
								)

							))
						)
					))
					guessing_accuracy_matrix
				))
		))

		;SDM is always output as a tuple of: [matrix unknown_class_deviation]
		(list
			(call !FormatSDMForOutput)
			(if leftover_unknown_class_deviation
				;if there's a leftover_unknown_class_deviation, output the SDM as a list (pair)
				leftover_unknown_class_deviation

				;if there is only one class trained, set the unknown deviation to be max possible value
				(= [1] (values rand_guess_accuracy_map))
				max_accuracy

				;else just output the expected deviation
				expected_deviation
			)
		)
	)

	;Edits deviation_matrix for output by filtering out deviations that correspond to counts that aren't in the sparse confusion matrix
	;and return tuples with the default class deviation for classes that have those computed
	#!FormatSDMForOutput
	(map
		(lambda
			;if there is a default deviation for the class, output a tuple of [sparse deviation map, default class deviation]
			(if (contains_index leftover_class_deviation_map (current_index))
				[
					(current_value 1)
					(get leftover_class_deviation_map (current_index 1))
				]

				;just output the sdm assoc
				(current_value)
			)
		)
		deviation_matrix
	)

	;computes the "leftover" confusion matrix of class counts that did not have statistical significance
	;and stores it into leftover_confusion_matrix
	#!ComputeLeftoverConfusionMatrix
	(seq
		(assign (assoc
			leftover_confusion_matrix
				;remove classes with empty rows by leaving only those with non-empty rows
				(filter (lambda (size (current_value)))
					;iterate over rows of confusion matrix
					(map
						(lambda (let
							(assoc
								predicted_class (current_index 1)
								row_map (current_value 1)
							)
							;leave entire row if predicted class doesn't have enough samples
							(if
								(or
									(= (null) (get row_map predicted_class))
									(< (get row_map predicted_class) confusion_matrix_min_count)
								)
								row_map

								;else only leave those classes that have counts but not enough samples
								(filter
									(lambda
										(and
											(< (current_value) confusion_matrix_min_count)
											(!= 0 (current_value))
										)
									)
									row_map
								)
							)
						))
						confusion_matrix
					)
				)
		))
	)

	;Helper method for computing SDM, called by ConfusionMatrixToSDM, filters out counts below threshold and stores as probabilities correct instead.
	;leaves only those predicted classes that had enough predictions.
	;Also computes the fallback residuals if there are any counts that didn't have enough statistical significance.
	#!ConvertAndReduceConfusionMatrix
	(seq
		(call !ComputeLeftoverConfusionMatrix)

		(declare (assoc
			total_leftover_correct_predictions
				(apply "+" (values
					(map (lambda (+ (or (get (current_value) (current_index))))) leftover_confusion_matrix)
				))
			total_leftover_all_predictions
				(apply "+" (values
					(map
						(lambda (apply "+" (values (current_value))))
						leftover_confusion_matrix
					)
				))
		))

		(assign (assoc
			confusion_matrix
				;current_index is the class being predicted
				;current_value is an assoc of class -> number predictions
				(map
					(lambda (let
						(assoc
							total_class_predictions (apply "+" (values (current_value 1)))
							predicted_class (current_index 1)
						)
						;convert counts to percent accuracy by dividing each count by total_class_predictions
						;filter out any entries where there weren't enough counts
						(filter (map
							(lambda
								(if (>= (current_value) confusion_matrix_min_count)
									(/ (current_value) total_class_predictions)

									;if the predicted class (diagonal) doesn't have enough, represent it with a 0 instead of filtering it out
									(= (current_index) predicted_class)
									0
								)
							)
							;ensure the predicted class is represented in the row even if it has no counts
							;since the values on the diagonal should all be present
							(if (contains_index (current_value) predicted_class)
								(replace (current_value))
								(append (replace (current_value)) (associate predicted_class 0))
							)
						))
					))
					confusion_matrix
				)
		))

		(declare (assoc
			weighted_accuracy_map
				;weighted accuracy for each class is its predicted probability * random guess accuracy
				(map
					(lambda (let
						(assoc predicted_class_prob (get (current_value 1) (current_index 1)))
						(* predicted_class_prob (get rand_guess_accuracy_map (current_index)) )
					))
					confusion_matrix
				)
		))
		(declare (assoc avg_random_accuracy (apply "+" (values weighted_accuracy_map)) ))

		(assign (assoc
			leftover_unknown_class_deviation
				;fallback #1, if there are enough leftover predictions, deviation is 1 - correct leftovers / total leftovers
				(if (>= total_leftover_correct_predictions confusion_matrix_min_count)
					(- 1 (/ total_leftover_correct_predictions total_leftover_all_predictions) )

					;else if there aren't enough leftover counts to compute unknown class deviation, use weighted random chance
					(> total_leftover_all_predictions total_leftover_correct_predictions)
					(let
						(assoc all_classes_map (get !expectedValuesMap [weight_feature feature "class_counts"]) )
						(if (= 0 (size all_classes_map))
							(assign (assoc
								all_classes_map
									(compute_on_contained_entities (list
										(query_value_masses
											feature
											(if valid_weight_feature weight_feature)
											(or
												(not (contains_index !nominalsMap feature))
												(contains_index !numericNominalFeaturesMap feature)
											)
										)
									))
							))
						)

						(declare (assoc
							non_sdm_classes (indices (remove all_classes_map (indices confusion_matrix)) )
						))
						;fallback #2, if there are classes in the dataset that weren't in the sdm, use random guess probability of those classes
						(if (size non_sdm_classes)
							(let
								(assoc total_count (apply "+" (values all_classes_map)) )

								;rand guess prob of classes not in sdm : 1 - sum of prob^2
								(- 1
									(apply "+"
										(map
											(lambda
												(pow
													(/ (get all_classes_map (current_value)) total_count)
													2
												)
											)
											non_sdm_classes
										)
									)
								)
							)

							;else fallback #3, use the average weighted random guess accuracy from the confusion matrix
							;deviation = 1 - average accuracy
							(- 1 avg_random_accuracy)
						)
					)

					;else value remains as null if there are no leftover counts
					(null)
				)
		))

		;ensure unknown class deviation isn't 0 by setting the floor to be the smallest possible probability
		(if (!= (null) leftover_unknown_class_deviation)
			(assign (assoc
				leftover_unknown_class_deviation (max smallest_prob leftover_unknown_class_deviation)
			))
		)

		;average accuracy of 0 means there are no (or not enough significant) counts for any of the predicted classes
		(if (= 0 avg_random_accuracy)
			(assign (assoc confusion_matrix (assoc) ))
		)
	)

	;helper method for computing SDM that clamps probabilities for the predicted classes to be no worse than random guessing
	#!ClampSDMProbabilities
	(declare
		(assoc
			guessing_accuracy_matrix
				;diagonal values are the probability of the match
				;all other classes are their probability without exceeding the predicted class probability (corresponding diagonal value)
				(map
					(lambda (let
						(assoc
							predicted_class (current_index 1)
							row_map (current_value 1)
						)
						(map
							(lambda
								(if (= predicted_class (current_index))
									(get prob_match_or_indistinguishable_map (current_index))

									;all other classes can't exceed the predicted class's probability
									(min
										(get prob_match_or_indistinguishable_map predicted_class)
										(+ (or (current_value)))
									)
								)
							)
							row_map
						)
					))
					confusion_matrix
				)
		)

		;guessing clamped accuracy
		;limit max accuracy of predicted classes to max of computed probability and random correct guess
		;limit min accuracy of other classes to min of computed probability and random wrong guess
		(map
			(lambda (let
				(assoc
					predicted_class (current_index 1)
					row_map (current_value 1)
				)

				(map
					(lambda
						(if (= predicted_class (current_index))
							(replace (max (get row_map predicted_class) (get rand_guess_accuracy_map predicted_class)))

							;set floor for accuracy using random matching probability
							(min
								(replace (max smallest_prob (current_value)))
								;probability of guessing wrong is 1 - random guess
								(- 1 (get rand_guess_accuracy_map predicted_class) )
							)
						)
					)
					row_map
				)
			))
			guessing_accuracy_matrix
		)
	)


)
