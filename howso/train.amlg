;Contains methods for training (input of data into the trainee).
(null

	;Train the provided cases, filtering out cases that match optionally passed in ablation parameters.
	;{long_running .true use_active_session .true}
	#train
	(declare
		;returns {ref "TrainResponse"}
		(assoc
			;{type "list" values {type "list" min_size 1} min_size 1  required .true}
			;list of cases, ie a list of lists of values.
			cases (null)
			;{type "list" values "string" required .true}
			;the list of features.
			features (null)
			;{type "list" values "string"}
			;list of features to derive in the specified order. If this list is not provided, features with
			;	the 'auto_derive_on_train' feature attribute set to True will be auto-derived. If provided an empty list, will not derive any features.
			;	Any derived_features that are already in the 'features' list will not be derived since their values are being explicitly provided.
			derived_features (null)
			;{type "string"}
			;the session label to record these cases to.  If not specified, refers to this entity's label of same name.
			session (null)
			;{type "string"}
			;name of series to pull features and case values from internal series storage.  If specified, trains on all cases that are
			;	stored in the internal series store for the specified series and session. The trained feature set is the combined features from storage
			;	and the passed in features.  If input_cases is of length one, the value(s) of this case are appended to all cases in the series.
			;	If input_cases is the same length as the series, the value of each case in input_cases is applied in order to each of the cases in the
			;	series.
			series (null)
			;{type "boolean"}
			;flag, if set to true assumes provided categorical (nominal or ordinal) feature values already been substituted.
			input_is_substituted .false
			;{type "boolean"}
			;flag, allows feature names beginning with "." if true, otherwise an error will be given if any features start with ".".
			allow_training_reserved_features .false
			;{type "string"}
			;name of feature into which to accumulate neighbors' influences as weight for ablated cases. If unspecified, will not accumulate weights.
			accumulate_weight_feature (null)
			;{type "boolean"}
			;flag, if set to true, and accumulate_weight_feature is provided, will not train on the cases, but instead accumulate all of their neighbor weights.
			train_weights_only .false
			;{type "boolean"}
			;flag, if set to true, will not auto_analyze, but will instead return the status "analyze" which indicates that an analyze call is recommended
			skip_auto_analyze .false
			;{type "boolean"}
			;flag, if set to true, will not reduce_data, but will instead return the status "reduce_data" which indicates that a reduce_data call is recommended
			skip_reduce_data .false
			;{type "number" min 0}
			;if specified, then the training indices for this batch of cases will start at this value. This value must be greater than the last trained index of the session.
			start_index (null)
		)

		(call !ValidateParameters)

		;unsure that session is set to some string value
		(if (= (null) session)
			(assign (assoc session "none"))
		)

		(assign (assoc
			accumulate_weight_feature
				(if (and !autoAblationEnabled (= (null) accumulate_weight_feature))
					!autoAblationWeightFeature
					accumulate_weight_feature
				)
		))

		;create the training session if it does not already exist
		(if (not (contains_entity session))
			;overwrite the session variable in case creating a new session without a name
			(assign (assoc
				session
					(first (create_entities session (lambda
						(null
							##.replay_steps (list)
							##.indices_map (assoc)
							;total count of cases trained
							##.trained_instance_count 0
							;total count of cases observed (incl ablated, trained as weights, etc)
							##.total_instance_count 0
							##.next_trained_index 0
							##.metadata (assoc)
						)
					)))
			))
		)

		(declare (assoc
			trained_instance_count (retrieve_from_entity session ".trained_instance_count")
			total_instance_count (retrieve_from_entity session ".total_instance_count")
			series_cases (if (!= (null) series) (get !seriesStore series))
			status_output (null)
			message (null)
			ablated_indices_list (list)
			warnings (assoc)
			;don't bother auto analyzing if not training on enough cases
			run_autoanalyze_check .false
			;possible data mass of dataset if all the specified cases are trained
			new_possible_data_mass 0
		))

		;if a start_index is given, it should be greater than the next index that would be trained for this session (to prevent idx collisions)
		(if (and
				start_index
				(< start_index (retrieve_from_entity session ".next_trained_index"))
			)
			(conclude
				(call !Return (assoc
					errors ["The given value for `start_index` must be greater than the last trained index of the specified session."]
				))
			)
		)

		(declare (assoc
			next_trained_index
				(if start_index
					start_index

					(retrieve_from_entity session ".next_trained_index")
				)
		))

		;parameter and data checks, returns on error
		(call !PreTrainChecks)

		;get time series derived features list, if applicable
		(if (and (= (null) derived_features) (!= (null) !tsTimeFeature) )
			(assign (assoc
				derived_features (get !tsFeaturesMap "ts_derived_features")
			))
		)

		;unsubstitute nominal feature values if necessary
		(if
			(and input_is_substituted !hasSubstituteFeatureValues)
			(assign (assoc
				cases
					(map
						(lambda
							(call !UnsubstituteFeatureValues (assoc
								features features
								feature_values (current_value 1)
							))
						)
						cases
					)
			))
		)

		(declare (assoc encode_features_on_train (retrieve_from_entity "!hasFeaturesNeedEncodingFromInput") ))

		;encode all cases in bulk if either training on accumulated weights only or training from series
		;because series trained cases are alredy encoded.
		(if (and
				encode_features_on_train
				(or (size series_cases) (and train_weights_only accumulate_weight_feature) )
			)
			(assign (assoc
				cases
					(map
						(lambda (let
							(assoc feature_values (current_value 1))
							;implicitly pass in features and feature_values
							(call !ConvertFromInput)
						))
						cases
					)

				;set the flag to false since cases are already encoded above
				encode_features_on_train .false
			))
		)

		;don't train the data, only accumulate weights to neighbors
		(if (and train_weights_only accumulate_weight_feature)
			(let
				(assoc
					rebalance_weights (or !continuousRebalanceFeatures !nominalRebalanceFeatures)
					total_mass (replace !cachedTotalMass)
					total_rebalance_mass (replace !cachedRebalanceTotalMass)
				)

				;if training with weights, ensure all cases have a weight of 1 defined by default
				(assign_to_entities (assoc !hasPopulatedCaseWeight .true ))
				(call !CreateCaseWeights (assoc feature_name accumulate_weight_feature) )

				(call !AccumulateCaseInfluenceWeights (assoc
					features features
					accumulate_weight_feature accumulate_weight_feature
					cases cases
				))

				;capture these cases into the total observed count
				(accum_to_entities session (assoc
					".total_instance_count" (size cases)
				))
				(assign_to_entities session (assoc
					".next_trained_index" (+ next_trained_index (size cases))
				))

				(if rebalance_weights
					(assign_to_entities (assoc
						!cachedTotalMass total_mass
						!cachedRebalanceTotalMass total_rebalance_mass
					))
				)

				(accum_to_entities (assoc !revision 1))

				(conclude
					(call !Return (assoc
						warnings (if (size warnings) (indices warnings))
						payload
							(assoc
								"num_trained" 0
								"ablated_indices" (list)
								"status" status_output
							)
					))
				)
			)
		)

		;series storage is already encoded, append it as-is to passed in data
		(if (size series_cases)
			(let
				(assoc
					series_features (get !seriesFeatures series)
					remaining_series_feature_indices (list)
				)

				;leave only those indices of series_features that will not be clobbered by features
				(assign (assoc
					remaining_series_feature_indices
						(filter
							(lambda (not (contains_value features (get series_features (current_value)))))
							(indices series_features)
						)
				))

				;set training features to be unique, removing those from the series that are being explicitly trained on
				(accum (assoc features (unzip series_features remaining_series_feature_indices) ))

				(assign (assoc
					cases
						;apply the one input case to all the cases in the series
						(if (= (size cases) 1)
							(let
								(assoc case_values (get cases 0))
								(map
									(lambda
										(append case_values (unzip (current_value) remaining_series_feature_indices) )
									)
									series_cases
								)
							)

							;else apply each input case to each of the cases in the series
							(= (size cases) (size series_cases))
							(map
								(lambda
									(append (get cases (current_index)) (unzip (current_value) remaining_series_feature_indices) )
								)
								series_cases
							)
						)
				))

				;clear out stored series
				(call remove_series_store (assoc series series))
			)
		)

		;if dataset has features that are for derivation output only and are not being explicitly trained on
		;then add them to the training data with nulls
		(if (size (remove (zip !trainedFeatures) features))
			(let
				(assoc
					;keep only those features that aren't specified in 'features', that have 'derived_feature_code' but
					;will not be auto derived and aren't the built-in time-series features
					derive_only_features
						(filter
							(lambda
								(and
									(not (contains_value features (current_value)))
									(!= (null) (get !featureAttributes [(current_value 1) "derived_feature_code"]) )
									(= (null) (get !featureAttributes [(current_value 1) "auto_derive_on_train"]) )
									;these features are derived manually
									(not (contains_value [".series_index" ".reverse_series_index" ".time_to_horizon" ".synchronous_counter" ".synchronous_counter_lag_1"] (current_value)))
								)
							)
							!trainedFeatures
						)
				)

				;store nulls for every derive_only_features  feature in input cases
				(if (size derive_only_features)
					(let
						(assoc nulls (map (lambda (null)) derive_only_features) )
						(assign (assoc
							features (append features derive_only_features)
							cases
								(map
									(lambda (append (current_value) nulls) )
									cases
								)
						))
					)
				)
			)
		)

		(declare (assoc num_cases (call !GetNumTrainingCases) ))

		(declare (assoc
			skip_ablation (call !CanTrainAblationBeSkipped)
			;if accumulating weight feature, store the index of that weight feature
			weight_feature_index (get (zip features (indices features)) accumulate_weight_feature)
			;trained count that's updated immediatelly as cases are trained during ablation
			ablation_trained_instance_count num_cases
		))

		(if (or !autoAnalyzeEnabled skip_ablation)
			(seq
				(assign (assoc
					new_possible_data_mass
						(+
							!dataMassChangeSinceLastAnalyze
							(if accumulate_weight_feature
								(apply "+" (map
									(lambda (or (get (current_value 1) weight_feature_index) 1))
									cases
								))

								;else just increase by 1 for each case being trained
								(size cases)
							)
						)
				))

				;if the number of cases will exceed the next autoAnalyzeThreshold, do run the autoanalyze check after training
				(if
					(and
						!autoAnalyzeEnabled
						;check if the new_possible_data_mass is greater than the threshold
						(>= new_possible_data_mass !autoAnalyzeThreshold)
					)
					(seq
						(assign (assoc run_autoanalyze_check .true ))
						;if auto-ablation is enabled and the amount of new data being trained may exceed
						;the ablation threshold, go ahead and ablate during this train flow
						(if
							(and
								!autoAblationEnabled
								(> (+ num_cases new_possible_data_mass) !autoAblationMinNumCases)
							)
							(assign (assoc skip_ablation .false ))
						)
					)
				)
			)
		)

		;iterate over the input cases and create them, only returning case ids for cases that were able to be created
		(declare (assoc new_case_ids (call !TrainCreateCases) ))

		;ablation flow that did not auto analyze, accumulate all the data mass in one step here
		(if (and (not skip_ablation) (not run_autoanalyze_check))
			;accumulates the data mass change to !dataMassChangeSinceLastAnalyze, which is either 1.0
			; or the case weight, if it exists.
			(accum_to_entities (assoc
				!dataMassChangeSinceLastAnalyze
					(apply "+" (map
						(lambda
							(if accumulate_weight_feature
								(or (get (current_value 1) weight_feature_index) 1)
								1
							)
						)
						;if accumulating the weight feature, accumulate it for all cases, even if they were ablated.
						(if accumulate_weight_feature
							cases
							;else only accumulate for cases that were actually trained and not ablated
							(unzip cases (remove (indices cases) ablated_indices_list))
						)
					))
			))
		)

		;set values if there were cases that were trained on
		#!UpdateSessionAndFeaturesAfterTrain
		(if (> (size new_case_ids ) 0)
			(let
				(assoc
					new_features (remove (zip features) !trainedFeatures)
					dataset_size (+ num_cases (size new_case_ids))
				)

				(accum (assoc trained_instance_count (size new_case_ids)))

				;add action to the existing replay data
				(accum_to_entities session (assoc
					".replay_steps" new_case_ids
					".trained_instance_count" (size new_case_ids)
					".indices_map"
						(zip
							(range next_trained_index (+ next_trained_index (size new_case_ids) -1))
							new_case_ids
						)
				))


				;if any of the trained features are not defined in feature attributes, add them as continuous_numeric with default attributes
				(if (size new_features)
					(seq
						(accum (assoc
							warnings
								(associate (concat
									"The following features trained were previously undefined: "
									(apply "concat" (trunc (weave (indices new_features) ", "))) ". "
									"They have been trained and assumed to be numeric and continuous. "
									"Please update the feature attributes if they are known."
								))
						))
						(accum_to_entities (assoc
							!featureAttributes
								(map
									(lambda (assoc "type" "continuous" "bounds" (assoc "allow_null" .true) ))
									new_features
								)
							!queryDistanceTypeMap (map (lambda "continuous_number") new_features)
						))
						(assign_to_entities (assoc
							!trainedFeatures (sort (values (append !trainedFeatures (indices !featureAttributes)) .true) )
							!trainedFeaturesContextKey
								(call !BuildContextFeaturesKey (assoc
									context_features (values (append !trainedFeatures (indices !featureAttributes)) .true)
								))
						))
						(call !UpdateDefinedFeatures)
					)
				)

				(call !UpdateRegionalMinSize)

				;update cached data properties such as has_nulls, null ratios, marginal stats, average dataset case entropies, etc
				(call !ClearCachedDataProperties)
			)
		)

		(if (and skip_ablation (> (size new_case_ids ) 0) )
			;update !dataMassChangeSinceLastAnalyze to the already computed new_possible_data_mass
			(assign_to_entities (assoc !dataMassChangeSinceLastAnalyze new_possible_data_mass ))
		)

		;if derived features wasn't specified, auto-detect them
		(if (and (= (null) derived_features) (> (size !derivedFeaturesMap) 0))
			(assign (assoc
				derived_features
					(values
						(apply "append"
							(map
								(lambda
									;if this trained feature has derived features, add all of them to the derived_features list
									(if (contains_index !sourceToDerivedFeatureMap (current_value))
										(get !sourceToDerivedFeatureMap (current_value))
										[]
									)
								)
								features
							)
						)
						.true
					)
			))
		)

		;auto populate derived features if necessary
		(if (and
				(> (size derived_features) 0)
				;either non-time series or ablation was skipped and thus features were not derived yet
				(or skip_ablation (= (null) !tsTimeFeature) )
			)
			(call !DeriveTrainFeatures (assoc
				features features
				;keep and derive only those features that are not in the features list
				derived_features (filter (lambda (not (contains_value features (current_value)))) derived_features)
				case_ids new_case_ids
			))
		)

		;if auto analysis is enabled, check whether this dataset should be re-analyzed
		;and either analyze or return the appropriate status to client so that analysis could be started
		(if skip_ablation
			(if (and run_autoanalyze_check (> (size new_case_ids ) 0))
				(call !AutoAnalyzeIfNeeded)
			)
		)

		(if !hasDependentFeatures
			#!UpdateDependentFeaturesMaps
			(let
				(assoc
					dependents_boundary_map (assoc)
					dependent_values_combinations_map (assoc)
					unique_nominals_set (list)
				)

				(if (size !continuousToNominalDependenciesMap)
					(seq
						(map
							(lambda (let
								(assoc
									dependent_nominals (current_value 1)
									continuous_feature (current_index 1)
								)

								;creates a nested map of:  value -> (optional nested layers values) -> valid ranges, for each unique combination
								(declare (assoc
									dependents_combinations_map
										(call !ComputeDependentBoundaries (assoc
											nominals dependent_nominals
											value_feature continuous_feature
											value_feature_nulls_are_dependent (get !featureAttributes [continuous_feature "null_is_dependent"])
										))
								))

								;creates a list of all unique valid nominal value combinations, e.g., [ ['heartrate' 'bpm'] ['xray' 'mSv'] ... ]
								(declare (assoc
									dependent_values_combinations
										(apply "append" (values
											(call !AccumulateDependentValuesCombinations (assoc
												nested_value_combinations_map dependents_combinations_map
												values_lists []
											))
										))
								))

								(accum (assoc
									dependents_boundary_map (associate continuous_feature dependents_combinations_map)
									dependent_values_combinations_map (associate continuous_feature dependent_values_combinations)
								))
							))
							!continuousToNominalDependenciesMap
						)

						(assign_to_entities (assoc
							!dependentsBoundaryMap dependents_boundary_map
							!dependentValuesCombinationsMap dependent_values_combinations_map
						))
					)
				)
			)
		)

		;if there are features that have nulls, check if they still have nulls next time we react or analyze
		(if !inactiveFeaturesMap
			(assign_to_entities (assoc !inactiveFeaturesNeedCaching .true ))
		)

		;capture these cases into the total observed count
		(accum_to_entities session (assoc
			".total_instance_count" (size cases)
		))
		(assign_to_entities session (assoc
			".next_trained_index" (+ next_trained_index (size cases))
		))

		(accum_to_entities (assoc !revision 1))

		;return response
		(call !Return (assoc
			warnings (if (size warnings) (indices warnings))
			payload
				(assoc
					"num_trained" (size new_case_ids)
					"ablated_indices" (sort ablated_indices_list)
					"status" status_output
				)
		))
	)

	;private helper method for train that checks for invalid features or parameters
	#!PreTrainChecks
	(declare
		(assoc
			reserved_feature_names
				(if allow_training_reserved_features
					(list)
					;filter out any normal features, leaving only invalid feature names that start with reserved characters
					(filter
						(lambda
							(or
								(contains_index !untrainableFeatureCharacterSet (first (current_value)))
								(= "" (current_value))
							)
						)
						features
					)
				)
		)

		;if any features are in the reserved list, can't train, output the error message
		(if (> (size reserved_feature_names) 0)
			(conclude (conclude
				(call !Return (assoc
					errors
						(list (concat
							"The following features should not start with characters '.' '^' '!' or '#' or be empty: "
							;change list of features into a space-separated list of feature names
							(apply "concat"
								(weave
									reserved_feature_names
									(range " " 1 (size reserved_feature_names) 1)
								)
							)
						))
					payload
						(assoc
							"num_trained" 0
							"ablated_indices" (list)
							"status" (null)
						)
				))
			))
		)

		;verify all row sizes match the number of features
		(if
			(size (filter
				(lambda (!= (size features) (size (current_value))))
				cases
			))
			(conclude (conclude
				(call !Return (assoc
					errors (list "The number of feature names specified does not match the number of feature values given.")
					payload
						(assoc
							"num_trained" 0
							"ablated_indices" ablated_indices_list
							"status" status_output
						)
				))
			))
		)

		;if specifying a series, make sure there are series_cases and the lengths match
		(if (!= (null) series)
			(if (= (size series_cases) 0)
				(assign (assoc
					cases (null)
					message "Specified series does not exist"
				))

				;if input cases don't match the number of cases stored in series
				(and (> (size cases) 1) (!= (size cases) (size series_cases)))
				(assign (assoc
					cases (null)
					message "cases do not match length of specified series"
				))
			)
		)

		;if bad input, ie, size of series does not match the training cases, don't train anything
		(if (= (null) cases)
			(conclude (conclude
				(call !Return (assoc
					errors (list message)
					payload
						(assoc
							"num_trained" 0
							"ablated_indices" ablated_indices_list
							"status" status_output
						)
				))
			))
		)

		(declare (assoc
			numeric_feature_indices
				(filter
					(lambda (or
						;only keep numerical nominals/ordinals and non-nominals that aren't datetimes/edit distance/string ordinals features
						(contains_index !numericNominalFeaturesMap (get features (current_value)) )
						(contains_index !ordinalNumericFeaturesSet (get features (current_value)) )
						(and
							(not (contains_index !nominalsMap (get features (current_value))) )
							(not (contains_index !featureDateTimeMap (get features (current_value))) )
							(not (contains_index !editDistanceFeatureTypesMap (get features (current_value))) )
							(not (contains_index !ordinalOrdinalToStringMap (get features (current_value))) )
						)
					))
					(indices features)
				)
		))

		;output warning for any numeric features that contain non-numeric values
		(if (size numeric_feature_indices)
			(map
				(lambda
					(map
						(lambda
							;streamline for performance by checking if numeric first, and if not, then separately check that it's not null
							(if (!~ 0 (get (current_value 1) (current_value)))
								(if (!= (null) (get (current_value 1) (current_value)))
									(accum (assoc
										warnings
											(associate (concat "Feature '" (get features (current_value 2)) "' contains non-numeric values." ))
									))
								)
							)
						)
						numeric_feature_indices
					)
				)
				cases
			)
		)
	)

	;private helper method for train that creates the cases in cases and returns the case ids
	#!TrainCreateCases
	(if skip_ablation
		(call !TrainCasesWithoutAblation)

		;time feature exists, do ablation on time series by deriving one series at a time and then ablating those cases prior to training
		!tsTimeFeature
		(call !TrainTimeSeriesAblation)

		;else ablating cases during training
		(call !TrainCasesWithAblation)
	)

	;sub method to train cases without ablation, computing and storing an estimated case weight if rebalance features are specified
	#!TrainCasesWithoutAblation
	(let
		(assoc train_features features )

		;need to compute features for these new cases and update them
		(if !computedFeaturesMap
			(call !ComputeFeaturesDuringTrain (assoc update_cases_and_features .true ))
		)

		;if there exist rebalance_features, compute those case weights to store when creating each case
		(if (or !continuousRebalanceFeatures !nominalRebalanceFeatures)
			(let
				(assoc
					rebalance_case_weights (call !ComputeRebalanceCaseWeights (assoc rebalance_cases cases ))
					total_mass (replace !cachedTotalMass)
					total_rebalance_mass (replace !cachedRebalanceTotalMass)
				)

				(assign (assoc
					cases
						(map
							(lambda (let
								(assoc case_weight (get rebalance_case_weights (current_index 1)) )

								(accum (assoc
									total_mass 1
									total_rebalance_mass case_weight
								))

								(append
									(current_value)
									;scale case weight so the total mass of the dataset remains the same, as though it wasn't rebalanced
									(* case_weight (/ total_mass total_rebalance_mass))
									;probability mass is always 1 for new cases
									1
								)
							))
							cases
						)
				))

				(assign_to_entities (assoc
					!cachedTotalMass total_mass
					!cachedRebalanceTotalMass total_rebalance_mass
				))

				(accum (assoc
					train_features
						;if ablation is enabled but not needed for this batch of cases
						(if !autoAblationEnabled
							[accumulate_weight_feature !internalLabelProbabilityMass]
							[".case_weight" !internalLabelProbabilityMass]
						)
				))
			)

			;if ablation is enabled but is not needed for this batch of cases,
			;ensure a case weight of 1 is still trained for each case
			!autoAblationEnabled
			(assign (assoc
				train_features (append train_features accumulate_weight_feature)
				cases (map (lambda (append (current_value) 1)) cases)
			))
		)

		;iterate over cases and create them here
		(map
			(lambda
				;create the case and output case id
				(call !CreateCase (assoc
					features train_features
					feature_values
						(if encode_features_on_train
							(call !ConvertFromInput (assoc
								feature_values (current_value 2)
								features train_features
							))
							;else use feature_values as-is
							(current_value 1)
						)
					session (get_value session)
					session_training_index (+ next_trained_index (current_index 1))
				))
			)
			cases
		)
	)

	;sub method to train cases using ablation by breaking up trained cases into batches and ablating per batch as necessary
	#!TrainCasesWithAblation
	(let
		(assoc
			batch_data_mass_threshold 0
			batch_data_mass 0
			batch_size 0
			input_case_index 0
			output_case_ids []

			;threshold-related variables
			thresholds_enabled
				(or
					(size !autoAblationAbsThresholdMap)
					(size !autoAblationDeltaThresholdMap)
					(size !autoAblationRelThresholdMap)
				)
			prev_prediction_stats_map {}
			new_prediction_stats_map {}
			thresholds_satisfied .false

			rebalance_weights (or !continuousRebalanceFeatures !nominalRebalanceFeatures)
			train_features
				;if auto ablate is enabled, populate the weight and probability mass features for this case
				(if !autoAblationEnabled
					(if (or !continuousRebalanceFeatures !nominalRebalanceFeatures)
						(append features [ !autoAblationWeightFeature !internalLabelProbabilityMass ] )
						(append features [ !autoAblationWeightFeature ] )
					)

					(or !continuousRebalanceFeatures !nominalRebalanceFeatures)
					(append features [ ".case_weight" !internalLabelProbabilityMass ] )

					features
				)
			weight_feature
				(if !autoAblationEnabled
					!autoAblationWeightFeature

					(or !continuousRebalanceFeatures !nominalRebalanceFeatures)
					".case_weight"
				)
		)

		(if (and (not read_only_mode) rebalance_weights)
			(declare (assoc
				rebalance_case_weights (null)
				total_mass (replace !cachedTotalMass)
				total_rebalance_mass (replace !cachedRebalanceTotalMass)
			))
		)

		(declare  (assoc
			hyperparam_map
				(call !GetHyperparameters (assoc
					context_features features
					weight_feature weight_feature
				))
		))
		(declare (assoc
			closest_k (get hyperparam_map "k")
			p_parameter (get hyperparam_map "p")
			dt_parameter (get hyperparam_map "dt")
			feature_weights (get hyperparam_map "featureWeights")
			feature_deviations (get hyperparam_map "featureDeviations")
			query_feature_attributes_map (get hyperparam_map "featureDomainAttributes")
		))

		;split by batches of cases until next analyze
		(while (< input_case_index (size cases))

			;Only compute prediction stats for ablation if thresholds are enabled, we're
			; not skipping ablation, and we have hyperparameters to use for the computation.
			(if (and thresholds_enabled (not skip_ablation) (size !hyperparameterMetadataMap))
				(seq
					(assign (assoc
						prev_prediction_stats_map new_prediction_stats_map
					))
					(assign (assoc
						new_prediction_stats_map
							(get
								(call !CalculateFeatureResiduals (assoc
									features features
									weight_feature !autoAblationWeightFeature
									use_case_weights .true
									compute_all_statistics .true
								))
								"prediction_stats"
							)
					))
					(assign (assoc
						thresholds_satisfied
							(apply "or"
								(values
									(call !CheckThresholds (assoc
										abs_threshold_map !autoAblationAbsThresholdMap
										delta_threshold_map !autoAblationDeltaThresholdMap
										rel_threshold_map !autoAblationRelThresholdMap
										prev_prediction_stats_map prev_prediction_stats_map
										new_prediction_stats_map new_prediction_stats_map
									))
								)
							)
					))
				)
			)

			(assign (assoc
				;always train a few extra cases since some are expected to be ablated
				;to prevent this threshold value from dropping down to very small values
				;but also limit to how much is trained at a time
				batch_data_mass_threshold
					(max
						10
						(min
							(+ 10 (- !autoAnalyzeThreshold !dataMassChangeSinceLastAnalyze))
							!ablationBatchSize
						)
					)
				batch_data_mass 0
				batch_size 0
			))

			(while (and (< batch_data_mass batch_data_mass_threshold) (< (+ input_case_index (current_index)) (size cases)) )
				(assign (assoc
					batch_data_mass
						(+
							(or (previous_result 1) 0)
							(if accumulate_weight_feature
								(or (get cases [(+ input_case_index (current_index 2)) weight_feature_index ]) 1)
								1
							)
						)
					batch_size (+ 1 (current_index 1))
				))
				batch_data_mass
			)
			(assign (assoc
				;this gets case data when read_only_mode is set, otherwise case_ids
				output_case_ids
					(call !AblateCases (assoc
						cases (unzip cases (range input_case_index (+ input_case_index batch_size -1)) )
						;ensure that starting training index value is updated for each batch
						session_training_index (+ total_instance_count input_case_index)
					))
			))

			(if (and run_autoanalyze_check (not skip_auto_analyze))
				(call !AutoAnalyzeIfNeeded)
			)

			;if the number of cases will exceed the reduce_data threshold since the last reduce_data call, run it again
			;the default !reduceDataInfluenceWeightEntropyThreshold of 0.6 will ensure that approximately 1/e of the data is removed
			(if
				(and
					(not skip_reduce_data)
					(>= (call !GetNumTrainingCases) !autoAblationMaxNumCases)
					(size !hyperparameterMetadataMap)
				)
				(call reduce_data (assoc
					features features
					skip_auto_analyze skip_auto_analyze
				))

				;else, add the new cases to the total number since the last data reduction
				; and notify the user that a reduce_data call is needed/recommended if skip_reduce_data is set
				; rather than performing it now.
				(seq
					;ensure we only set the reduce_data status output if a reduction is actually necessary.
					(if (and
							skip_reduce_data
							(>= (call !GetNumTrainingCases) !autoAblationMaxNumCases)
						)
						(assign (assoc status_output "reduce_data"))
					)
					(if (not read_only_mode)
						(accum_to_entities (assoc !dataMassChangeSinceLastDataReduction batch_size ))
					)
				)
			)

			(accum (assoc input_case_index batch_size ))

			(if (> (current_index) 0)
				(assign (assoc output_case_ids (append (previous_result 1) output_case_ids) ))
			)

			output_case_ids
		)

		(if (and (not read_only_mode) rebalance_weights)
			(assign_to_entities (assoc
			 	!cachedTotalMass total_mass
				!cachedRebalanceTotalMass total_rebalance_mass
			))
		)

		(if (not read_only_mode)
			(assign (assoc
				output_case_ids (filter (lambda (contains_entity (current_value))) output_case_ids)
			))
		)

		output_case_ids
	)


	;Helper method to train cases with an ablation check
	#!AblateCases
	(let
		(assoc
			do_influence_weight_entropy_check
				;only do I.W.E. ablation if there are enough cases in dataset and influence weight entropies are stored
				(and
					!autoAblationEnabled
					(>= num_cases !autoAblationMinNumCases)
					(call !HasInfluenceWeightEntropies)
				)
		)

		(if (and do_influence_weight_entropy_check (= (null) !autoAblationMaxInfluenceWeightEntropy))
			;if there is no influence weight entropy cached yet, do the caching here
			(call !ComputeAndStoreInfluenceWeightEntropies (assoc features features))
		)

		(declare (assoc
			indices_to_train
				;If one or more thresholds has been satisfied, or the Trainee has not yet been analyzed,
				; just train all of the cases in this batch.
				(if (or
						thresholds_satisfied
						(not (size !hyperparameterMetadataMap))
					)
					(indices cases)
					;Otherwise, do the normal ablation filtering.
					||(filter
						(lambda  (let
							(assoc
								feature_values (get cases (current_value 1))
								case_index (current_value 1)
							)

							(if encode_features_on_train
								(assign (assoc
									feature_values
										(call !ConvertFromInput (assoc
											feature_values feature_values
											features features
										))
								))
							)

							;time series ablation explicitly keeps the first and last case of a series
							(if ts_ablated_indices_map
								(if (or
										(= (- (size cases) 1) (current_index))
										;first case and it's actually the first case of the series
										(and
											(= 0 (current_index))
											;the .series_index feature is second to last
											(= 0 (get feature_values (- (size features) 2)) )
										)
									)
									(conclude .true)
								)
							)

							;do not train on this case if it is null or all case values are null or it's within provided thresholds
							;if one of the ablation methods returns false, then the case should be ablated.
							(and
								(call !CaseOutsideThresholds)
								;do ablation entropy check, else keep case / do not ablate
								(if do_influence_weight_entropy_check (call !ShouldNewCaseBeTrained) .true)
							)
						))
						(indices cases)
					)
				)
		))

		;ensure ablated indices are based off actual training index and not restarted at 0 every time this method is called
		(accum (assoc
			ablated_indices_list
				(map
					(lambda
						(if (size ts_ablated_indices_map)
							(get ts_ablated_indices_map (+ input_case_index (current_value)))
							(+ input_case_index (current_value))
						)
					)
					(remove (indices cases) indices_to_train)
				)
			ablation_trained_instance_count (size indices_to_train)
		))

		;need to compute features for these new cases
		(declare (assoc
			computed_features_data_map
				(if !computedFeaturesMap
					(call !ComputeFeaturesDuringTrain (assoc
						cases (unzip cases indices_to_train)
						update_cases_and_features .false
					))
				)
		))

		(declare (assoc
			ablate_train_features
				(if computed_features_data_map
					(append
						features
						(get computed_features_data_map "computed_features")
						;the weight specific features go at the end
						(tail train_features (- (size features))
					))
					;else leave train_features as-is
					train_features
				)
		))
		;assign this to an outer variable that in a scope that must handle the derived case data returned here
		(if read_only_mode (assign (assoc derived_case_features ablate_train_features)) )

		(if rebalance_weights
			(assign (assoc
				rebalance_case_weights (call !ComputeRebalanceCaseWeights (assoc rebalance_cases (unzip cases indices_to_train) ))
			))
		)

		;create the cases
		(declare (assoc
			output_cases
				(map
					(lambda (let
						(assoc
							feature_values (get cases (current_value 1))
							rebalance_case_weight (null)
						)
						(if encode_features_on_train
							(assign (assoc
								feature_values
									(call !ConvertFromInput (assoc
										feature_values feature_values
										features features
									))
							))
						)
						(if rebalance_weights
							(seq
								(accum (assoc
									total_mass 1
									total_rebalance_mass (get rebalance_case_weights (current_index 1))
								))
								;scale case weight so the total mass of the dataset remains the same, as though it wasn't rebalanced
								(assign (assoc
									rebalance_case_weight
										(*
											(get rebalance_case_weights (current_index 1))
											(/ total_mass total_rebalance_mass)
										)
								))
							)
						)
						(if computed_features_data_map
							(accum (assoc feature_values (get computed_features_data_map ["computed_values" (current_index 2)]) ))
						)

						;if in compute_train_payload, just return the feature values that would be trained
						(if read_only_mode
							(conclude
								(if rebalance_weights
									;store rebalance weight and probability mass of 1
									(append feature_values [ rebalance_case_weight 1 ])

									;if auto ablate is enabled, populate the weight feature for this case
									!autoAblationEnabled
									(append feature_values 1)

									feature_values
								)
							)
						)

						;create the case and output case id
						(call !CreateCase (assoc
							features ablate_train_features
							feature_values
								(if rebalance_weights
									;store rebalance weight and probability mass of 1
									(append feature_values [ rebalance_case_weight 1 ])

									;if auto ablate is enabled, populate the weight feature for this case
									!autoAblationEnabled
									(append feature_values 1)

									feature_values
								)
							session (get_value session)
							session_training_index
								(if (size ts_ablated_indices_map)
									(+ session_training_index (get ts_ablated_indices_map (+ input_case_index (current_value 1))))
									(+ session_training_index (current_value 1))
								)
						))
					))
					indices_to_train
				)
		))

		;if there are ablated cases to accumulate influence weights to, do it here
		;also increase !dataMassChangeSinceLastAnalyze by the ablated cases and recompute influence weights entropy
		(if (and (not read_only_mode) accumulate_weight_feature (< (size indices_to_train) (size cases)) )
			(call !AccumulateCaseInfluenceWeights (assoc
				features features
				accumulate_weight_feature accumulate_weight_feature
				cases
					(unzip
						cases
						(remove (indices cases) indices_to_train)
					)
			))
		)

		;if auto analyzing, need to accumulate data masses for all cases
		(if run_autoanalyze_check
			(let
				 (assoc
					mass_to_accumulate
						(if (and accumulate_weight_feature (size indices_to_train))
							(apply "+"
								(map
									(lambda (or (get (current_value) weight_feature_index) 1))
									(unzip cases indices_to_train)
								)
							)

							;else it's 1 for every case so it's just the size of the trained data
							(size indices_to_train)
						)
				)

				(accum_to_entities (assoc !dataMassChangeSinceLastAnalyze mass_to_accumulate))
			)
		)

		output_cases
	)

)
