;Contains methods for the updating and merging of cases and case histories.
(null

	;merges cases specified by cases_to_merge
	;returns the number of duplicates merged
	;parameter:
	; cases_to_merge : list of case ids to merge into one
	#!MergeSpecifiedDuplicateCases
	(let
		(assoc
			;make a list of all replay references from all cases involved
			all_replay_references
				(map
					(lambda (retrieve_from_entity (current_value) !internalLabelSession))
					cases_to_merge
				)


			case_to_keep (first cases_to_merge)
			duplicate_cases_map (zip (tail cases_to_merge))

			unique_replays_referenced (null)
		)

		;dataset has changed so clear out these cached value
		(call !ClearCachedCountsAndEntropies)

		;destroy duplicate cases
		(map (lambda (destroy_entities (current_index))) duplicate_cases_map)

		;get unique sessions referenced
		(assign (assoc unique_replays_referenced (values all_replay_references .true )))

		;replace all references to cases that use any of the cases merged
		; with the first element of all_replay_references (the newly merged case)
		(map
			(lambda (assign_to_entities
				(current_value)
					(assoc
						".replay_steps"
						(map (lambda
								;keep the current case only if it isn't in the duplicate list
								(if
									(contains_index duplicate_cases_map (current_value))
									(get_value case_to_keep)

									(current_value)
								)
							)
							(retrieve_from_entity (current_value 1) ".replay_steps")
						)
					)
			))

			unique_replays_referenced
		)

		;ouput the number of merged dupes
		(size duplicate_cases_map)
	)

	;finds any cases that have zero distance and merges the cases: combines their lists and updates any references in associated replays
	; parameters:
	; features: list of features
	#!MergeDuplicateCases
	(declare
		(assoc
			features (list)

			;local variable, not a parameter
			hyperparam_map
				(call !GetHyperparameters (assoc
					feature (null)
					weight_feature ".none"
				))
		)
		(declare (assoc
			feature_deviations  (get hyperparam_map "featureDeviations")
			query_feature_attributes_map (get hyperparam_map "featureDomainAttributes")
		))

		(if (= 0 (size features)) (assign (assoc features !trainedFeatures)))

		;for all cases, combine duplicates
		(map
			(lambda (let
				(assoc
					cases_same_position
						;if the case entity still exists (might have already been deleted by another iteration)
						(if (contains_entity (current_value 1))
							;find those identical to it
							(contained_entities
								(query_within_generalized_distance
									0.0
									features
									(current_value 2)
									(get hyperparam_map "p")
									;weights can always be null since only looking for distances of 0
									(null)
									!queryDistanceTypeMap
									query_feature_attributes_map
									feature_deviations
									(null)
									1 ;dt
									(null) ;don't need a case weight
									;use a fixed random seed to guarantee deterministic behavior for reacts (named "fixed rand seed")
									"fixed rand seed"
									(null) ; radius
									!numericalPrecision
								)
							)
							;otherwise empty list
							(list)
						)
				)

				;if there's more than one like it (itself is included)
				(if (< 1 (size cases_same_position))
					(call !MergeSpecifiedDuplicateCases (assoc cases_to_merge cases_same_position))
				)
			))

			(call !AllCases)
		)
	)

	;Edit feature values for the specified cases.
	;Cases are specified by either case_indices or by the condition. If neither is provided, edits all cases.
	;Updates the accumulated data mass for the dataset proportional to the number of cases and features modified.
	;returns null if invalid features specified or an assoc with "count"
	;{use_active_session .true}
	#edit_cases
	(declare
		;returns {
		; 	type "assoc"
		; 	description "Map containing the count of how many cases were edited."
		;	additional_indices .false
		; 	indices {
		; 		"count" {type "number" required .true}
		; 	}
		; }
		(assoc
			;{type "list" values "string" required .true}
			;list of names of feature to edit
			features (null)
			;{type "list" required .true}
			;list of values corresponding to features
			feature_values (null)
			;{ref "CaseIndices"}
			;list of pair (list) of session id and index, where index is the original 0-based session_training_index of the case as
			;	it was trained. If specified, ignores condition and condition_session
			case_indices (list)
			;{ref "Condition"}
			;assoc of feature->value(s)
			;		no value or (null) = select cases where that feature is (null)/missing
			;   	- for continuous or numeric ordinal features:
			;			one value = must equal exactly the value or be close to it for fuzzy match
			;			two values = inclusive between, supports (null) on either side for less than/greater than conditions
			;			[(null) (null)] = select all non-null cases
			;   	- for nominal or string ordinal features:
			;			n values = must match any of these values exactly
			condition (assoc)
			;{type "string"}
			;if specified ignores condition and operates on cases for the specified session id
			condition_session (null)
			;{type "number" min 0}
			;limit on the number of cases to edit; If set to zero there will be no limit.
			;	If null, will be set to k if precision is "similar" or no limit if precision is "exact". default is null
			num_cases (null)
			;{type "string" enum ["exact" "similar"]}
			;enum used only with 'condition' parameter, will find exact matches if 'exact' and similar cases if 'similar'.
			precision "exact"
			;{type "string"}
			;the session id when this call is being made
			session "none"
		)
		(call !ValidateParameters)
		(call !ValidateCondition)

		;can't edit invalid or internal features
		(declare (assoc
			has_invalid_features
				(size (filter
					;leave only invalid features
					(lambda (contains_index !untrainableFeatureCharacterSet (first (current_value))) )
					features
				))
			affected_features (replace features)
			re_derivation_series_case_ids (null)

			;store the originally passed in values as-is for history tracking
			unencoded_feature_values (get_value feature_values)
			session_indices_map (assoc)
		))
		(if has_invalid_features
			(conclude
				(call !Return (assoc errors (list "Failed to edit cases: ensure features do not start with an invalid character.")  ))
			)
		)

		;encode feature values if necessary
		(if !hasFeaturesNeedEncodingFromInput
			(assign (assoc
				feature_values
					(call !ConvertFromInput (assoc
						feature_values feature_values
						features features
					))
			))
		)


		(declare (assoc
			case_ids
				;if case_indices are provided, pull cases by those
				(if (size case_indices)
					(call !GetCaseIds (assoc case_indices case_indices))

					;otherwise pull cases by condition/quantity
					(or (size condition) (!= (null) num_cases) )
					(call !GetCasesByCondition (assoc
						condition condition
						condition_session condition_session
						precision precision
						num_cases num_cases
					))

					;else pull all cases
					(call !AllCases)
				)
		))

		(if case_ids
			(seq
				(map
					(lambda
						(call !UpdateCaseWithHistory (assoc
							case_id (current_value 1)
							features features
							feature_values feature_values
							unencoded_feature_values unencoded_feature_values
							session session
						))
					)
					case_ids
				)

				;update derived features if necessary
				(let
					(assoc
						affected_derived_features
							;any features edited that are the source feature of a non-TS derived feature
							(filter
								(lambda
									(and
										;not a time-series feature (lag, rate, etc.)
										(not (contains_index (get !featureAttributes (current_value)) "ts_type"))
										;generated upon training, otherwise not saved into cases
										(size (get !featureAttributes [(current_value 1) "auto_derive_on_train"]) )
										;at least one source feature that affects this derived feature was edited
										(size (filter
											(lambda
												;"list of derived features contains this specific derived feature?""
												(contains_value (current_value) (current_value 1))
											)
											;only iterate over sources features that were edited
											(keep !sourceToDerivedFeatureMap features)
										))
										;the derivation code only uses values from within the same case (not other cases in the series)
										;offsets other than zero indicate deriving from values of another row within a series
										;tackling this problem for TS data is TODO: 21518
										(=
											(size
												(call !ZeroLagFeaturesInCustomCode (assoc
													code_string (get !featureAttributes [(current_value 2) "auto_derive_on_train" "code"])
												))
											)
											(size (get !featureAttributes [(current_value 1) "auto_derive_on_train" "code_features"]))
										)
									)
								)
								(or (indices !derivedFeaturesMap) [])
							)
					)

					;this will be a no-op if affected_derived_features is empty
					(map
						(lambda
							(let
								(assoc
									derived_feature (current_value 1)
									necessary_features
										;the labels (feature names) used in the derivation code
										(get !featureAttributes [(current_value 2) "auto_derive_on_train" "code_features"])
								)

								(declare (assoc
									necessary_values
										(map
											(lambda (retrieve_from_entity (current_value) necessary_features))
											case_ids
										)
								))

								(declare (assoc
									updated_values
										;derive new values for each case
										(call !AddDerivedCodeFeature (assoc
											feature derived_feature
											features necessary_features
											series_data necessary_values
										))
								))

								(call !StoreCaseValues (assoc
									case_values_map (zip case_ids updated_values)
									label_name derived_feature
									overwrite .true
								))
							)
						)
						affected_derived_features
					)

					;update features so that data mass change is correct
					(accum (assoc features affected_derived_features ))
				)
			)
		)

		;check if time series dataset, if so, need to pull all cases from affected series so that their
		;derived features can be-rederived below after cases are removed
		(if (and (!= (null) !tsTimeFeature) (size !derivedFeaturesMap))
			(let
				(assoc series_id_features (get !tsFeaturesMap "series_id_features") )

				;for each case pull the list of series id values for all the series id features
				(declare (assoc
					series_id_lists
						(values (map
							(lambda (retrieve_from_entity (current_value) series_id_features))
							case_ids
						) .true)
				))

				;for each series affected, get the cases so they can be re-derived
				(declare (assoc
					per_series_cases
						(map
							(lambda (let
								(assoc
									series_id_values (current_value 1)
								)

								(contained_entities
									(values (map
										(lambda
											(query_equals (current_index) (current_value))
										)
										(zip series_id_features series_id_values)
									))
								)
							))
							series_id_lists
						)
				))

				(assign (assoc
					affected_features (values (append affected_features (get !tsFeaturesMap "ts_derived_features")) .true)
				))

				;collapse all lists of cases into one list of case ids
				(assign (assoc
					re_derivation_series_case_ids (apply "append" per_series_cases)
				))
			)
		)

		;if there are cases that need to have features re-derived, do it here
		(if re_derivation_series_case_ids
			(call !DeriveTrainFeatures (assoc
				features !trainedFeatures
				;keep and derive only those features that are not in the features list
				derived_features (get !tsFeaturesMap "ts_derived_features")
				case_ids re_derivation_series_case_ids
			))
		)

		;accum data mass equal to (size case_ids) /* the % of features being edited.
		(accum_to_entities (assoc
			!dataMassChangeSinceLastAnalyze
				(* (size case_ids) (/ (size affected_features) (size !trainedFeatures) ))
			!dataMassChangeSinceLastDataReduction
				(* (size case_ids) (/ (size affected_features) (size !trainedFeatures) ))
		))

		(call !UpdateHasNulls (assoc features affected_features))

		;it's possible that the resulting case values activate or deactivate a feature
		(call !UpdateInactiveFeatures (assoc editing_existing_cases .true ))

		(accum_to_entities (assoc !revision 1))

		;return number of case ids edited
		(call !Return (assoc payload (assoc "count" (size case_ids)) ))
	)

	;update a cases's history with specified values
	;
	;parameters:
	; case_id: case id of case whose history is being updated
	; features: list of feature names that are being edited
	; feature_values: list of encoded values for storing into the case
	; unencoded_feature_values: list of original values the featurse are being set to for history
	; session: the session id when this call is being made
	#!UpdateCaseWithHistory
	(declare
		(assoc
			case_id (null)
			features (list)
			feature_values (list)
			unencoded_feature_values (list)
			session "none"
		)

		;pull previous case values pre-edit
		(declare (assoc previous_values (retrieve_from_entity case_id features) ))
		(if !hasEncodedFeatures
			(assign (assoc
				previous_values
					(call !ConvertToOutput (assoc
						features features
						feature_values previous_values
					))
			))
		)

		(declare (assoc
			edit_events
				(map
					(lambda
						(assoc
							"feature" (current_value 1)
							"type" "edit"
							"value" (get unencoded_feature_values (current_index 1))
							"previous_value" (get previous_values (current_index 1))
						)
					)
					features
				)
		))

		(declare (assoc
			case_edit_history
				;if the case has no edit history, create the label for it with an empty assoc as the value
				(if (not (contains_label case_id !internalLabelCaseEditHistory))
					(seq
						;need to explicitly add the !internalLabelCaseEditHistory label to the case
						(call !StoreCaseValues (assoc case_values_map (associate case_id (assoc)) label_name !internalLabelCaseEditHistory))
						(assoc)
					)

					;else retrieve the existing edit history
					(retrieve_from_entity case_id !internalLabelCaseEditHistory)
				)
		))

		;update the history record for this case
		(assign (assoc
			case_edit_history
				;if making updates to a session already in the history, append to that session history
				(if (contains_index case_edit_history session)
					(let
						;get the list of edits for this session
						(assoc session_history_list (get case_edit_history session))
						;add to the list of edits the current edit event
						(accum (assoc session_history_list edit_events))
						;output the appended new list of edits to the edit history
						(append case_edit_history (associate session session_history_list))
					)

					;output the created history entry for this session
					(append case_edit_history (associate session edit_events))
				)
		))

		;write the updated values along with the history to the case
		(assign_to_entities
			case_id
			(append
				(zip features feature_values)
				(associate !internalLabelCaseEditHistory case_edit_history)
			)
		)
	)


	;adds edit history to an individual case
	;example format of case_edit_history label as stored in each case entity:
	;	(assoc
	;		"!sessionId_A"
	;			(list
	;				(assoc "feature" "A"  "type" "set" "value" 5)
	;				(assoc "feature" "B"  "type" "remove")
	;			)
	;		"!sessionId_B"
	;			(list (assoc "feature" "C" "type" "set" "value" (null)))
	;	)
	;parameters:
	; edit_type : set, impute or remove
	; case : entity id of case to edit
	; feature : feature that was edited
	; feature_value : optional value feature was set to
	; session : session id of edit
	#!AddCaseEditHistory
	(declare
		(assoc
			;edit type should be either set or remove, but if neither is specified will defailt to a generic 'edit'
			edit_type "edit"
			case (null)
			feature ""
			feature_value (null)
			session "none"
		)

		(if (!= (null) case)
			(let
				(assoc
					edit_event
						(if (= edit_type "remove")
							(assoc "feature" feature "type" edit_type)

							(assoc "feature" feature "type" edit_type "value" feature_value)
						)
					;pull previous case values pre-edit
					previous_value (retrieve_from_entity case feature)
				)

				(if !hasEncodedFeatures
					(assign (assoc
						previous_value
							(first
								(call !ConvertToOutput (assoc
									features (list feature)
									feature_values (list previous_value)
								))
							)
					))
				)
				(accum (assoc edit_event (assoc "previous_value" previous_value)))

				;if the case has no edit history, create the label for it with an empty assoc as the value
				(if (not (contains_label case !internalLabelCaseEditHistory))
					(call !StoreCaseValues (assoc case_values_map (associate case (assoc)) label_name !internalLabelCaseEditHistory))
				)

				(declare (assoc case_edit_history (retrieve_from_entity case !internalLabelCaseEditHistory)))

				;if making updates to a session already in the history, append to that session history
				(if (contains_index case_edit_history session)
					(let
						;get the list of edits for this session
						(assoc session_history_list (get case_edit_history session))
						;add to the list of edits the current edit event
						(accum (assoc session_history_list (list edit_event)))
						;append the new list of edits to the edit history
						(accum (assoc case_edit_history (associate session session_history_list)))
					)

					;else create the history entry for this session
					(accum (assoc case_edit_history (associate session (list edit_event))))
				)

				;store the updated value into case_edit_history label
				(assign_to_entities case (associate !internalLabelCaseEditHistory case_edit_history))
			)
		)
	)

	;Iterate over all the passed in cases and accumulate their corresponding neighbor weights into the neighbors' weight_feature
	;parameters:
	; features: feature set to use for finding neighbors
	; cases: list of lists of values (non trainee-stored cases) for whose neighbors to accumulate weights for.
	; accumulate_weight_feature: name of feature into which to accumulate neighbors' influences as weight.
	#!AccumulateCaseInfluenceWeights
	(declare
		(assoc
			features !trainedFeatures
			cases (list)
			accumulate_weight_feature ".case_weight"
		)

		(declare (assoc
			hyperparam_map
				(call !GetHyperparameters (assoc
					feature (null)
					context_features features
					weight_feature accumulate_weight_feature
				))
			weight_feature_index
				;will retrieve the index of weight feature or (null)
				(if (contains_value features accumulate_weight_feature)
					(get (zip features (indices features)) accumulate_weight_feature)
				)
			context_features (filter (lambda (!= (current_value) accumulate_weight_feature)) features)
			num_cases (size cases)
			batch_size 0
			case_index 0
			batch_of_cases []
			closest_cases_maps {}
			entropy_weights []
			rebalance_case_weights (null)
		))
		(declare (assoc k_param (get hyperparam_map "k") ))
		;if k_param is a dynamic k tuple, use the max k value to compute the larger possible max_influence_entropy
		(declare (assoc k_value (if (~ 0 k_param) k_param (last k_param)) ))
		(declare (assoc
			;cache the maximum entropy possibe given k similar cases, used to compute the entropy ratio for each accumulated case
			max_influence_entropy (entropy (range (/ 1 k_value) 1 k_value 1))
			;smallest possible amount to be distributed
			smallest_case_weight  (/ 1 (call !GetNumTrainingCases))
		))

		;accumulate all cases in batches of !ablatedCasesDistributionBatchSize
		(while (< case_index num_cases)
			(assign (assoc batch_size (min !ablatedCasesDistributionBatchSize (- num_cases case_index)) ))
			(assign (assoc
				batch_of_cases (unzip cases (range case_index (+ case_index batch_size -1)))
			))

			(if rebalance_weights
				(assign (assoc
					rebalance_case_weights (call !ComputeRebalanceCaseWeights (assoc rebalance_cases batch_of_cases))
				))
			)

			;store all the local datas for the cases in one pass
			(assign (assoc
				closest_cases_maps (call !ComputeClosestCasesMapsForAccumulation)
			))

			;distribute the weights by writing to each of the local datas' cases while also computing the entropy ratio for each case
			(assign (assoc
				entropy_weights
					(map
						(lambda (let
							(assoc
								;closest_cases_map (current_value 1)
								case_weight
									(if (!= (null) weight_feature_index)
										(get batch_of_cases [ (current_index 2) weight_feature_index ] )
										;assume weight of 1 if weight feature values are not explicitly provided
										1
									)
								total_neighbor_influence (apply "+" (values (current_value 1)))
							)

							(if rebalance_weights
								(seq
									(accum (assoc
										total_mass 1
										total_rebalance_mass (get rebalance_case_weights (current_index 1))
									))
									;scale case weight so the total mass of the dataset remains the same, as though it wasn't rebalanced
									(assign (assoc
										case_weight
											(*
												case_weight
												(get rebalance_case_weights (current_index 1))
												(/ total_mass total_rebalance_mass)
											)
									))
								)
							)

							(declare (assoc
								influence_map
									;iterate over all the closest cases and accumulate the normalized weight to each one
									(map
										(lambda (seq
											(if rebalance_weights
												(let
													(assoc
														case_old_weights_pair (retrieve_from_entity (current_index 1) [ accumulate_weight_feature !internalLabelProbabilityMass ] )
													)
													;accumulate the portion of the total influence to probability mass
													(declare (assoc
														new_probability_mass
															(+
																(or (last case_old_weights_pair) 1)
																(/ (current_value 1) total_neighbor_influence)
															)

														;increase weight by portion of the total influence of the rebalanced case_weight
														new_case_weight
															(+
																(or (first case_old_weights_pair) 1)
																(*
																	case_weight
																	(/ (current_value 1) total_neighbor_influence)
																)
															)
													))

													(if (not (contains_label (current_index) accumulate_weight_feature))
														(accum_entity_roots (current_index)
															(zip_labels
																[ accumulate_weight_feature !internalLabelProbabilityMass ]
																[ new_case_weight new_probability_mass ]
															)
														)

														;else label exists, set to new values
														(assign_to_entities
															(current_index)
															(associate
																accumulate_weight_feature new_case_weight
																!internalLabelProbabilityMass new_probability_mass
															)
														)
													)
												)

												;else no rebalance weights, accumulate to weight feature
												;if accumulate_weight_feature label doesn't exist in this case, add it with a weight `1`
												(if (not (contains_label (current_index) accumulate_weight_feature))
													(accum_entity_roots (current_index)
														(zip_labels
															(list accumulate_weight_feature)
															(list (+ 1 (* (/ (current_value 1) total_neighbor_influence) case_weight)) )
														)
													)

													;else label exists, accumulate to it
													(accum_to_entities
														(current_index)
														(associate
															accumulate_weight_feature
																(* (/ (current_value 1) total_neighbor_influence) case_weight)
														)
													)
												)
											)

											;normalize influence
											(/ (current_value) total_neighbor_influence)
										))
										;closest_cases_map
										(current_value 1)
									)
							))

							;output 1 - ratio of: influential cases entropy / max influential entropy
							;that way if every case is evenly distributed, it adds zero practical mass (smallest_case_weight) to the dataset
							(max
								(- 1
									(/
										(entropy (values influence_map))
										max_influence_entropy
									)
								)
								;prevent adding zero mass by ensuring at least some amount is added
								smallest_case_weight
							)
						))
						closest_cases_maps
					)
			))

			;add the weight of all the entropy ratios accumulated by each case to !dataMassChangeSinceLastAnalyze to ensure that cases trained as
			;weights (whether through auto-ablation or otherwise) contribute to the progress towards the next auto-analyze, if enabled.
			(accum_to_entities (assoc !dataMassChangeSinceLastAnalyze (apply "+" entropy_weights) ))

			(accum (assoc case_index batch_size))
		)
	)

	;helper method for !AccumulateCaseInfluenceWeights to compute all the local datas for the specified batch_of_cases
	#!ComputeClosestCasesMapsForAccumulation
	||(map
		(lambda (let
			(assoc
				;map of case_id -> weight
				closest_cases_map
					(compute_on_contained_entities
						(query_nearest_generalized_distance
							(replace k_param)
							(replace context_features)
							(replace (unzip (zip features (current_value 1)) context_features))
							(replace (get hyperparam_map "p"))
							(replace (get hyperparam_map "featureWeights"))
							(replace !queryDistanceTypeMap)
							(replace (get hyperparam_map "featureDomainAttributes"))
							(replace (get hyperparam_map "featureDeviations"))
							(null)
							(replace (get hyperparam_map "dt"))
							(if (!= accumulate_weight_feature ".none") accumulate_weight_feature)
							;use a fixed random seed to guarantee deterministic behavior for reacts (named "fixed rand seed")
							"fixed rand seed"
							(null) ;radius
							(replace !numericalPrecision)
						)
					)
			)

			;if there are perfect matches (value is infinite), keep only those and set their weight to 1
			(if (contains_value (values closest_cases_map) .infinity)
				;keep only perfect matches
				(map 1 (filter (lambda (= (current_value) .infinity)) closest_cases_map) )

				;else return map as-is
				closest_cases_map
			)
		))
		;list of list of values
		batch_of_cases
	)

	;Iterate over the specified dataset cases, pull their weight and distribute it to their corresponding neighbors into the neighbors' distribute_weight_feature
	;parameters:
	; features: feature set to use for finding neighbors
	; case_ids: list of dataset case ids whose weights need to be distributed
	; distribute_weight_feature : name of feature into which to pull cases' weight and distribute neighbors' influences as weight.
	; has_rebalance_features: flag, if set to true will also distribute out probability mass to !internalLabelProbabilityMass
	#!DistributeCaseInfluenceWeights
	(declare
		(assoc
			features !trainedFeatures
			case_ids (list)
			distribute_weight_feature ".case_weight"
			has_rebalance_features .false
		)

		(declare (assoc original_distribute_weight_feature distribute_weight_feature))

		;for rebalance weights, use the built-in probability mass feature for distribution
		(if has_rebalance_features (assign (assoc distribute_weight_feature !internalLabelProbabilityMass)) )

		(declare (assoc
			hyperparam_map
				(call !GetHyperparameters (assoc
					feature (null)
					context_features features
					weight_feature ".none"
				))
			;default value of 1 for the accumulate_weight_feature
			new_weight_label_and_value (zip_labels (list distribute_weight_feature) (list 1))
		))

		;ensure the weight feature isn't among the features being used to find cases for distribution
		(assign (assoc features (filter (lambda (!= distribute_weight_feature (current_value))) features) ))

		(declare (assoc
			distributed_cases_maps
				||(map
					(lambda (let
						(assoc
							;case weight value that needs to be distributed among the neighbors
							case_weight (or (get (current_value 1) distribute_weight_feature) 1)
						)

						(declare (assoc
							;map of case_id -> weight
							closest_cases_map
								(compute_on_contained_entities
									;don't consider cases whose weights should be distributed, since they are all about to be removed
									(query_not_in_entity_list case_ids)
									(query_nearest_generalized_distance
										(get hyperparam_map "k")
										(replace features)
										;case id
										(current_index 1)
										(get hyperparam_map "p")
										(get hyperparam_map "featureWeights")
										!queryDistanceTypeMap
										(get hyperparam_map "featureDomainAttributes")
										(get hyperparam_map "featureDeviations")
										(null)
										(get hyperparam_map "dt")
										original_distribute_weight_feature
										;use a fixed random seed to guarantee deterministic behavior for reacts (named "fixed rand seed")
										"fixed rand seed"
										(null) ;radius
										!numericalPrecision
									)
								)
						))

						(declare (assoc total_influence (apply "+" (values closest_cases_map)) ))

						;if there are perfect matches (value is infinite), keep only those and set their weight to 1
						(if (= .infinity total_influence)
							(seq
								(assign (assoc
									closest_cases_map (map 1 (filter (lambda (= (current_value) .infinity)) closest_cases_map) )
								))
								(assign (assoc total_influence (apply "+" (values closest_cases_map)) ))
							)

							;all cases are equally too distant, set their influence to be same
							(= 0 total_influence)
							(assign (assoc
								closest_cases_map (map 1 closest_cases_map)
								total_influence (size closest_cases_map)
							))
						)
						;output pairs of: [ case_weight, distributed weight closest_cases_map]

						;populate neighbor cases' masses and update their case weights accordingly
						;eg, if 2 neighbor are splitting this case_weight evenly among them, their masses will both go up by 0.5
						;and their case weights will be scaled up relative the increase in each of their masses,
						;a neighbor with a case_weight of 0.8 and a mass of 4, will have a new mass of 4.5 and a weight of 0.9
						(if has_rebalance_features
							[
								case_weight
								(map
									(lambda (let
										(assoc
											neighbor_case_id (current_index 1)
											old_neighbor_mass (or (get (current_value 1) !internalLabelProbabilityMass) 1)
										)

										;new neighbor mass = old neighbor mass + normalized influence
										(declare (assoc
											new_neighbor_mass
												(+
													old_neighbor_mass
													;normalized portion of influence to accumulate to neighbor
													(* case_weight (/ (get closest_cases_map neighbor_case_id) total_influence))
												)
										))

										;new neighbor case weight = old case weight * new probability mass / old probability mass
										(declare (assoc
											new_neighbor_case_weight
												(*
													(or (get (current_value 1) original_distribute_weight_feature) 1)
													(/ new_neighbor_mass old_neighbor_mass)
												)
										))
										;outputs as a pair
										[new_neighbor_case_weight new_neighbor_mass]
									))
									;create an assoc of case id -> { .case_weight : value, .probability_mass : value} for each neighbor
									(compute_on_contained_entities
										(query_in_entity_list (indices closest_cases_map))
										(query_exists original_distribute_weight_feature)
										(query_exists !internalLabelProbabilityMass)
									)
								)
							]

							;else just output the pair
							[
								case_weight
								(map (lambda (* case_weight (/ (current_value) total_influence)) ) closest_cases_map)
							]
						)
					))
					(compute_on_contained_entities (query_in_entity_list case_ids) (query_exists distribute_weight_feature) )
				)
		))

		;clear query caches for weight features prior to updating them
		(reclaim_resources (null) .false (values [original_distribute_weight_feature distribute_weight_feature !internalLabelProbabilityMass] .true) )

		;distribute both weight and mass
		(if has_rebalance_features
			||(map
				(lambda
					(map
						(lambda
							(assign_to_entities (current_index) (associate
								;weight is stored as the first in a pair
								original_distribute_weight_feature (first (current_value 1))
								;mass is stored as the second in a pair
								!internalLabelProbabilityMass (last (current_value 1))
							))
						)
						;map of case -> pair of [weight, mass] to be distributed into it
						(last (current_value))
					)
				)
				(values distributed_cases_maps)
			)

			;else no rebalance features, distribute the corresponding portion of this case's weight based on the neighbor's influence
			||(map
				(lambda
					(map
						(lambda
							(accum_to_entities (current_index) (associate distribute_weight_feature (current_value 1)) )
						)
						;map of case -> weight to be distributed into it
						(last (current_value))
					)
				)
				(values distributed_cases_maps)
			)
		)

		;add the weight accumulated to each case to !dataMassChangeSinceLastAnalyze to ensure that cases trained as
		; only weights (whether through auto-ablation or otherwise) contribute to the progress towards the next auto-analyze,
		; if enabled.
		(accum_to_entities (assoc
			!dataMassChangeSinceLastAnalyze
				;sum of all case_weight values
				(apply "+" (map
					(lambda (first (current_value)))
					(values distributed_cases_maps)
				))
		))
	)

	;Helper method to reduce a list of assocs into one assoc with all the values summed up.
	;functions the same way as this reduce, but is much more performant for lists of size > 4:
	;
	; (reduce
	; 	(lambda
	; 		(map
	; 			(lambda (+ (or (first (current_value))) (or (last (current_value))) ) )
	; 			(previous_result)
	; 			(current_value)
	; 		)
	; 	)
	; 	list_of_assocs
	; )
	;
	; example input of: [ { a 1 b 2} { a 2 c 3} { b 2 d 2} ] outputs: { a 3 b 4 c 3 d 2}
	;
	;parameters:
	; list_of_assocs: list of assocs that needs to be reduced down to one assoc with each key's values added up
	#!ReduceAssocsAddValues
	||(map
		(lambda
			(apply "+"
				(filter (map
					(lambda (get (current_value) (current_index 1)))
					list_of_assocs
				))
			)
		)
		;assoc of only the unique ids among all the lists
		(apply "append" list_of_assocs)
	)

	;Helper method just like !ReduceAssocsAddValues, but where values for each key are a tuple.
	;The index of the value being added up for output needs to be provided.
	;
	; example input of: [ { a [1 2] b [2 3]} { a [2 3] c [3 6]} { b [2 3] d [2 8]} ] with index=1, outputs: { a 5 b 6 c 6 d 8}
	;
	;parameters:
	; list_of_assocs: list of assocs that needs to be reduced down to one assoc with each key's values added up
	; index: index of value in a tuple
	#!ReduceAssocsAddValuesTuple
	||(map
		(lambda
			(apply "+"
				(filter (map
					(lambda (get (current_value) [(current_index 2) index]))
					list_of_assocs
				))
			)
		)
		;assoc of only the unique ids among all the lists
		(apply "append" list_of_assocs)
	)

	;Holds out random cases and returns the name of the contained entity holding them.
	;
	;parameters:
	; num_samples : number of random samples to hold out
	; rand_seed : random seed to use for selection of cases
	#!HoldOutRandomCases
	(declare
		(assoc rand_seed (rand))

		(declare (assoc holdout_entity_name (concat "_temp" rand_seed) ))

		(create_entities holdout_entity_name (null))

		(map
			(lambda
				(move_entities (current_value) (list holdout_entity_name (current_value 1)))
			)
			(call !AllCases (assoc num num_samples rand_seed rand_seed))
		)

		holdout_entity_name
	)

	;Restores cases that were being held in entity named 'holdout_entity_name' back to the dataset
	;
	;parameters:
	; holdout_entity_name: name of entity that was returned whyn HoldOutRandomCases was called
	#!RestoreHeldOutCases
	(declare
		(assoc holdout_entity_name (null))

		;restore the validation cases from backup
		(if (!= (null) holdout_entity_name)
			(seq
				(map
					(lambda
						(move_entities (list holdout_entity_name (current_value 1)) (current_value))
					)
					(contained_entities holdout_entity_name)
				)

				(destroy_entities holdout_entity_name)
			)
		)
	)

)
