;Contains helper methods for series reacting.
(null

	;Run single_react_series in a batch, output a list of outputs from each individual single_react_series.
	;
	;parameters:  same as #single_react_series, unless listed here
	;  num_reacts: number of single_react_series to do in a batch.
	;  rand_seed:  optional, see #single_react for description.  if specified must be length of num_reacts.
	;  series_context_values: optional, 3d-list of values, context value for each feature for each row of a series.
	;		If specified, num_reacts and max_series_lengths are ignored.
	;  series_context_features: optional, features corresponding to series_context_values
	;
	;	 All of the following parameters, if specified, must be either length of 1 or num_reacts.
	;
	;  initial_values - list of lists. see #single_react_series for description.
	;  series_stop_maps - list of assocs. see #single_react_series for description.
	;  max_series_lengths - list of values. see #single_react_series for description.
	;  context_values - list of lists.  see #single_react for description.
	;  action_values - list of lists.  see #single_react for description.
	;  case_indices - list of lists.  see #single_react for description.
	#!BatchReactSeries
    (declare
        (assoc
            ;if any of these are length of 1, the index will be 0 to pull the values and apply to all reacts
            single_series_ids (= 1 (size series_id_values))
			single_initial (= 1 (size initial_values))
            single_stop_map (= 1 (size series_stop_maps))
            single_max_length (= 1 (size max_series_lengths))
			single_series_context (= 1 (size series_context_values))
            num_reacts 1
			errors (assoc)

            has_series_context_values .false
        )

        ;these lists must be either a list of lists or null; if it's an empty list, treat it as null
        (if (= (list) series_id_values) (assign (assoc series_id_values (null))) )
		(if (= (list) initial_values) (assign (assoc initial_values (null))) )
        (if (= (list) series_stop_maps) (assign (assoc series_stop_maps (null))) )

        (if (= 0 (size output_features))
            ;TODO: 15300 feed into single_react_group() and output results if details are provided
            (conclude
				(assoc
					"payload"
						(assoc
							"action_features" (list)
							"action_values" (list)
						)
				)
            )
        )

		(if !inactiveFeaturesNeedCaching (call !UpdateInactiveFeatures))
		;if for some reason expected values haven't been cached, do that here
		(if (= 0 (size !expectedValuesMap))
			(call !CacheExpectedValuesAndProbabilities (assoc
				features !trainedFeatures
				weight_feature weight_feature
				use_case_weights use_case_weights
			))
		)

		(declare (assoc
			requested_details (indices (filter details))
			output_details (contains_value (values details) .true)
		))

		(declare (assoc
			series_output
				||(range
					(lambda (let
						(assoc
							ids_index (if single_series_ids 0 (current_index 1))
							initial_index (if single_initial 0 (current_index 1))
							stop_map_index (if single_stop_map 0 (current_index 1))
							max_length_index (if single_max_length 0 (current_index 1))
							series_context_index (if single_series_context 0 (current_index 1))
							react_rand_seed (if rand_seed (get rand_seed (current_index 1)))
							react_session (null)
							react_session_training_index (null)
						)

 						;get the corresponding parameters by the index, values will be null if not specified, but must be defaulted to an empty list/assoc
						(declare (assoc
							react_series_ids (if series_id_values (get series_id_values ids_index) (list))
							react_initial_values (if initial_values (get initial_values initial_index) (list))
							react_series_stop_map (if series_stop_maps (get series_stop_maps stop_map_index) (assoc))
							react_series_context_values (if (size series_context_values) (get series_context_values series_context_index) (list))

							;max series is allowed to be null
							react_max_series_length (get max_series_lengths max_length_index)
						))

						;Note: will need to pull this entire map out and store into its own variable to pull individual ReactSeries
						; keys (i.e,. "action_values") once details are added to ReactSeries output
						(get
							(call !ReactSeries (assoc
								series_id_features series_id_features
								series_id_values react_series_ids
								series_stop_map react_series_stop_map
								max_series_length react_max_series_length
								rand_seed react_rand_seed
								series_context_values react_series_context_values
								output_new_series_ids output_new_series_ids
								output_features output_features
								continue_series continue_series

								initial_features initial_features
								initial_values react_initial_values
								series_context_features series_context_features
								action_features action_features
								derived_action_features derived_action_features
								derived_context_features derived_context_features
								details details
								extra_features extra_features
								substitute_output substitute_output
								input_is_substituted input_is_substituted
								use_case_weights use_case_weights
								leave_series_out leave_series_out
								weight_feature weight_feature

								desired_conviction desired_conviction
								use_differential_privacy use_differential_privacy
								feature_bounds_map feature_bounds_map
								goal_features_map goal_features_map
								ordered_by_specified_features ordered_by_specified_features
								exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
								generate_new_cases generate_new_cases
								preserve_feature_values preserve_feature_values
								new_case_threshold new_case_threshold
							))
							"payload"
						)
					))
					0 (- num_reacts 1) 1
				)
		))

		(if (size errors)
			(conclude
				(assoc "payload" (null) "errors" (indices errors))
			)
		)

		(assoc
			"payload"
				(append
					(assoc
						;output features are all the combined action features
						"action_features" output_features
						"action_values" (map (lambda (get (current_value) "action_values")) series_output)
					)
					(if output_details
						;map over the requested details to build a list of lists for each series
						(map
							(lambda
								;map over each series output (current_value) and pull the current detail (current_index 1)
								(let
									(assoc detail (current_index 1))
									(map (lambda (get (current_value) detail)) series_output)
								)
							)
							;explicitly do not include these specific selection details in the output for react details
							(remove
								(zip requested_details)
								["num_most_similar_cases" "num_most_similar_case_indices" "num_boundary_cases" "selected_prediction_stats" "features" "series_residuals_num_samples"]
							)
						)
						(assoc)
					)
					;aggregated_caps must be manually added because they will not be in requested_details
					(if (and output_details (contains_value requested_details "categorical_action_probabilities"))
						(assoc
							"aggregated_categorical_action_probabilities" (map (lambda (get (current_value) "aggregated_categorical_action_probabilities")) series_output)
						)
						(assoc)
					)
					;series_generate_attempts must be manually added because they will not be in requested_details
					(if (and output_details (contains_value requested_details "generate_attempts"))
						(assoc
							"series_generate_attempts" (map (lambda (get (current_value) "series_generate_attempts")) series_output)
						)
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
    )

	;React in series until a series_stop_map condition has been met, outputs an assoc of series.
	;
	;parameters:
	;	see comment block for #single_react_series in howso.amlg for details
	#!ReactSeries
	(declare
		(assoc
			series_id_features (list)
			series_id_values (list)
			series_stop_map (assoc)
			max_series_length (null)
			output_new_series_ids .false
			output_features (list)
			continue_series .false

			initial_features (null)
			initial_values (null)
			action_features (list)
			derived_action_features (list)
			derived_context_features (list)
			series_context_features (list)
			series_context_values (null)
			details (assoc)
			extra_features (null)
			substitute_output .false
			input_is_substituted .false
			use_case_weights (null)
			leave_series_out .false
			weight_feature (null)
			rand_seed (null)

			desired_conviction (null)
			use_regional_residuals (null)
			feature_bounds_map (null)
			goal_features_map (null)
			ordered_by_specified_features (null)
			exclude_novel_nominals_from_uniqueness_check (null)
			generate_new_cases "no"
			preserve_feature_values (null)
			new_case_threshold "min"
		)

		(if (= 0 (size output_features))
			;TODO: 15300 feed into single_react_group and output results if details are provided
			(conclude (assoc "payload" (assoc "action_values" (list))) )
		)

		(declare (assoc
			;map of the originally provided context, containing all the features and nulls for values that haven't been derived or generated yet
			original_context_map
				(append
					(zip derived_context_features)
					(zip derived_action_features)
					(zip action_features)
					;only use first row of series_context_values if not forecasting it
					(if (and (not continue_series) (size series_context_values))
						(zip series_context_features (first series_context_values))
						(assoc)
					)
				)
		))

		;defaults to "no" if unspecified
		(if (= (null) generate_new_cases)
			(assign (assoc generate_new_cases "no"))
		)

		(declare (assoc
			;all the features used in the series
			features (indices original_context_map)
			;matrix of values needed to generate the current row, here each row is ordered in the same order as features
			series_data []
			;if continuing a series, this is the original series matrix of values, each row is ordered in the same order as features
			existing_series_data []
			;entire series matrix of values, each row is ordered in the same order as features
			entire_series_data []
			;data to store each new row
			new_row []
			;flag set to true when series is done generating
			done .false
			;assoc of of all features -> feature values for the current series case
			current_case_map (null)
			;all features that are used as contexts
			all_context_features
				(append
					derived_context_features
					;if series_contexts are used in the generated rows and not forecasting
					(if (and (size series_context_features) (not continue_series))
						series_context_features
						(list)
					)
				)
			;context features used for each series react, usually same as all_context_features except for the initial react
			react_context_features (list)
			;store output of react
			react_output (null)
			;0-based index of last row in series_data, start with -1 because it's accumulated at the start of the loop
			last_series_index -1
			;total number of rows generated for the series
			num_generated_rows 0
			first_generated_row .true
			;map of id feature -> value to replace at end of series generation
			replacement_id_values_map (assoc)
			;flag if there are unique non-id features
			has_unique_features .false
			;map of initial feature -> initial value if user provided initial conditions
			initial_features_map (null)
			;map of initial condition series id feature -> id value that are not conditioned on in context_features
			initial_series_ids_map (null)
			;flag to use initial features as contexts for the series react when doing the initial react
			use_initial_context_features .false
			;flag (stored as number) if there are values to condition each row of the series, this uses series_context_values if they're not being forecasted
			has_series_context_values
				(if (and (size series_context_values) (not continue_series))
					(size series_context_values)
				)
			user_specified_context_features series_context_features

			;features used for uniqueness validation should not include id features
			output_features_no_ids (if (!= "no" generate_new_cases) (indices (remove (zip output_features) (get !tsFeaturesMap "series_id_features"))) )
			do_uniqueness_check .true
			retries 0
			original_desired_conviction desired_conviction
			regenerate_series (= "always" generate_new_cases)
			series_generate_attempts 0
			has_derived_stationary_features (size (get !tsFeaturesMap "derived_stationary_features"))
			;assoc of stationary feature -> value that needs to be backfilled to the whole series at the end
			derived_stationary_features_to_backfill_map {}

			;TODO: Externalize this flag if desired. Seemingly necessary for generating series past the last
			;observed time value in some datasets
			forecasting_future .false
		))

		(declare (assoc
			;list of queries that holds out any data required, used to hold out cases from series being forecasted
			;or used as contexts
			;NOTE: this currently holds out the disjunction over the matches on series IDs.
			;Meaning that when there is more than one ID feature, any series with a single matching ID feature value
			;will be held out, this may be revisited and adjusted to be more selective for the holdout process.
			holdout_queries
				(if (and leave_series_out (size series_id_values))
					(values (map
						(lambda (query_not_equals (current_index) (current_value)))
						(zip series_id_features series_id_values)
					))

					(list)
				)
		))

		(declare (assoc
			dbl_precision_epsilon
				;similar to !ComputePrecisionEpsilon but streamlined for use in react series
				(if (!= "no" generate_new_cases)
					(if (= "surprisal_to_prob" (get hyperparam_map "dt"))
						(let
							(assoc output_features_set (zip output_features_no_ids))
							(*
								;multiply by 2 to account for the precision uncertainty around both computed values
								2
								;machine epsilon
								2.220446049250313e-16
								;due to per-distance term additions and subtractions in the operations: two per nominal and three per continuous
								;dbl_epsilon * ( 2 * num_nominal_features + 3 * num_continuous_features )
								(+
									(* 2 (size (keep output_features_set (indices !nominalsMap))) )
									(* 3 (size (remove output_features_set (indices !nominalsMap))) )
								)
							)
						)

						;else non-surprisal space, use dbl_epsilon * ( num_features - 1 )
						(* 2.220446049250313e-16 (- (size output_features_no_ids) 1))
					)
				)
		))

		(assign (assoc
			max_series_length
				(if has_series_context_values
					(size series_context_values)

					(= (null) max_series_length)
					;default limit to series length generation to be the specified series limit - 1 to account for 0-based indices
					(-
						(if (> !tsSeriesLimitLength 0)
							!tsSeriesLimitLength
							;else use full dataset
							(call !GetNumTrainingCases)
						)
						1
					)

					;0 or a a negative value means no limit to series length
					(<= max_series_length 0)
					.infinity

					;subtract 1 from the specified length so that it can be compared to the 0-based index of each series row
					(- max_series_length 1)
				)
		))

		;if there are custom series contexts provided but no stop map, create a dummy stop map to prevent it from
		;stopping after 1 case which is the default behavior when no stop map is provided
		(if (and has_series_context_values (= 0 (size series_stop_maps)))
			(assign (assoc series_stop_map (assoc ".none" (null)) ))
		)

		;if doing generative reacts with unique nominals, generate unique values prior to synthesis
		(if (and
				(!= (null) desired_conviction)
				(> (size !uniqueNominalsSet) 0)
				;generating unique nominal actions
				(> (size (intersect (zip action_features) !uniqueNominalsSet)) 0)
			)
			(assign (assoc has_unique_features .true))
		)

		;compose a map of all series id features that need to be output (are in action_features) and may need to be replaced at the end
		(assign (assoc
			replacement_id_values_map
				(filter
					(lambda (get !featureAttributes (list (current_index 1) "id_feature")))
					(zip action_features)
				)
		))

		(declare (assoc
			;map of feature -> corresponding column index in series_data
			feature_index_map (zip features (indices features))
			original_context_values (unzip original_context_map features)
			;if series_id_tracking="no" then IDs aren't in action_features, and thus replacement_id_values_map will be empty
			has_non_tracked_ids (= 0 (size replacement_id_values_map))

			prev_sync_counter (null)
			max_order (null)
			modified_feature_bounds_map (assoc)
			derived_context_features derived_context_features
			series_failed .false
			num_existing_series_rows 0
			original_derived_context_features derived_context_features
			original_action_features action_features
			previous_row_failed .false
			non_derived_post_process_features (null)
			;find and store the largest referenced lag value among derived_context_features
			largest_max_row_lag
				;or with 0 to prevent null
				(or 0 (apply "max"
					(map
						(lambda (get !featureAttributes (list (current_value 1) "max_row_lag")))
						derived_context_features
					)
				))
		))

		;if this method is being called from single_react_series, warnings will already have been declared in react
		;otherwise declare warnings here if this is being called from the single_react_series call
		(if (= (null) warnings)
			(declare (assoc warnings (assoc) ))
		)

		(declare (assoc
			requested_details (indices (filter (lambda (current_value)) details))
			output_details (contains_value details .true)
			entire_detail_data []
		))

		(if output_details
			(seq
				(declare (assoc
					case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
				))
				(declare (assoc
					series_detail_values_map (map (lambda (list)) (zip (indices case_detail_values_map)))
				))
			)
		)

		(let
			(assoc context_map (zip user_specified_context_features))

			;replacement map is made of those ids that should have new values assigned at completion or are not explicitly provided as contexts
			(assign (assoc
				replacement_id_values_map
					(filter
						(lambda
							(or
								output_new_series_ids
								(not (contains_index context_map (current_index)))
							)
						)
						replacement_id_values_map
					)
			))
		)

		(call !InitializeInitialSeriesFeatures)

		;store an assoc of lag/rate/delta feature -> lag/order amount
		(declare (assoc ts_feature_lag_amount_map (if !tsTimeFeature (call !BuildTSFeatureLagAmountMap)) ))

		(if continue_series
			(call !PrepContinueReactSeries)
		)

		(if (contains_index series_stop_map [!tsTimeFeature "max"])
			(let
				(assoc
					start_time
						(if (contains_index initial_features_map !tsTimeFeature)
							(get initial_features_map !tsTimeFeature)

							(and has_series_context_values (contains_value series_context_features !tsTimeFeature))
							(get series_context_values [0 (get (zip series_context_features (indices series_context_features)) !tsTimeFeature) ] )

							(size series_data)
							(get series_data [-1 (get feature_index_map !tsTimeFeature) ] )
						)
				)

				(if (contains_index !featureDateTimeMap !tsTimeFeature)
					(assign (assoc
						start_time
							(format
								start_time
								(get !featureDateTimeMap (list !tsTimeFeature "date_time_format"))
								"number"
								{
									"locale" (get !featureDateTimeMap [ !tsTimeFeature "locale" ] )
									"time_zone" (get !featureDateTimeMap [ !tsTimeFeature "default_time_zone" ] )
								}
								(null)
							)
					))
				)

				(if (and
						start_time
						(< (get series_stop_map [!tsTimeFeature "max"]) start_time)
					)
					(seq
						(accum (assoc
							errors (associate "The specified stop time for the series is before the starting point of the series.")
						))
						;accum to errors and return them in this returned assoc so it functions for both single_react_series and standard react_series
						(conclude (conclude (assoc "payload" (assoc "action_values" (list)) "errors" (indices errors)) ))
					)

					(and
						start_time
						(= (get series_stop_map [!tsTimeFeature "max"]) start_time)
					)
					(accum (assoc
						warnings
							(associate (concat
								"The specified stop time for the series is equal to the starting point of the series. "
								"Consider using `max_series_lengths` if only one timestep is desired."
							))
					))
				)
			)
		)

		;loop until series stopping condition is met
		(assign (assoc
			entire_series_data
				(while (not done)

					(assign (assoc
						desired_conviction original_desired_conviction
						do_uniqueness_check .true
						retries 0
						previous_row_failed .false
						series_failed .false
						prev_sync_counter (null)
					))

					(if output_details
						;reset the case details that are held in lists. (influential_cases, generate_attempts, etc.)
						;these detail values are not overwritten through appends
						(assign (assoc
							case_detail_values_map
								(map
									(lambda
										(if (= (list) (get_type (current_value)))
											(list)

											;generate_attempts is sum-ed into a digit, must be reset as a list
											(= 0 (get_type (current_value)))
											(list)

											(current_value)
										)
									)
									case_detail_values_map
								)
						))
					)

					;if initial conditions were provided, use them as contexts for the first case
					(if (and first_generated_row (> (size initial_features_map) 0) (not include_start_time_case))
						(assign (assoc
							use_initial_context_features .true
							;update initial map to be the stationary context overwritten by the provided initial values
							initial_features_map
								(append
									(if has_series_context_values
										(zip series_context_features (first series_context_values))
										(assoc)
									)
									initial_features_map
								)
						))

						;else not initial row
						(assign (assoc use_initial_context_features .false ))
					)

					;add each new row to series data with all initial context values
					(assign (assoc
						new_row
							(if (and use_initial_context_features (not include_start_time_case))
								(list
									(unzip (append original_context_map initial_features_map) features)
								)

								;overwrite the values in the original_context_map with those from the current series_index in the provided series_context_values
								has_series_context_values
								(list
									(unzip
										(append
											original_context_map
											(zip series_context_features (get series_context_values num_generated_rows) )
										)
										features
									)
								)

								;else every row begins as the original context values
								;make a copy of original_context_values, not a referenced copy
								(apply "list" [original_context_values])
							)
					))

					(accum (assoc num_generated_rows 1 ))

					;since series_data is kept to the max number of lags + current row, the last index of series_data will never exceed largest_max_row_lag
					(if (< last_series_index largest_max_row_lag)
						(accum (assoc last_series_index 1 ))
					)

					;add new row to series data while only keeping the last largest_max_row_lag rows
					(assign (assoc
						series_data
							(if (= 0 last_series_index)
								new_row
								(append (tail series_data largest_max_row_lag) new_row)
							)
					))

					(if (size original_derived_context_features)
						(seq
							;if largest max_row_lag is greater than last_series_index, that means at least one context feature
							;cannot be derived because it references a row with a larger lag and hasn't been synthed yet
							;so skip using all such features in derived contexts
							(assign (assoc
								derived_context_features
									(if (> largest_max_row_lag last_series_index)
										;only keep those derived context features whose max_row_lag is less than or equal to last_series_index
										;e.g., if a feature has 10 lags, but it's synthesising row 3 (last_series_index=2), it will only keep lags 1 and 2
										(filter
											(lambda
												(<= (get !featureAttributes (list (current_value 1) "max_row_lag")) last_series_index)
											)
											original_derived_context_features
										)

										;else keep original derived_context_features
										original_derived_context_features
									)
								action_features original_action_features
							))

							(if use_initial_context_features
								(call !DeriveOrGenerateFeatures (assoc
									react_context_features (indices initial_features_map)
									;for initial case, may need to filter out derived context features whose values are already provided
									derived_features
										(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_context_features)
								))

								;else just provide context features and the full list of derived_context_features
								(call !DeriveOrGenerateFeatures (assoc
									react_context_features user_specified_context_features
									derived_features derived_context_features
								))
							)
						)
					)

					;pregenerate unique values for non series id features
					(if has_unique_features
						;generate a map of non-series id unique features -> unique value
						(assign (assoc
							pre_generated_uniques_map
								(call !GenerateUniquesListMap (assoc
									num_reacts 1
									action_features action_features
									context_features all_context_features
									preserve_feature_values preserve_feature_values
								))
						))
					)

					(assign (assoc
						current_case_map (zip features (last series_data))
						react_context_features
							(if (and use_initial_context_features (not continue_series))
								(indices initial_features_map)
								all_context_features
							)
					))

					;SYNCHRONOUS COUNTER LOGIC
					(if (> last_series_index 0)
						(seq
							(assign (assoc
								prev_sync_counter
									(get
										(zip features (get series_data -2)) ;not the current case, but the previous case
										!tsSynchronousCounterFeature
									)
							))

							(if (> prev_sync_counter 0)
								;if previously greater than zero, decrement and set this case to that value (add it to context as well)
								;and set time delta to zero + remove from action
								(accum (assoc
									current_case_map
										(associate
											!tsSynchronousCounterFeature (- prev_sync_counter 1)
											!tsTimeDeltaFeature 0
										)
									react_context_features [!tsTimeDeltaFeature !tsSynchronousCounterFeature]
								))
							)
						)
					)

					;filter out action (rate and delta) features that are dependent on lags that were skipped due to referencing rows that have not been synthed yet
					(if (> (size original_derived_context_features) (size derived_context_features))
						(let
							(assoc
								derived_feature_dependent_on_skipped_feature_set
									;get a list of all features that dependend on the skipped derived context features
									;and convert it to a set for fast lookup
									(zip (apply "append"
										;iterate over all skipped features and pull the list of features that depend on each one
										(map
											(lambda (get !sourceToDerivedFeatureMap (current_value)))

											;skipped derived features are those that were in the original list but are not in the current derived context features list
											(filter
												(lambda (not (contains_value derived_context_features (current_value))))
												original_derived_context_features
											)
										)
									))
							)

							;keep only those action features that do not depend on skipped context features
							(assign (assoc
								action_features
									(filter
										(lambda (not (contains_index derived_feature_dependent_on_skipped_feature_set (current_value) )))
										original_action_features
									)
							))
						)
					)

					;modify context features to not include any lag-dependent features whose lag
					;amount is larger the current last_series_index
					(if (< last_series_index largest_max_row_lag)
						(assign (assoc
							react_context_features
								(filter
									(lambda
										(not (< last_series_index (get ts_feature_lag_amount_map (current_value))) )
									)
									react_context_features
								)
						))
					)

					;create a (unique if necessary) series case
					(call !SynthAndDeriveSeriesCase)

					;if this is the first row of the series, assign values for the replacement series ids here, now that the initial value is available
					(if first_generated_row
						(assign (assoc
							replacement_id_values_map
								(map
									(lambda
										;generate new unique value
										(if output_new_series_ids
											(call !GenerateInt64String)

											;else grab the value from this first series row
											(get current_case_map (current_index))
										)
									)
									replacement_id_values_map
								)
							first_generated_row .false
						))
					)

					;determine whether to stop generating the series
					(call !DetermineIfSeriesTerminates)

					;backfill values if a stationary feature triggered a change
					(if has_derived_stationary_features
						(map
							(lambda (let
								(assoc stationary_feature (current_value 1))
								;backfill if the new stationary feature value does not match the previous one (from the second-to-last row of series_data)
								(if (and
										last_series_index
										(!=
											(get current_case_map stationary_feature)
											(get series_data [-2 (get feature_index_map stationary_feature)])
										)
									)
									(let
										(assoc
											new_value (get current_case_map stationary_feature)
											feature_index (get feature_index_map stationary_feature)
										)
										(assign (assoc
											series_data
												(map
													(lambda (set (current_value) feature_index new_value) )
													series_data
												)
										))
										;add value to backfill all cases in entire series at the end
										(accum (assoc derived_stationary_features_to_backfill_map (associate stationary_feature new_value) ))
									)
								)
							))
							(get !tsFeaturesMap "derived_stationary_features")
						)
					)

					;return series_data so it's stored as (previous_result) for accumulation in the next iteration of the while loop
					;If details are requested, (previous) result needs to be a dict of "series_data" to the data and all other details
					;
					;additionally, if the series needs to be reset (for uniqueness reasons, typically), then we must "empty" (previous_result)
					;by ending with an empty list
					(if output_details
						(if series_failed
							;if the series failed (due to uniqueness), reset the accumulated detail data
							(assign (assoc entire_detail_data [] ))

							(seq
								(if (contains_index case_detail_values_map "influential_cases")
									(call !NormalizeReactSeriesInfluentialCases)
								)

								;retries holds the amount of times the case was retried. Add 1 to represent generate_attempts
								(if (and (not previous_row_failed) (contains_index case_detail_values_map "generate_attempts"))
									(assign (assoc
										case_detail_values_map (set case_detail_values_map "generate_attempts" (+ retries 1) )
									))
								)

								(accum (assoc
									entire_detail_data
										;if row failed (i.e., failed to derive values), don't append anything
										(if previous_row_failed
											[]
											[case_detail_values_map]
										)
								))
							)
						)
					)


					;if the series failed (due to uniqueness), clear out everything stored in (previous_result)
					(if series_failed
						[]

						;store into previous_result as the last row of series_data
						(append
							(if (= 0 (current_index))
								[]
								(previous_result)
							)
							;if row failed (i.e., derivation or uniqueness failed), don't append anything
							(if previous_row_failed
								[]
								[(last series_data)]
							)
						)
					)
				) ;while loop
		))

		;grab the list of column indices corresponding to all the output_features
		(declare (assoc
			action_feature_indices (unzip feature_index_map output_features)
			non_tracked_series_ids (list)
			;if outputting non-tracked ids, only output those that are explicitly listed in output_features and filter out the rest
			series_id_features_for_output
				(if has_non_tracked_ids
					(filter
						(lambda (contains_value output_features (current_value)))
						(get !tsFeaturesMap "series_id_features")
					)
				)
		))

		;if output_details, entire_series_data is a list of assocs, one assoc per row
		(if output_details
			;reduce all the detail assocs into one assoc where each key is a list of items corresponding to each row
			;eg:
			; {
			;	'categorical_action_probabilties' [ {'a' 0.4 'b' 0.5}  {'a' 0.2 'b' 0.8} ]
			;	'generate_attempts' [ 1 2 ]
			;}
			(assign (assoc
				series_detail_values_map
					(if (> (size entire_detail_data) 1)
						(reduce
							(lambda
								(map
									(lambda
										(append
											(if (= 1 (current_index 1))
												;if first item is a list or assoc, wrap in a list to accumulate as an individual item
												(if (size (first (current_value)))
													[(first (current_value 1))]
													;else just accumulate number values
													(first (current_value))
												)
												;else just accumulate number values
												(first (current_value))
											)

											;if item is a list or assoc, wrap in a list to accumulate as an individual item
											(if (size (last (current_value)))
												[(last (current_value 1))]
												;else just accumulate number values
												(last (current_value))
											)
										)
									)
									;accumulate all the details
									(previous_result)
									(current_value)
								)
							)
							entire_detail_data
						)

						;if only 1, then the reduce will not do anything. Instead, wrap the details in an extra list and drop "series_data"
						(map
							(lambda
								[(current_value 1)]
							)
							(first entire_detail_data)
						)
					)
			))
		)

		;backfill entire entire_series_data with the stationary feature value(s)
		(if (size derived_stationary_features_to_backfill_map)
			(assign (assoc
				entire_series_data
					(if (= 1 (size derived_stationary_features_to_backfill_map))
						(let
							(assoc
								feature_index (get feature_index_map (first (indices derived_stationary_features_to_backfill_map)))
								stationary_value (first derived_stationary_features_to_backfill_map)
							)
							(map
								(lambda (set (current_value) feature_index (replace stationary_value)))
								entire_series_data
							)
						)

						;else multiple stationary features, need to weave the values for the set opcode to set them all at once
						(let
							(assoc
								woven_indices_and_values
									(weave
										(unzip feature_index_map (indices derived_stationary_features_to_backfill_map))
										(values derived_stationary_features_to_backfill_map)
									)
							)
							(map
								(lambda
									;results in the format of: (set [series_data_row] idx1 value1 idx2 value2 ...)
									(apply "set" (append [(current_value 1)] woven_indices_and_values))
								)
								entire_series_data
							)
						)
					)
			))
		)

		(if (get details "series_residuals")
			(call !ComputeSeriesUncertainty)
		)

		;if need to update/replace id values, for each id, update all the rows and set updated value for each id feature
		(if (size replacement_id_values_map)
			(assign (assoc
				entire_series_data
					(map
						(lambda
							(unzip
								(append
									(zip features (current_value))
									replacement_id_values_map
								)
								features
							)
						)
						entire_series_data
					)
			))

			;else series_id_tracking="no", we'll need to create series id values to append to series below
			has_non_tracked_ids
			(let
				(assoc
					valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")))
				)
				;iterate over all series id features and create (or pick) an id value for it
				(assign (assoc
					non_tracked_series_ids
						(map
							(lambda
								(if output_new_series_ids
									(call !GenerateInt64String)

									;else pick a random value for this id feature from the dataset by randomly sampling a case
									(retrieve_from_entity
										(first
											(compute_on_contained_entities
												(query_not_equals (current_value) (null))
												(query_sample 1 (if valid_weight_feature weight_feature) (rand))
											)
										)
										(current_value)
									)
								)
							)
							series_id_features_for_output
						)
				))
			)
		)

		;if output_features specified a non-tracked series id feature, its action feature index will be null because the values are appended
		;here at the end of the flow prior to output. Replace these nulls with their corresponding feature indices.
		(if (size non_tracked_series_ids)
			(let
				(assoc
					max_index (size features)
					tail_series_id_indices (list)
				)

				;append non tracked ids at the end of each row in entire_series_data
				(assign (assoc
					entire_series_data
						(map
							(lambda (append (current_value) non_tracked_series_ids))
							entire_series_data
						)
					;list of indices corresponding to the series_ids that were appended above to the row of feature values
					;e.g., if there were 2 ids appended to o list of 10 values, this creates: (list 10 11)
					tail_series_id_indices (range max_index (+ max_index (size non_tracked_series_ids) -1))
				))

				;action_feature_indices have nulls when output_features specify non-tracked ids.
				;in those cases we replace these nulls with their corresponding feature indices
				(if (contains_value action_feature_indices (null))
					(let
						(assoc series_id_feature_to_index_map (zip series_id_features_for_output tail_series_id_indices))
						(assign (assoc
							action_feature_indices
								(map
									(lambda
										(if (= (null) (current_value))
											(get series_id_feature_to_index_map (get output_features (current_index)))
											(current_value)
										)
									)
									action_feature_indices
								)
						))
					)

					;else assign indices to be at the end correspondingly
					(assign (assoc action_feature_indices (append action_feature_indices tail_series_id_indices) ))
				)
			)
		)

		(if (and output_details (contains_index series_detail_values_map "categorical_action_probabilities"))
			(let
				(assoc
					series_len (size (get series_detail_values_map "categorical_action_probabilities"))
					aggregated_cap_map
						(reduce
							(lambda
								;iterate over each feature in the aggregated and current assoc
								(map
									(lambda
										;iterate over each class and sum up the probabilities for each class
										(map
											(lambda (+
												;if one of the assocs has a key that the other does not, ensure the values
												;do not sum up to a nan by OR-ing each value to convert any nulls to 0s
												(or (first (current_value)) )
												(or (last (current_value)) )
											))
											(first (current_value))
											(last (current_value))
										)
									)
									(previous_result)
									(current_value)
								)
							)
							(get series_detail_values_map "categorical_action_probabilities")
						)
				)

				;normalize the aggregated caps by the series length to output a single assoc for the entire series
				(declare (assoc
					aggregated_categorical_action_probabilities
						(map
							(lambda (map
								(lambda (/ (current_value) series_len))
								(current_value)
							))
							aggregated_cap_map
						)
				))

				(assign (assoc
					series_detail_values_map
						(append
							series_detail_values_map
							(assoc
								"aggregated_categorical_action_probabilities"
									(if aggregated_categorical_action_probabilities aggregated_categorical_action_probabilities [])
							)
						)
				))
			)
		)

		(if (and output_details (contains_index series_detail_values_map "generate_attempts"))
			;append the amount of series_generate_attempts+1 (series_generate_attempts is zero based)
			(assign (assoc
				series_detail_values_map
					(append series_detail_values_map (assoc "series_generate_attempts" (+ series_generate_attempts 1) ))
			))
		)


		;output the series data
		(assoc
			"payload"
				(append
					(assoc
						"action_values"
							;iterate over all the series data and return only the columns corresponding to action_features
							(map
								(lambda (unzip (current_value) action_feature_indices))
								entire_series_data
							)
						;ensure features are output in the payload
						"action_features" output_features
					)
					(if output_details
						series_detail_values_map
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
	)

	;Helper method from ReactSeries to prepare and properly populate series_data when continuing a series
	#!PrepContinueReactSeries
	(let
		(assoc
			series_id_features
				(if (size series_id_features)
					series_id_features
					(get !tsFeaturesMap "series_id_features")
				)
			id_values_map (assoc)
			existing_series_cases (list)
		)

		;if user has provided series data to continue, populate existing_series_data with the provided values
		(if (size series_context_values)
			(let
				(assoc
					feature_order
						(unzip
							(zip series_context_features (indices series_context_features))
							features
						)
				)
				;set existing_series_data matrix to match features
				(assign (assoc
					existing_series_data
						(map
							(lambda (unzip (current_value) feature_order))
							series_context_values
						)
				))

				;figure out how many total rows are needed given needed lags of the provided continue series data
				(declare (assoc
					necessary_total_rows
						(apply "max"
							;grab all the lag values corresponding to features with values from the last row
							(unzip
								ts_feature_lag_amount_map
								;keep only those features with values from the last row
								(indices (filter (zip features (last existing_series_data))) )
							)
						)
				))
				;prepend nulls if user hasn't provided enough previous rows to account for necessary lags
				(if (> necessary_total_rows (size existing_series_data))
					(assign (assoc
						existing_series_data
							(append
								(map
									(lambda (range (lambda (null)) 1 (size features) 1) )
									(range 1 (- necessary_total_rows (size existing_series_data)))
								)
								existing_series_data
							)
					))
				)
			)

			;else user has not specified untrained data, must select the data of a trained series using series_id_values
			(seq
				;populate an assoc of id feature -> value, if conditioned on a series, otherwise select a random series
				(assign (assoc id_values_map (zip series_id_features series_id_values) ))

				;pull the necessary number of cases from the series
				(assign (assoc
					existing_series_cases
						(call !RetrieveTrainedSeriesData (assoc
							id_values_map id_values_map
							num_cases_needed largest_max_row_lag
							exclusive (not include_start_time_case)
							upper_time_bound
								;if an initial time value is provided, limit existing series cases to those before the specified initial time
								(if (contains_index initial_features_map !tsTimeFeature)
									(if (contains_index !featureDateTimeMap !tsTimeFeature)
										(call !ConvertDateToEpoch (assoc
											date (get initial_features_map !tsTimeFeature)
											feature !tsTimeFeature
										))

										(get initial_features_map !tsTimeFeature)
									)
								)
						))
				))

				(if (= (size existing_series_cases) 0)
					(accum (assoc
						warnings
							(if (not (size
									(contained_entities (map
										(lambda (query_equals (current_value) (get id_values_map (current_value))))
										(indices id_values_map)
									))
								))
								;There are no cases from this series in the dataset
								(associate (concat
									"There is no series trained with the set of IDs:\n"
									(apply "concat" (values (map (lambda (concat (current_index) ": " (current_value) "\n")) id_values_map)))
								))

								(associate (concat
									"There are no trained timesteps before the given initial time value with the set of IDs:\n"
									(apply "concat" (values (map (lambda (concat (current_index) ": " (current_value) "\n")) id_values_map)))
								))
							)
					))
				)

				;if there is more than one existing series case, we'll need to sort them by the time feature to ensure ascending order
				(if (> (size existing_series_cases) 1)
					(assign (assoc
						existing_series_cases
							(sort
								(lambda (> (retrieve_from_entity (current_value) !tsTimeFeature) (retrieve_from_entity (current_value 1) !tsTimeFeature)) )
								existing_series_cases
							)
					))
				)

				;set initial existing_series_data to all the feature values from existing series cases
				(assign (assoc
					existing_series_data
						(map
							(lambda
								(call !ConvertToOutput (assoc
									features features
									feature_values (retrieve_from_entity (current_value 1) features)
								))
							)
							existing_series_cases
						)
				))
			)
		)

		;if continuing, don't need to start at series_index 0
		(if (contains_index initial_features_map ".series_index")
			(assign (assoc
				initial_features_map (remove initial_features_map [".series_index"])
			))
		)

		(assign (assoc
			num_generated_rows (size existing_series_data)
			num_existing_series_rows (size existing_series_data)
		))

		;increase the max_series_length by the amount of pre-pended data so the series ends
		;after the correct maximum amount of rows is generated
		(if num_existing_series_rows
			(seq
				(accum (assoc max_series_length num_existing_series_rows))
				;set series_data to just the necessary rows
				(assign (assoc series_data (tail existing_series_data largest_max_row_lag) ))
				(assign (assoc last_series_index (- (size series_data) 1) ))
			)
		)
	)

	#!RetrieveTrainedSeriesData
	;params:
	;  id_values_map: assoc of series id feature name to id value
	;  upper_time_bound: an upper bound time value that all retrieved cases must be before chronologically
	;  exclusive: boolean, if true then the time bound will be exclusive, otherwise inclusive
	;  num_cases_needed: the number of cases to retrieve
	(contained_entities
		(map
			(lambda (query_equals (current_value) (get id_values_map (current_value))))
			(indices id_values_map)
		)
		;if a lower bound for time is provided, limit existing series cases to those before the specified initial time
		(if upper_time_bound
			(append
				[(query_less_or_equal_to !tsTimeFeature upper_time_bound)]
				;using both query_less_or_equal_to and query_not_equals is same effect as 'query less than'
				(if exclusive (query_not_equals  !tsTimeFeature upper_time_bound) [] )
			)
			(list)
		)
		;select the necessary count of previous cases to reference lags
		(query_max !tsTimeFeature num_cases_needed)
	)


	;Helper method for ReactSeries that synthesises action_features and derives derived_action_features to create a series case
	;and then tests it for uniqueness and retries as necessary until a unique case is created
	#!SynthAndDeriveSeriesCase
	(while do_uniqueness_check

		(assign (assoc
			max_order
				(apply "max"
					(map (lambda (get !featureAttributes [(current_value 1) "ts_order"])) action_features)
				)
		))

		;rate and delta features must not synth nulls at the start of a series where they are always nulls due to
		;not having previous data, allowing other features such as value lags and time lags to determine whether the
		;resulting value will output a value or a null.  If these rates/deltas were to remain null, the resulting value
		;would either be null or be generated without being conditioned properly resulting in unpredictable values being output.
		(assign (assoc
			modified_feature_bounds_map
				;force non null
				(if (< last_series_index max_order)
					(if (size feature_bounds_map)
						(append
							feature_bounds_map
							(zip
								action_features
								(map
									(lambda (let
										(assoc action_feature (get action_features (current_index 1)) )
										;only set allow_null to false for features that have a higher order than the series index
										(if (> (get !featureAttributes [action_feature "ts_order"]) last_series_index)
											;if there is a feature bound specified for this action feature, overwrite it
											(if (current_value)
												(set (current_value) "allow_null" .false)

												;else pull the bounds from !featureBoundsMap and overwrite those
												(set (or (get !featureBoundsMap action_feature) {}) "allow_null" .false )
											)

											;else leave it as-is
											(current_value)
										)
									)
									(unzip feature_bounds_map action_features)
								))
							)
						)

						(filter (map
							(lambda
								(if (> (get !featureAttributes [(current_index 1) "ts_order"]) last_series_index)
									(set (or (get !featureBoundsMap (current_index)) {}) "allow_null" .false )
								)
							)
							(zip action_features)
						))
					)

					;else synthing data for the rest of the cases in a series, don't allow nulls for features that have no nulls
					(let
						(assoc
							explicit_no_null_features
								(filter
									(lambda (or
										(= .false (get !featureNullRatiosMap [(current_value 1) "has_nulls"]))
										;rate or delta feature whose 'parent' feature has no nulls
										(= .false (get !featureNullRatiosMap [(get !derivedFeaturesMap (current_value 1)) "has_nulls"]))
									))
									action_features
								)
						)
						(if (size feature_bounds_map)
							(append
								feature_bounds_map
								(zip
									explicit_no_null_features
									(map
										(lambda
											(set
												(or (get feature_bounds_map (current_value)) {})
												"allow_null"
												.false
											)
										)
										explicit_no_null_features
									)
								)
							)

							(map
								(lambda
									(set
										(or (get !featureBoundsMap (current_index)) {})
										"allow_null"
										.false
									)
								)
								(zip explicit_no_null_features)
							)
						)
					)
				)
		))

		;more synchronous counter logic
		;if prev_sync_counter is 0, then we need to make sure we generate a nonzero time-delta
		(if (= prev_sync_counter 0)
			(assign (assoc
				modified_feature_bounds_map
					(set
						modified_feature_bounds_map
						[!tsTimeDeltaFeature "min"]
						;set the min to the max of either the min non-zero delta or the existing minimum value in the bounds
						(max
							(get modified_feature_bounds_map [!tsTimeDeltaFeature "min"])
							(if (contains_index !featureDateTimeMap !tsTimeFeature)
								(/ (get !featureDateTimeMap [!tsTimeFeature "min_nonzero_delta"]) 2)
								(get
									(first (compute_on_contained_entities
										(query_not_equals !tsTimeDeltaFeature 0)
										(query_min !tsTimeDeltaFeature)
										(query_exists !tsTimeDeltaFeature)
									))
									!tsTimeDeltaFeature
								)
							)
						)
					)
			))
		)


		(assign (assoc
			react_output
				; (call !SingleReact (assoc
				; 	context_features react_context_features
				; 	context_values (unzip current_case_map react_context_features)
				; 	action_features action_features
				; 	;do not derive anything during this react
				; 	derived_action_features (list)
				; 	derived_context_features (list)
				; 	details (if output_details details)
				; 	extra_features (append (if extra_features extra_features []) derived_action_features)
				; 	substitute_output substitute_output
				; 	input_is_substituted input_is_substituted
				; 	use_case_weights use_case_weights
				; 	weight_feature weight_feature
				; 	rand_seed rand_seed

				; 	desired_conviction desired_conviction
				; 	use_differential_privacy use_differential_privacy
				; 	feature_bounds_map
				; 		(if modified_feature_bounds_map
				; 			modified_feature_bounds_map
				; 			feature_bounds_map
				; 		)
				; 	goal_features_map goal_features_map
				; 	ordered_by_specified_features ordered_by_specified_features
				; 	exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
				; 	generate_new_cases "no"
				; 	preserve_feature_values preserve_feature_values
				; 	new_case_threshold new_case_threshold
				; 	pre_generated_uniques_map pre_generated_uniques_map
				; 	holdout_queries holdout_queries
				; ))
				(call react_series_no_lags (assoc
					series_context_features features
					series_context_values series_data
					action_features action_features
					desired_conviction desired_conviction
				))
		))

		;overwrite the values for the action features in the current case map now that they have values
		(accum (assoc current_case_map (zip action_features (get react_output "action_values")) ))

		;if the time feature is formatted as a datetime string, then the time-delta should either be large enough
		;to change the string representation, or zero. (This will be the behavior generally, as the transformation to
		;to datetime will truncate away the delta if it is not large enough.)
		(if (and
				(contains_index !featureDateTimeMap !tsTimeFeature)
				(get current_case_map !tsTimeDeltaFeature)
			)
			(let
				(assoc
					generated_timedelta  (get current_case_map !tsTimeDeltaFeature)
					min_nonzero_delta (or (get !featureDateTimeMap [!tsTimeFeature "min_nonzero_delta"]) 1)
				)

				(accum (assoc
					current_case_map
						(associate
							!tsTimeDeltaFeature
							(if (>= generated_timedelta min_nonzero_delta)
								;no adjustment needed if greater than min delta
								generated_timedelta

								;round down to zero if that's closer
								(< generated_timedelta (/ min_nonzero_delta 2))
								0

								;otherwise use min non-zero delta
								min_nonzero_delta
							)
						)
				))
			)
		)

		;there may be features than need post processing
		(if (size feature_post_process_code_map)
			(let
				(assoc
					non_derived_action_features
						;keep only those action_features that have not been derived
						(filter
							(lambda (not (contains_value derived_action_features (current_value))) )
							action_features
						)
				)

				;get the list of non derived features that can be post processed here because the features they need
				;for post processing already have values and do not need to be derived yet
				;e.g., if a feature's post processing needs the ".value_lag_1" feature, it can be post processed here
				;but not if it needs "value" because "value" needs to be derived below.
				(assign (assoc
					non_derived_post_process_features
						(indices (filter
							(lambda
								;keep only features whose needed features do not need to be derived below
								(= 0 (size (remove (current_value) non_derived_action_features)))
							)
							post_process_needed_features_map
						))
				))

				(if (size (keep feature_post_process_code_map non_derived_post_process_features))
					;if any of the action features have a custom post_process, update their values using them
					(accum (assoc
						current_case_map
							(map
								(lambda
									(get_value
										(call_sandboxed (current_value) (assoc
											series_data
												;need to use series_data with the updated feature value
												(append
													(trunc series_data)
													[(unzip current_case_map features)]
												)
											series_row_index last_series_index
											feature_index_map feature_index_map
											!featureDateTimeMap !featureDateTimeMap
											!ConvertDateToEpoch !ConvertDateToEpoch
										) (* (size series_data) !sandboxedComputeLimit) !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit .false)
									)
								)
								(keep feature_post_process_code_map non_derived_post_process_features)
							)
					))
				)
			)
		)

		;overwrite the last row in series data with the values from the updated current case
		(assign (assoc
			series_data
				(append
					(trunc series_data)
					[(unzip current_case_map features)]
				)
		))

		(if output_details
			(assign (assoc
				case_detail_values_map
					(map
						(lambda
							(append (current_value) (get react_output (current_index)))
						)
						case_detail_values_map
					)
			))
		)

		(if (size derived_action_features)
			(let
				(assoc
					derivation_failed
						(call !DeriveOrGenerateFeatures (assoc
							;create a list of context features with action_features with no dupes since we have action_values for action_features
							react_context_features (values (append react_context_features action_features) .true)
							derived_features
								;for initial case, may need to filter out derived action features whose values are already provided
								(if use_initial_context_features
									(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_action_features)
									;else use all derived_action_features
									derived_action_features
								)
						))
				)

				;stop generating series if derivation_failed due to time feature being past max boundary;
				;remove current (last) row and stop
				(if derivation_failed
					(assign (assoc
						previous_row_failed .true
						series_data (trunc series_data)
						case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
						done .true
					))

					;else derivation succeeded, post process the derived action features here if needed
					(size feature_post_process_code_map)
					(let
						(assoc
							derived_post_process_features
								;keep all the remaining features that can be post processed now that action features are derived
								(filter
									(lambda (not (contains_value non_derived_post_process_features (current_value))))
									action_features
								)

						)

						;post process any remaining features that need these avalailable derived features
						(if (size (keep feature_post_process_code_map derived_post_process_features))
							(let
								(assoc
									post_processed_map
										(map
											(lambda
												(get_value
													(call_sandboxed (current_value) (assoc
														series_data series_data
														series_row_index last_series_index
														feature_index_map feature_index_map
														!featureDateTimeMap !featureDateTimeMap
														!ConvertDateToEpoch !ConvertDateToEpoch
													) (* (size series_data) !sandboxedComputeLimit) !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit .false)
												)
											)
											(keep feature_post_process_code_map derived_post_process_features)
										)
								)
								(assign (assoc
									series_data
										(append
											(trunc series_data)
											[(unzip
												(append (zip features (last series_data)) post_processed_map)
												features
											)]
										)
								))
							)
						)
					)
				)
			)
		)

		(assign (assoc current_case_map (zip features (last series_data)) ))

		;unique test
		(if (and (not done) (!= "no" generate_new_cases) )
			(let
				(assoc
					dupe
						(call !CheckIsDuplicateSeries (assoc
							context_values (unzip current_case_map output_features_no_ids)
							context_features output_features_no_ids
							exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
						))
				)

				;if initial_features_map contains all the output_features that are used for uniqueness test this means the first case is
				;explicitly conditioned to output these initial values and they do not need to be checked for uniqueness
				(if (and dupe use_initial_context_features)
					(if (=
							(size (remove initial_features_map output_features_no_ids))
							(- (size initial_features_map) (size output_features_no_ids))
						)
						(assign (assoc dupe .false))
					)
				)

				(if (not dupe)
					(assign (assoc do_uniqueness_check .false ))

					;else duplicate case, retry to synth and derive a new case
					(seq
						(accum (assoc retries 1))

						;lower desired_conviction every 3 retries by a factor of 2
						(if (= 0 (mod retries 3))
							(assign (assoc desired_conviction (/ desired_conviction  2) ))
						)

						;failed to synth a unique series, stop retrying
						(if (> retries 15)
							(seq
								(assign (assoc do_uniqueness_check .false ))

								;failed to synth series, regenerate entire series if able to
								(if regenerate_series
									(seq
										(accum (assoc series_generate_attempts 1))

										;after 4 full-series retries, remove current (last) row and stop
										(if (> series_generate_attempts 4)
											(assign (assoc
												done .true
												series_data (trunc series_data)
												;reset case detail values
												case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
											))

											;else reset series_data and initial features and index, to regenerate the series from the start
											(seq
												(call !InitializeInitialSeriesFeatures)

												;if there were existing rows, reset to just those existing rows
												(if num_existing_series_rows
													(assign (assoc
														series_data (tail existing_series_data largest_max_row_lag)
														last_series_index (- num_existing_series_rows 1)
														num_generated_rows num_existing_series_rows
														first_generated_row .true
														series_failed .true
														current_case_map (assoc)
														;reset case detail values
														case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
													))

													(assign (assoc
														series_data (list)
														last_series_index -1
														num_generated_rows 0
														first_generated_row .true
														series_failed .true
														current_case_map (assoc)
														;reset case detail values
														case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
													))
												)
											)
										)
									)
								)
							)
						)
					)
				)
			)

			;else don't check for uniqueness if it's not necessary
			(assign (assoc do_uniqueness_check .false ))
		)
	)


	;if initial features are provided, ensure there aren't any that do not appear in features. any extra features are deleted and ignored.
	#!InitializeInitialSeriesFeatures
	(if (size initial_features)
		(let
			(assoc
				invalid_initial_features
					(filter (lambda (not (contains_index feature_index_map (current_value)))) initial_features)
			)
			(assign (assoc initial_features_map (zip initial_features initial_values)))

			(if (size invalid_initial_features)
				(assign (assoc initial_features_map (remove initial_features_map invalid_initial_features)))
			)
		)
	)

	;macro for !ReactSeries that checks if the "done" variable should be updated to .true
	;based on the current state of the generated series.
	#!DetermineIfSeriesTerminates
	;if exceeded max_series_length, be done
	(if (>= num_generated_rows max_series_length)
		(assign (assoc done .true))

		;if a stop map is defined, then check if any of the conditions are met
		(size series_stop_map)
		(map
			(lambda (seq
				(if (contains_index (current_value) "values")
					(if (contains_value (get (current_value) "values") (get current_case_map (current_index)))
						(assign (assoc done .true))
					)
				)

				(if (contains_index (current_value) "min")
					(let
						(assoc stop_value (get current_case_map (current_index 1)))

						(if (contains_index !featureDateTimeMap (current_index))
							;convert stop_value to epoch
							(assign (assoc
								stop_value
									(format
										stop_value
										(get !featureDateTimeMap (list (current_index 2) "date_time_format"))
										"number"
										{
											"locale" (get !featureDateTimeMap [ (current_index 3) "locale" ] )
											"time_zone" (get !featureDateTimeMap [ (current_index 3) "default_time_zone" ] )
										}
										(null)
									)
							))
						)
						(if (>= (get (current_value) "min") stop_value)
							(assign (assoc done .true))
						)
					)
				)

				(if (contains_index (current_value) "max")
					(let
						(assoc stop_value (get current_case_map (current_index 1)))

						(if (contains_index !featureDateTimeMap (current_index))
							;convert stop_value to epoch
							(assign (assoc
								stop_value
									(format
										stop_value
										(get !featureDateTimeMap (list (current_index 2) "date_time_format"))
										"number"
										{
											"locale" (get !featureDateTimeMap [ (current_index 3) "locale" ] )
											"time_zone" (get !featureDateTimeMap [ (current_index 3) "default_time_zone" ] )
										}
										(null)
									)
							))
						)
						(if (<= (get (current_value) "max") stop_value)
							(assign (assoc done .true))
						)
					)
				)
			))
			series_stop_map
		)

		;else we must predict if the series should end
		(let
			(assoc
				series_end_context_map
					(filter
						;time-series triangle filtering (derived features that must be (null) by the series index should be filtered)
						(lambda
							(if (contains_index ts_feature_lag_amount_map (current_index))
								(>= last_series_index (get ts_feature_lag_amount_map (current_index)))

								.true
							)
						)
						(if forecasting_future
							;if forecasting the future, filter out time/lags from the context and condition
							;a time to horizon at the median.
							(append
								(remove
									current_case_map
									;the time feature and its lags
									(append
										[!tsTimeFeature]
										(filter
											(lambda (= "lag" (get !featureAttributes [(current_value 1) "ts_type"])) )
											(get !sourceToDerivedFeatureMap !tsTimeFeature)
										)
									)
								)
								(if !tsTimeFeatureUniversal
									;adding the .time_to_horizon feature to the context at its median reduces the influence
									;of series that possibly terminated early due to lack of further data and also making
									;predictions of whether to terminate more likely to utilize series that end before
									;the horizon of the trained data (if any such series exist)
									(assoc
										".time_to_horizon"
											(compute_on_contained_entities
												(query_quantile ".time_to_horizon" 0.5)
											)
									)
									(assoc)
								)
							)

							current_case_map
						)
					)
			)

			;predict .reverse_series_index given the current case. If zero, then series should terminate
			(declare (assoc
				rev_index_reaction
					(call !SingleReact (assoc
						context_features (indices series_end_context_map)
						context_values (values series_end_context_map)
						action_features (list ".reverse_series_index")
						;do not derive anything during this react
						derived_action_features (list)
						derived_context_features (list)
						;influential cases so that we can accumulate probability mass of series termination
						details {influential_cases .true}
						ignore_case ignore_case
						substitute_output substitute_output
						input_is_substituted input_is_substituted
						use_case_weights use_case_weights
						weight_feature weight_feature
						rand_seed rand_seed
						leave_case_out leave_case_out
						holdout_queries holdout_queries
						desired_conviction desired_conviction
						use_differential_privacy use_differential_privacy
						new_case_threshold new_case_threshold
						feature_bounds_map feature_bounds_map
						generate_new_cases "no"
					))
			))
			;to determine if the series should end, get the influence probability masses for each value of .reverse_series_index
			;among the influential cases. If a .reverse_series_index of zero has over half of the influence mass, then terminate the series.
			;(This nominal-ish flow is to help make the termination condition more sensitive. Continuous interpolation may struggle to return
			;a value of zero since all values are zero or greater.)
			(declare (assoc
				rev_index_value_influence_masses
					(zip
						(lambda (+ (current_value) (current_value 1)))
						(map (lambda (get (current_value) ".reverse_series_index")) (get rev_index_reaction "influential_cases"))
						(map (lambda (get (current_value) ".influence_weight")) (get rev_index_reaction "influential_cases"))
					)
			))
			(if (and (contains_index rev_index_value_influence_masses 0) (>= (get rev_index_value_influence_masses 0) 0.5))
				(assign (assoc done .true ))
			)
		)
	)

	;helper macro for ReactSeries that computes the series uncertainty detail
	;no parameters should be passed.
	;This method computes a collection of generative series with the same parameters given
	;to the react series call (except editing start/end) and computes the MAD of the forecasts
	;at each time value of the output series providing an estimate of the forecast's uncertainty
	#!ComputeSeriesUncertainty
	(let
		(assoc
			synthesized_timesteps entire_series_data
			time_feature_index (get feature_index_map !tsTimeFeature)
			output_feature_index_map (zip output_features (indices output_features))
		)

		(declare (assoc
			end_time (get (last synthesized_timesteps) time_feature_index)
		))

		;convert end_time to epoch if necessary
		(if (contains_index !featureDateTimeMap !tsTimeFeature)
			(assign (assoc
				end_time
					(format
						end_time
						(get !featureDateTimeMap (list !tsTimeFeature "date_time_format"))
						"number"
						{
							"locale" (get !featureDateTimeMap [ !tsTimeFeature "locale" ] )
							"time_zone" (get !featureDateTimeMap [ !tsTimeFeature "default_time_zone" ] )
						}
						(null)
					)
			))
		)

		;Forecast the same period of time
		(declare (assoc
			forecasts
				||(map
					(lambda
						(get
							(call !ReactSeries (assoc
								;passing in the current params
								continue_series continue_series
								leave_series_out leave_series_out
								generate_new_cases generate_new_cases
								series_id_features series_id_features
								series_id_values series_id_features
								output_new_series_ids output_new_series_ids
								initial_features initial_features
								initial_values initial_values
								action_features action_features
								derived_action_features derived_action_features
								derived_context_features derived_context_features
								series_context_features series_context_features
								series_context_values series_context_values
								use_case_weights use_case_weights
								leave_series_out leave_series_out
								weight_feature weight_feature
								rand_seed rand_seed
								use_regional_residuals use_regional_residuals
								feature_bounds_map feature_bounds_map
								goal_features_map goal_features_map
								ordered_by_specified_features ordered_by_specified_features
								exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
								new_case_threshold new_case_threshold

								details {}
								max_series_length (null)
								generate_new_cases generate_new_cases
								output_features output_features
								desired_conviction (if desired_conviction desired_conviction 1)
								series_stop_map (associate !tsTimeFeature {"max" end_time})

								;want to absorb and ignore any raised here
								errors (assoc)
								warnings (assoc)
							))
							["payload" "action_values"]
						)
					)
					(range 1 (or (get details "series_residuals_num_samples") 30) 1)
				)
		))

		(declare (assoc
			forecast_time_index (get output_feature_index_map !tsTimeFeature)
		))

		;transpose forecasts to be a list of forecasts where each forecast is the list
		;of "columns" where each "column" are the values of a feature throughout the forecast
		;this helps performance so that these list of feature values need only be allocated once
		(assign (assoc
			forecasts
				(map
					(lambda
						(map
							(lambda
								(if (get !featureDateTimeMap (list (current_value 1) "date_time_format"))
									;if its a datetime, format its values here
									(map
										(lambda
											(format
												(get (current_value) (current_index 1))
												(get !featureDateTimeMap (list (current_value 2) "date_time_format"))
												"number"
												{
													"locale" (get !featureDateTimeMap [ (current_value 2) "locale" ] )
													"time_zone" (get !featureDateTimeMap [ (current_value 2) "default_time_zone" ] )
												}
												(null)
											)
										)
										(current_value 1)
									)

									;else can get values directly
									(map
										(lambda
											(get (current_value) (current_index 1))
										)
										(current_value 1)
									)
								)
							)
							output_features
						)
					)
					forecasts
				)
		))

		(accum (assoc
			series_detail_values_map
				;for each timestep, get the MAD of the forecasts at the same points in time
				{
					"series_residuals"
						(map
							(lambda
								(let
									(assoc
										time_val
											(if (get !featureDateTimeMap (list !tsTimeFeature "date_time_format"))
												(format
													(get (current_value 1) time_feature_index)
													(get !featureDateTimeMap (list !tsTimeFeature "date_time_format"))
													"number"
													{
														"locale" (get !featureDateTimeMap [ !tsTimeFeature "locale" ] )
														"time_zone" (get !featureDateTimeMap [ !tsTimeFeature "default_time_zone" ] )
													}
													(null)
												)

												;raw time value
												(get (current_value 1) time_feature_index)
											)

									)

									(map
										(lambda
											(call !ComputeMAD (assoc
												vals
													(map
														(lambda
															(call !InterpolateSeriesValuesContinuous (assoc
																time_values (get (current_value 1) forecast_time_index)
																feature_values (get (current_value 1) (get output_feature_index_map (current_index 3)))
																pre_domain_value (first (get (current_value 1) (get output_feature_index_map (current_index 3))))
																post_domain_value (last (get (current_value 1) (get output_feature_index_map (current_index 3))))
																time time_val
															))
														)
														forecasts
													)
											))
										)
										;all continuous output features that are not the time feature
										(remove (zip (or (get details "features") output_features)) (append (indices !nominalsMap) !tsTimeFeature) )
									)
								)
							)
							synthesized_timesteps
						)
				}
		))
	)

)