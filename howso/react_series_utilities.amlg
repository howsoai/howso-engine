;Contains helper methods for series reacting.
(null

	;Run single_react_series in a batch, output a list of outputs from each individual single_react_series.
	;
	;parameters:  same as #single_react_series, unless listed here
	;  num_reacts: number of single_react_series to do in a batch.
	;  rand_seed:  optional, see #single_react for description.  if specified must be length of num_reacts.
	;  series_context_values: optional, 3d-list of values, context value for each feature for each row of a series.
	;		If specified, num_reacts and max_series_lengths are ignored.
	;  series_context_features: optional, features corresponding to series_context_values
	;
	;	 All of the following parameters, if specified, must be either length of 1 or num_reacts.
	;
	;  initial_values - list of lists. see #single_react_series for description.
	;  series_stop_maps - list of assocs. see #single_react_series for description.
	;  max_series_lengths - list of values. see #single_react_series for description.
	;  context_values - list of lists.  see #single_react for description.
	;  action_values - list of lists.  see #single_react for description.
	;  case_indices - list of lists.  see #single_react for description.
	#!BatchReactSeries
    (declare
        (assoc
            ;if any of these are length of 1, the index will be 0 to pull the values and apply to all reacts
            single_series_ids (= 1 (size series_id_values))
			single_initial (= 1 (size initial_values))
            single_stop_map (= 1 (size series_stop_maps))
            single_max_length (= 1 (size max_series_lengths))
			single_series_context (= 1 (size series_context_values))
            num_reacts 1

            has_series_context_values (false)
        )

        ;these lists must be either a list of lists or null; if it's an empty list, treat it as null
        (if (= (list) series_id_values) (assign (assoc series_id_values (null))) )
		(if (= (list) initial_values) (assign (assoc initial_values (null))) )
        (if (= (list) series_stop_maps) (assign (assoc series_stop_maps (null))) )

        (if (= 0 (size output_features))
            ;TODO: 15300 feed into single_react_group() and output results if details are provided
            (conclude
				(assoc
					"payload"
						(assoc
							"action_features" (list)
							"action_values" (list)
						)
				)
            )
        )

		(if !inactiveFeaturesNeedCaching (call !UpdateInactiveFeatures))
		;if for some reason expected values haven't been cached, do that here
		(if (= 0 (size !expectedValuesMap))
			(call !CacheExpectedValuesAndProbabilities (assoc
				features !trainedFeatures
				weight_feature weight_feature
				use_case_weights use_case_weights
			))
		)

		(declare (assoc
			requested_details (indices (filter details))
			output_details (contains_value (values details) (true))
		))

		(declare (assoc
			series_output
				||(range
					(lambda (let
						(assoc
							ids_index (if single_series_ids 0 (current_index 1))
							initial_index (if single_initial 0 (current_index 1))
							stop_map_index (if single_stop_map 0 (current_index 1))
							max_length_index (if single_max_length 0 (current_index 1))
							series_context_index (if single_series_context 0 (current_index 1))
							react_rand_seed (if rand_seed (get rand_seed (current_index 1)))
							react_session (null)
							react_session_training_index (null)
						)

 						;get the corresponding parameters by the index, values will be null if not specified, but must be defaulted to an empty list/assoc
						(declare (assoc
							react_series_ids (if series_id_values (get series_id_values ids_index) (list))
							react_initial_values (if initial_values (get initial_values initial_index) (list))
							react_series_stop_map (if series_stop_maps (get series_stop_maps stop_map_index) (assoc))
							react_series_context_values (if (size series_context_values) (get series_context_values series_context_index) (list))

							;max series is allowed to be null
							react_max_series_length (get max_series_lengths max_length_index)
						))

						;Note: will need to pull this entire map out and store into its own variable to pull individual ReactSeries
						; keys (i.e,. "action_values") once details are added to ReactSeries output
						(get
							(call !ReactSeries (assoc
								series_id_features series_id_features
								series_id_values react_series_ids
								series_stop_map react_series_stop_map
								max_series_length react_max_series_length
								rand_seed react_rand_seed
								series_context_values react_series_context_values
								output_new_series_ids output_new_series_ids
								output_features output_features
								continue_series continue_series

								initial_features initial_features
								initial_values react_initial_values
								series_context_features series_context_features
								action_features action_features
								derived_action_features derived_action_features
								derived_context_features derived_context_features
								details details
								extra_features extra_features
								substitute_output substitute_output
								input_is_substituted input_is_substituted
								use_case_weights use_case_weights
								leave_series_out leave_series_out
								weight_feature weight_feature

								desired_conviction desired_conviction
								use_regional_residuals use_regional_residuals
								feature_bounds_map feature_bounds_map
								goal_features_map goal_features_map
								ordered_by_specified_features ordered_by_specified_features
								exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
								generate_new_cases generate_new_cases
								preserve_feature_values preserve_feature_values
								new_case_threshold new_case_threshold
							))
							"payload"
						)
					))
					0 (- num_reacts 1) 1
				)
		))

		(assoc
			"payload"
				(append
					(assoc
						;output features are all the combined action features
						"action_features" output_features
						"action_values" (map (lambda (get (current_value) "action_values")) series_output)
					)
					(if output_details
						;map over the requested details to build a list of lists for each series
						(map
							(lambda
								;map over each series output (current_value) and pull the current detail (current_index 1)
								(let
									(assoc detail (current_index 1))
									(map (lambda (get (current_value) detail)) series_output)
								)
							)
							;explicitly do not include these specific selection details in the output for react details
							(remove
								(zip requested_details)
								["num_most_similar_cases" "num_most_similar_case_indices" "num_boundary_cases" "selected_prediction_stats"]
							)
						)
						(assoc)
					)
					;aggregated_caps must be manually added because they will not be in requested_details
					(if (and output_details (contains_value requested_details "categorical_action_probabilities"))
						(assoc
							"aggregated_categorical_action_probabilities" (map (lambda (get (current_value) "aggregated_categorical_action_probabilities")) series_output)
						)
						(assoc)
					)
					;series_generate_attempts must be manually added because they will not be in requested_details
					(if (and output_details (contains_value requested_details "generate_attempts"))
						(assoc
							"series_generate_attempts" (map (lambda (get (current_value) "series_generate_attempts")) series_output)
						)
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
    )

	;React in series until a series_stop_map condition has been met, outputs an assoc of series.
	;
	;parameters:
	;	see comment block for #single_react_series in howso.amlg for details
	#!ReactSeries
	(seq

		(if (= 0 (size output_features))
			;TODO: 15300 feed into single_react_group and output results if details are provided
			(conclude (assoc "payload" (assoc "action_values" (list))) )
		)

		(declare (assoc
			;map of the originally provided context, containing all the features and nulls for values that haven't been derived or generated yet
			original_context_map
				(append
					(zip derived_context_features)
					(zip derived_action_features)
					(zip action_features)
					;only use first row of series_context_values if not forecasting it
					(if (and (not continue_series) (size series_context_values))
						(zip series_context_features (first series_context_values))
						(assoc)
					)
				)
			series_has_terminators (get !tsFeaturesMap "series_has_terminators")
			stop_on_terminator (get !tsFeaturesMap "stop_on_terminator")
		))

		;defaults to "no" if unspecified
		(if (= (null) generate_new_cases)
			(assign (assoc generate_new_cases "no"))
		)

		(declare (assoc
			;all the features used in the series
			features (indices original_context_map)
			;matrix of values, here each row is ordered in the same order as features
			series_data (list)
			;data to store each new row
			new_row (list)
			;flag set to true when series is done generating
			done (false)
			;assoc of of all features -> feature values for the current series case
			current_case_map (null)
			;all features that are used as contexts
			all_context_features
				(append
					derived_context_features
					;if series_contexts are used in the generated rows and not forecasting
					(if (and (size series_context_features) (not continue_series))
						series_context_features
						(list)
					)
				)
			;context features used for each series react, usually same as all_context_features except for the initial react
			react_context_features (list)
			;store output of react
			react_output (null)
			;0-based index of last row in series_data, start with -1 because it's accumulated at the start of the loop
			last_series_index -1
			first_generated_row (true)
			;map of id feature -> value to replace at end of series generation
			replacement_id_values_map (assoc)
			;flag if there are unique non-id features
			has_unique_features (false)
			;map of initial feature -> initial value if user provided initial conditions
			initial_features_map (null)
			;map of initial condition series id feature -> id value that are not conditioned on in context_features
			initial_series_ids_map (null)
			;flag to use initial features as contexts for the series react when doing the initial react
			use_initial_context_features (false)
			;flag (stored as number) if there are values to condition each row of the series, this uses series_context_values if they're not being forecasted
			has_series_context_values
				(if (and (size series_context_values) (not continue_series))
					(size series_context_values)
				)
			user_specified_context_features series_context_features

			;features used for uniqueness validation should not include id features
			output_features_no_ids (if (!= "no" generate_new_cases) (indices (remove (zip output_features) (get !tsFeaturesMap "series_id_features"))) )
			do_uniqueness_check (true)
			retries 0
			original_desired_conviction desired_conviction
			regenerate_series (= "always" generate_new_cases)
			series_generate_attempts 0
		))

		(declare (assoc
			;list of queries that holds out any data required, used to hold out cases from series being forecasted
			;or used as contexts
			;NOTE: this currently holds out the disjunction over the matches on series IDs.
			;Meaning that when there is more than one ID feature, any series with a single matching ID feature value
			;will be held out, this may be revisited and adjusted to be more selective for the holdout process.
			holdout_queries
				(if (and leave_series_out (size series_id_values))
					(values (map
						(lambda (query_not_equals (current_index) (current_value)))
						(zip series_id_features series_id_values)
					))

					(list)
				)
		))

		(declare (assoc
			dbl_precision_epsilon
				;similar to !ComputePrecisionEpsilon but streamlined for use in react series
				(if (!= "no" generate_new_cases)
					(if (= "surprisal_to_prob" (get hyperparam_map "dt" ))
						(let
							(assoc output_features_set (zip output_features_no_ids))
							;surprisal space dbl_precision_epsilon is dbl_epsilon * ( num_nominal_features + 2 * num_continuous_features + num_features - 1 )
							(*
								2.220446049250313e-16
								(+
									(size (keep output_features_set (indices !nominalsMap)))
									(* 2 (size (remove output_features_set (indices !nominalsMap))) )
									(size output_features_no_ids)
									-1
								)
							)
						)

						;else non-surprisal space, use dbl_epsilon * ( num_features - 1 )
						(* 2.220446049250313e-16 (- (size output_features_no_ids) 1))
					)
				)
		))

		(assign (assoc
			max_series_length
				(if has_series_context_values
					(- (size series_context_values) 1)

					(= (null) max_series_length)
					;default limit to series length generation to be the specified series limit - 1 to account for 0-based indices
					(-
						(if (> !tsSeriesLimitLength 0)
							!tsSeriesLimitLength
							;else use full model
							(call !GetNumTrainingCases)
						)
						1
					)

					;0 or a a negative value means no limit to series length
					(<= max_series_length 0)
					.infinity

					;subtract 1 from the specified length so that it can be compared to the 0-based index of each series row
					(- max_series_length 1)
				)
		))

		;if there are custom series contexts provided but no stop map, create a dummy stop map to prevent it from
		;stopping after 1 case which is the default behavior when no stop map is provided
		(if (and has_series_context_values (= 0 (size series_stop_maps)))
			(assign (assoc series_stop_map (assoc ".none" (null))))
		)

		;if doing generative reacts with unique nominals, generate unique values prior to synthesis
		(if (and
				(!= (null) desired_conviction)
				(> (size !uniqueNominalsSet) 0)
				;generating unique nominal actions
				(> (size (intersect (zip action_features) !uniqueNominalsSet)) 0)
			)
			(assign (assoc has_unique_features (true)))
		)

		;compose a map of all series id features that need to be output (are in action_features) and may need to be replaced at the end
		(assign (assoc
			replacement_id_values_map
				(filter
					(lambda (get !featureAttributes (list (current_index 1) "id_feature")))
					(zip action_features)
				)
		))

		;map of feature -> corresponding column index in series_data
		(declare (assoc
			feature_index_map (zip features (indices features))
			original_context_values (unzip original_context_map features)
			;if series_id_tracking="no" then IDs aren't in action_features, and thus replacement_id_values_map will be empty
			has_non_tracked_ids (= 0 (size replacement_id_values_map))

			;track progress length of series being generated if it's a stop condition in the series_stop_map
			track_progress (contains_index series_stop_map ".series_progress")
			total_progress 0
			initial_existing_progress 0
			num_existing_series_rows 0
			original_derived_context_features derived_context_features
			original_action_features action_features
			previous_row_failed (false)
			;find and store the largest referenced lag value among derived_context_features
			largest_max_row_lag
				;or with 0 to prevent null
				(or 0 (apply "max"
					(map
						(lambda (get !featureAttributes (list (current_value 1) "max_row_lag")))
						derived_context_features
					)
				))
		))

		;if this method is being called from single_react_series, warnings will already have been declared in react
		;otherwise declare warnings here if this is being called from the single_react_series call
		(if (= (null) warnings)
			(declare (assoc warnings (assoc) ))
		)

		(declare (assoc
			requested_details (indices (filter (lambda (current_value)) details))
			output_details (contains_value (values details) (true))
		))

		(if output_details
			(declare (assoc
				case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
				series_detail_values_map (map (lambda (list)) (zip requested_details))
			))
		)

		(let
			(assoc context_map (zip user_specified_context_features))

			;replacement map is made of those ids that should have new values assigned at completion or are not explicitly provided as contexts
			(assign (assoc
				replacement_id_values_map
					(filter
						(lambda
							(or
								output_new_series_ids
								(not (contains_index context_map (current_index)))
							)
						)
						replacement_id_values_map
					)
			))
		)


		;if initial features are provided, ensure there aren't any that do not appear in features. any extra features are deleted and ignored.
		#!InitializeInitialSeriesFeatures
		(if (size initial_features)
			(let
				(assoc
					invalid_initial_features
						(filter (lambda (not (contains_index feature_index_map (current_value)))) initial_features)
				)
				(assign (assoc initial_features_map (zip initial_features initial_values)))

				(if (size invalid_initial_features)
					(assign (assoc initial_features_map (remove initial_features_map invalid_initial_features)))
				)
			)
		)

		;store an assoc of lag/rate/delta feature -> lag/order amount
		(declare (assoc ts_feature_lag_amount_map (if !tsTimeFeature (call !BuildTSFeatureLagAmountMap)) ))

		(if continue_series
			(call !PrepContinueReactSeries)
		)

		;loop until series stopping condition is met
		(while (not done)

			(assign (assoc
				desired_conviction original_desired_conviction
				do_uniqueness_check (true)
				retries 0
				previous_row_failed (false)
			))

			(if output_details
				;reset the case details that are held in lists. (influential_cases, generate_attempts, etc.)
				;these detail values are not overwritten through appends
				(assign (assoc
					case_detail_values_map
						(map
							(lambda
								(if (= (list) (get_type (current_value)))
									(list)

									;generate_attempts is sum-ed into a digit, must be reset as a list
									(= 0 (get_type (current_value)))
									(list)

									(current_value)
								)
							)
							case_detail_values_map
						)
				))
			)

			;if initial conditions were provided, use them as contexts for the first case
			(if (and first_generated_row (> (size initial_features_map) 0))
				(assign (assoc
					use_initial_context_features (true)
					;update initial map to be the stationary context overwritten by the provided initial values
					initial_features_map
						(append
							(if has_series_context_values
								(zip series_context_features (first series_context_values))
								(assoc)
							)
							initial_features_map
						)
				))

				;else not initial row
				(assign (assoc use_initial_context_features (false) ))
			)

			;add each new row to series data with all initial context values
			(assign (assoc
				new_row
					(if use_initial_context_features
						(list
							(unzip (append original_context_map initial_features_map) features)
						)

						;overwrite the values in the original_context_map with those from the current series_index in the provided series_context_values
						has_series_context_values
						(list
							(unzip
								(append
									original_context_map
									(zip series_context_features (get series_context_values (+ 1 last_series_index)) )
								)
								features
							)
						)

						;else every row begins as the original context values
						;make a copy of original_context_values, not a referenced copy
						(apply "list" [original_context_values])
					)
			))
			(accum (assoc last_series_index 1 ))

			(if (= (current_index) 0)
				(accum (assoc series_data new_row))

				;else there is a previous_result, accumulate new_row to it
				(if output_details
					(let
						;previous_result is a pair of [series_data, all_influential_cases]
						(assoc accumulated_data (previous_result 1) )
						(assign (assoc
							series_data (append (get accumulated_data "series_data") new_row)
						))
						(if output_details
							(assign (assoc
								series_detail_values_map
									(map
										(lambda
											(get accumulated_data (current_index))
										)
										series_detail_values_map
									)
							))
						)
					)

					;else when not outputting details, previous_result is just the series_data itself
					(assign (assoc series_data (append (previous_result 1) new_row) ))
				)
			)

			(if (size original_derived_context_features)
				(seq
					;if largest max_row_lag is greater than last_series_index, that means at least one context feature
					;cannot be derived because it references a row with a larger lag and hasn't been synthed yet
					;so skip using all such features in derived contexts
					(assign (assoc
						derived_context_features
							(if (> largest_max_row_lag last_series_index)
								;only keep those derived context features whose max_row_lag is less than or equal to last_series_index
								;e.g., if a feature has 10 lags, but it's synthesising row 3 (last_series_index=2), it will only keep lags 1 and 2
								(filter
									(lambda
										(<= (get !featureAttributes (list (current_value 1) "max_row_lag")) last_series_index)
									)
									original_derived_context_features
								)

								;else keep original derived_context_features
								original_derived_context_features
							)
						action_features original_action_features
					))

					(if use_initial_context_features
						(call !DeriveOrGenerateFeatures (assoc
							react_context_features (indices initial_features_map)
							;for initial case, may need to filter out derived context features whose values are already provided
							derived_features
								(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_context_features)
						))

						;else just provide context features and the full list of derived_context_features
						(call !DeriveOrGenerateFeatures (assoc
							react_context_features user_specified_context_features
							derived_features derived_context_features
						))
					)
				)
			)

			;pregenerate unique values for non series id features
			(if has_unique_features
				;generate a map of non-series id unique features -> unique value
				(assign (assoc
					pre_generated_uniques_map
						(call !GenerateUniquesListMap (assoc
							num_reacts 1
							action_features action_features
							context_features all_context_features
							preserve_feature_values preserve_feature_values
						))
				))
			)

			(assign (assoc
				current_case_map (zip features (last series_data))
				react_context_features
					(if (and use_initial_context_features (not continue_series))
						(indices initial_features_map)
						all_context_features
					)
			))

			;if first case of series and using continue_series, start with computed series_progress
			(if (and use_initial_context_features initial_existing_progress)
				(assign (assoc current_case_map (set current_case_map ".series_progress" initial_existing_progress)))
			)

			;filter out action (rate and delta) features that are dependent on lags that were skipped due to referencing rows that have not been synthed yet
			(if (> (size original_derived_context_features) (size derived_context_features))
				(let
					(assoc
						derived_feature_dependent_on_skipped_feature_set
							;get a list of all features that dependend on the skipped derived context features
							;and convert it to a set for fast lookup
							(zip (apply "append"
								;iterate over all skipped features and pull the list of features that depend on each one
								(map
									(lambda (get !sourceToDerivedFeatureMap (current_value)))

									;skipped derived features are those that were in the original list but are not in the current derived context features list
									(filter
										(lambda (not (contains_value derived_context_features (current_value))))
										original_derived_context_features
									)
								)
							))
					)

					;keep only those action features that do not depend on skipped context features
					(assign (assoc
						action_features
							(filter
								(lambda (not (contains_index derived_feature_dependent_on_skipped_feature_set (current_value) )))
								original_action_features
							)
					))
				)
			)

			;modify context features to not include any lag-dependent features whose lag
			;amount is larger the current last_series_index
			(if (< last_series_index largest_max_row_lag)
				(assign (assoc
					react_context_features
						(filter
							(lambda
								(not (< last_series_index (get ts_feature_lag_amount_map (current_value))) )
							)
							react_context_features
						)
				))
			)

			;create a (unique if necessary) series case
			(call !SynthAndDeriveSeriesCase)

			(if track_progress
				(accum (assoc
					total_progress
						;has_series_context_values is the number of series context values, progress the amount to match the number of provided contexts
						(if has_series_context_values
							(/ 1 has_series_context_values)

							;else progress the synthed amount
							(get current_case_map ".series_progress_delta")
						)
				))
			)

			;if this is the first row of the series, assign values for the replacement series ids here, now that the initial value is available
			(if first_generated_row
				(assign (assoc
					replacement_id_values_map
						(map
							(lambda
								;generate new unique value
								(if output_new_series_ids
									(call !GenerateInt64String)

									;else grab the value from this first series row
									(get current_case_map (current_index))
								)
							)
							replacement_id_values_map
						)
					first_generated_row (false)
				))
			)

			;Check every case to see if we've generated a terminator value
			(if series_has_terminators
				(let
					(assoc
						series_end_context_features (indices (filter (remove current_case_map ".series_progress")))
					)

					;predict .series_progress given the current case
					(declare (assoc
						series_progress
							(first (get
								(call !SingleReact (assoc
									context_features series_end_context_features
									context_values (unzip current_case_map series_end_context_features)
									action_features (list ".series_progress")
									;do not derive anything during this react
									derived_action_features (list)
									derived_context_features (list)
									;no details
									details (null)
									ignore_case ignore_case
									substitute_output substitute_output
									input_is_substituted input_is_substituted
									use_case_weights use_case_weights
									weight_feature weight_feature
									rand_seed rand_seed
									leave_case_out leave_case_out
									holdout_queries holdout_queries

									desired_conviction desired_conviction
									use_regional_residuals use_regional_residuals
									new_case_threshold new_case_threshold
									feature_bounds_map feature_bounds_map
									generate_new_cases "no"
								))
								"action_values"
							))
					))

					;series_progress >= 1 means we synthed a terminator value, end series immediately
					(if (>= series_progress 1)
						(assign (assoc total_progress 1))

						;else if series must stop on a terminator but it should be ending,
						;prevent it from ending just yet by lowering its total_progress to below 1
						(and stop_on_terminator (>= total_progress 1))
						(assign (assoc total_progress 0.9999999999999999))
					)
				)
			)

			;determine whether to stop generating the series
			;if there's no series_stop_map or exceeded max_series_length, be done
			(if (or
					(>= total_progress 1)
					(= 0 (size series_stop_map))
					(>= last_series_index max_series_length)
				)
				(assign (assoc done (true)))

				(map
					(lambda (seq
						(if (contains_index (current_value) "values")
							(if (contains_value (get (current_value) "values") (get current_case_map (current_index)))
								(assign (assoc done (true)))
							)
						)

						(if (contains_index (current_value) "min")
							(let
								(assoc stop_value (get current_case_map (current_index 1)))

								(if (contains_index !featureDateTimeMap (current_index))
									;convert stop_value to epoch
									(assign (assoc
										stop_value
											(format
												stop_value
												(get !featureDateTimeMap (list (current_index 2) "date_time_format"))
												"number"
												(assoc "locale" (get !featureDateTimeMap (list (current_index 3) "locale")))
												(null)
											)
									))
								)
								(if (>= (get (current_value) "min") stop_value)
									(assign (assoc done (true)))
								)
							)
						)

						(if (contains_index (current_value) "max")
							(let
								(assoc stop_value (get current_case_map (current_index 1)))

								(if (contains_index !featureDateTimeMap (current_index))
									;convert stop_value to epoch
									(assign (assoc
										stop_value
											(format
												stop_value
												(get !featureDateTimeMap (list (current_index 2) "date_time_format"))
												"number"
												(assoc "locale" (get !featureDateTimeMap (list (current_index 3) "locale")))
												(null)
											)
									))
								)
								(if (<= (get (current_value) "max") stop_value)
									(assign (assoc done (true)))
								)
							)
						)
					))
					series_stop_map
				)
			)

			;return series_data so it's stored as previous_result for accumulation in the next iteration of the while loop
			;and explanation details if requested
			(if output_details
				(seq
					(if (contains_index case_detail_values_map "influential_cases")
						(call !NormalizeReactSeriesInfluentialCases)
					)

					;retries holds the amount of times the case was retried. Add 1 to represent generate_attempts
					(if (and (not previous_row_failed) (contains_index case_detail_values_map "generate_attempts"))
						(assign (assoc
								case_detail_values_map
									(set
										case_detail_values_map
										"generate_attempts"
										(+ retries 1)
									)
							))
					)

					;update series_detail_values_map on the last iteration so it can be output when single_react_series returns
					(if done
						(assign (assoc
							series_detail_values_map
								(map
									(lambda
										(if (size (get case_detail_values_map (current_index)))
											(append (current_value) (list (get case_detail_values_map (current_index 1))) )

											;generate_attempts should be a number, so size doesn't work
											(= 0 (get_type (get case_detail_values_map (current_index))))
											(append (current_value) (list (get case_detail_values_map (current_index 1))) )

											;don't append if the case detail value is empty
											(current_value)
										)
									)
									series_detail_values_map
								)
						))
					)

					;store accumulated data into previous_result as an assoc
					(append
						(assoc "series_data" series_data)
						(map
							(lambda
								(append (current_value) (list (get case_detail_values_map (current_index 1))) )
							)
							series_detail_values_map
						)
					)
				)

				;else store into previous_result as just series_data
				series_data
			)
		) ;while loop

		(if (get details "series_uncertainty")
			;do another set of forecasts on trained series that are the same length as this
			;generated series
			; then measure the average error on each time-distance for each feature
			(let
				(assoc
					synth_start_case
						(if num_existing_series_rows
							(get series_data (- num_existing_series_rows 1))

							(first series_data)
						)
					time_feature_index (get feature_index_map !tsTimeFeature)
				)

				(declare (assoc
					time_synthesized
						(-
							(get (last series_data) time_feature_index)
							(get synth_start_case time_feature_index)
						)
				))

				;Get most similar timesteps that have enough time-remaining in their series
				;to forecast far enough to match the length of this forecast
				(declare (assoc
					most_similar_timesteps
						(compute_on_contained_entities (append
							holdout_queries
							(query_nearest_generalized_distance
								(* (get hyperparam_map "k") 3) ;TODO: not this
								features
								synth_start_case
								(get hyperparam_map "featureWeights")
								!queryDistanceTypeMap
								(get hyperparam_map "featureDomainAttributes")
								(get hyperparam_map "featureDeviations")
								(get hyperparam_map "p")
								(get hyperparam_map "dt")
								(if valid_weight_feature weight_feature (null))
								(rand)
								(null) ;radius
								!numericalPrecision
							)
						))
				))

				(declare (assoc
					series_ids_list
						(map (lambda (retrieve_from_entity (current_value) series_id_features))  (indices most_similar_timesteps))
				))

				;for each series a case was sampled from (with repetition)
				;sample the most similar case that has enough time left to forecast
				(assign (assoc
					most_similar_timesteps
						(map
							(lambda
								(let
									(assoc
										id_matching_queries
											(map
												(lambda (query_equals (get series_id_features (current_index)) (current_value)))
												(current_value 1)
											)
									)

									(declare (assoc
										latest_time_for_series
											(-
												(retrieve_from_entity
													(first (contained_entities (append
														holdout_queries
														id_matching_queries
														(query_max !tsTimeFeature 1)
													)))
													!tsTimeFeature
												)
												time_synthesized
											)
									))

									(first (contained_entities (append
										holdout_queries
										id_matching_queries
										;not one of the currently found cases
										(query_not_in_entity_list (filter (target)))
										(query_less_or_equal_to !tsTimeFeature latest_time_for_series)
										(query_nearest_generalized_distance
											1
											features
											synth_start_case
											(get hyperparam_map "featureWeights")
											!queryDistanceTypeMap
											(get hyperparam_map "featureDomainAttributes")
											(get hyperparam_map "featureDeviations")
											(get hyperparam_map "p")
											(get hyperparam_map "dt")
											(if valid_weight_feature weight_feature (null))
											(rand)
											(null) ;radius
											!numericalPrecision
										)
									)))
								)
							)
							series_ids_list
						)
				))


				;Forecast from each of these timesteps at least 'time_synthesized'
				(+ 23.4)
			)
		)

		;grab the list of column indices corresponding to all the output_features
		(declare (assoc
			action_feature_indices (unzip feature_index_map output_features)
			non_tracked_series_ids (list)
			;if outputting non-tracked ids, only output those that are explicitly listed in output_features and filter out the rest
			series_id_features_for_output
				(if has_non_tracked_ids
					(filter
						(lambda (contains_value output_features (current_value)))
						(get !tsFeaturesMap "series_id_features")
					)
				)
		))

		;if need to update/replace id values, for each id, update all the rows and set updated value for each id feature
		(if (size replacement_id_values_map)
			(assign (assoc
				series_data
					(map
						(lambda
							(unzip
								(append
									(zip features (current_value))
									replacement_id_values_map
								)
								features
							)
						)
						series_data
					)
			))

			;else series_id_tracking="no", we'll need to create series id values to append to series below
			has_non_tracked_ids
			(let
				(assoc
					valid_weight_feature (and use_case_weights (or !hasPopulatedCaseWeight (!= weight_feature ".case_weight")))
				)
				;iterate over all series id features and create (or pick) an id value for it
				(assign (assoc
					non_tracked_series_ids
						(map
							(lambda
								(if output_new_series_ids
									(call !GenerateInt64String)

									;else pick a random value for this id feature from the dataset by randomly sampling a case
									(retrieve_from_entity
										(first
											(compute_on_contained_entities (list
												(query_not_equals (current_value 1) (null))
												(query_sample 1 (if valid_weight_feature weight_feature) (rand))
											))
										)
										(current_value)
									)
								)
							)
							series_id_features_for_output
						)
				))
			)
		)

		;if output_features specified a non-tracked series id feature, its action feature index will be null because the values are appended
		;here at the end of the flow prior to output. Replace these nulls with their corresponding feature indices.
		(if (size non_tracked_series_ids)
			(let
				(assoc
					max_index (size features)
					tail_series_id_indices (list)
				)

				;append non tracked ids at the end of each row in series_data
				(assign (assoc
					series_data
						(map
							(lambda (append (current_value) non_tracked_series_ids))
							series_data
						)
					;list of indices corresponding to the series_ids that were appended above to the row of feature values
					;e.g., if there were 2 ids appended to o list of 10 values, this creates: (list 10 11)
					tail_series_id_indices (range max_index (+ max_index (size non_tracked_series_ids) -1))
				))

				;action_feature_indices have nulls when output_features specify non-tracked ids.
				;in those cases we replace these nulls with their corresponding feature indices
				(if (contains_value action_feature_indices (null))
					(let
						(assoc series_id_feature_to_index_map (zip series_id_features_for_output tail_series_id_indices))
						(assign (assoc
							action_feature_indices
								(map
									(lambda
										(if (= (null) (current_value))
											(get series_id_feature_to_index_map (get output_features (current_index)))
											(current_value)
										)
									)
									action_feature_indices
								)
						))
					)

					;else assign indices to be at the end correspondingly
					(assign (assoc action_feature_indices (append action_feature_indices tail_series_id_indices) ))
				)
			)
		)

		(if (and output_details (contains_index series_detail_values_map "categorical_action_probabilities"))
			(let
				(assoc
					series_len (size (get series_detail_values_map "categorical_action_probabilities"))
					aggregated_cap_map
						(reduce
							(lambda
								;iterate over each feature in the aggregated and current assoc
								(map
									(lambda
										;iterate over each class and sum up the probabilities for each class
										(map
											(lambda (+
												;if one of the assocs has a key that the other does not, ensure the values
												;do not sum up to a nan by OR-ing each value to convert any nulls to 0s
												(or (first (current_value))  )
												(or (last (current_value)) )
											))
											(first (current_value))
											(last (current_value))
										)
									)
									(previous_result)
									(current_value)
								)
							)
							(get series_detail_values_map "categorical_action_probabilities")
						)
				)

				;normalize the aggregated caps by the series length to output a single assoc for the entire series
				(declare (assoc
					aggregated_categorical_action_probabilities
						(map
							(lambda (map
								(lambda (/ (current_value) series_len))
								(current_value)
							))
							aggregated_cap_map
						)
				))

				(assign (assoc
					series_detail_values_map
						(append
							series_detail_values_map
							(assoc
								"aggregated_categorical_action_probabilities"
									(if aggregated_categorical_action_probabilities aggregated_categorical_action_probabilities [])
							)
						)
				))
			)
		)

		(if (and output_details (contains_index series_detail_values_map "generate_attempts"))
			;append the amount of series_generate_attempts+1 (series_generate_attempts is zero based)
			(assign (assoc
				series_detail_values_map
					(append series_detail_values_map (assoc "series_generate_attempts" (+ series_generate_attempts 1) ))
			))
		)


		;output the series data
		(assoc
			"payload"
				(append
					(assoc
						"action_values"
							;iterate over all the series data and return only the columns corresponding to action_features
							(map
								(lambda (unzip (current_value) action_feature_indices))
								;if there were existing series rows, do not include them in the output
								(if num_existing_series_rows
									(tail series_data (- num_existing_series_rows))
									series_data
								)
							)
						;ensure features are output in the payload
						"action_features" output_features
					)
					(if output_details
						series_detail_values_map
						(assoc)
					)
				)
			"warnings" (if (size warnings) (indices warnings))
		)
	)

	;Helper method from ReactSeries to prepare and properly populate series_data when continuing a series
	#!PrepContinueReactSeries
	(let
		(assoc
			series_id_features
				(if (size series_id_features)
					series_id_features
					(get !tsFeaturesMap "series_id_features")
				)
			id_values_map (assoc)
			existing_series_cases (list)
		)

		;if all series end on terminators and this react is not conditioned to start at a specific time step,
		;stop this react series since it can't continue terminated series
		(if
			(and
				stop_on_terminator
				series_has_terminators
				(not (contains_index initial_features_map !tsTimeFeature))
				;don't terminate a provided untrained continuing series
				(= 0 (size series_context_values))
			)
			(seq
				(accum (assoc warnings (assoc "Can't continue terminated series.") ))
				;immediately stop this series since it's terminated
				(conclude (conclude
					(assoc
						"payload"
							(assoc
								"action_values" (null)
								"action_features" output_features
							)
						"warnings" (if (size warnings) (indices warnings))
					)
				))
			)
		)

		;if user has provided series data to continue, populate series_data with the provided values
		(if (size series_context_values)
			(let
				(assoc
					feature_order
						(unzip
							(zip series_context_features (indices series_context_features))
							features
						)
				)
				;set series_data matrix to match features
				(assign (assoc
					series_data
						(map
							(lambda (unzip (current_value) feature_order))
							series_context_values
						)
				))

				;figure out how many total rows are needed given needed lags of the provided continue series data
				(declare (assoc
					necessary_total_rows
						(apply "max"
							;grab all the lag values corresponding to features with values from the last row
							(unzip
								ts_feature_lag_amount_map
								;keep only those features with values from the last row
								(indices (filter (zip features (last series_data))) )
							)
						)
				))
				;prepend nulls if user hasn't provided enough previous rows to account for necessary lags
				(if (> necessary_total_rows (size series_data))
					(assign (assoc
						series_data
							(append
								(map
									(lambda (range (lambda (null)) 1 (size features) 1) )
									(range 1 (- necessary_total_rows (size series_data)))
								)
								series_data
							)
					))
				)

				(assign (assoc
					;update last_series_index to the index of the last row in the series
					last_series_index (- (size series_data) 1)
					num_existing_series_rows (size series_data)
				))
			)

			;else user has not specified untrained data, must select the data of a trained series using series_id_values
			(seq
				;populate an assoc of id feature -> value, if conditioned on a series, otherwise select a random series
				(assign (assoc id_values_map (zip series_id_features series_id_values) ))

				;pull the necessary number of cases from the series
				(assign (assoc
					existing_series_cases
						(call !RetrieveTrainedSeriesData (assoc
							id_values_map id_values_map
							num_cases_needed largest_max_row_lag
							exclusive_upper_time_bound
								;if an initial time value is provided, limit existing series cases to those before the specified initial time
								(if (contains_index initial_features_map !tsTimeFeature)
									(if (contains_index !featureDateTimeMap !tsTimeFeature)
										(call !ConvertDateToEpoch (assoc
											date (get initial_features_map !tsTimeFeature)
											feature !tsTimeFeature
										))

										(get initial_features_map !tsTimeFeature)
									)
								)
						))
				))

				(if (= (size existing_series_cases) 0)
					(accum (assoc
						warnings
							(associate (concat
								"There is no series trained with the set of IDs:\n"
								(apply "concat" (values (map (lambda (concat (current_index) ": " (current_value) "\n")) id_values_map)))
							))
					))
				)

				;if there is more than one existing series case, we'll need to sort them by the time feature to ensure ascending order
				(if (> largest_max_row_lag 1)
					(assign (assoc
						existing_series_cases
							(sort
								(lambda (> (retrieve_from_entity (current_value) !tsTimeFeature) (retrieve_from_entity (current_value 1) !tsTimeFeature)) )
								existing_series_cases
							)
					))
				)

				;set initial series_data to all the feature values from existing series cases
				(assign (assoc
					series_data
						(map
							(lambda
								(call !ConvertToOutput (assoc
									features features
									feature_values (retrieve_from_entity (current_value 1) features)
								))
							)
							existing_series_cases
						)
					;update last_series_index to the index of the last row in the series
					last_series_index (- (size existing_series_cases) 1)
					num_existing_series_rows (size existing_series_cases)
				))

			)
		)

		;increase the max_series_length by the amount of pre-pended data so the series ends
		;after the correct maximum amount of rows is generated
		(if (size series_data)
			(accum (assoc max_series_length (size series_data) ))
		)

		;if end condition is not specified, generate progress based on where series is continuing from
		(if (not (contains_index series_stop_map !tsTimeFeature))
			;if there are previous cases to continue from, generate a progress value given the values from the last case
			(if (size (last series_data))
				(let
					(assoc
						initial_progress_context_features
							(let
								(assoc
									time_delta_feature_name (concat "." !tsTimeFeature "_delta_1")
									time_lag_feature_name (concat "." !tsTimeFeature "_lag_1")
								)
								;use all value, delta, and rate features to determine initial series progress
								;exclude time feature (and its derived features)
								(append
									;derived action features that are not the time feature
									(filter (lambda (!= !tsTimeFeature (current_value))) derived_action_features)
									;non-time-deltas that are populated based on last series index
									(filter
										(lambda (and
											(!= time_delta_feature_name (current_value))
											(or
												;the "root" lag/delta features are in "delta_features" as well
												;but have no ts_order defined
												(not (contains_index (get !featureAttributes (current_value)) "ts_order"))
												(<= (get ts_feature_lag_amount_map (current_value)) last_series_index)
											)
											(contains_value features (current_value))
										))
										(get !tsFeaturesMap "delta_features")
									)
									;non-time-lags that are populated based on last series index
									(filter
										(lambda (and
											(!= time_lag_feature_name (current_value))
											(<= (get ts_feature_lag_amount_map (current_value)) last_series_index)
											(contains_value features (current_value))
										))
										(get !tsFeaturesMap "lag_features")
									)
									;rates that are populated based on last series index
									(filter
										(lambda (and
											(<= (get ts_feature_lag_amount_map (current_value)) last_series_index)
											(contains_value features (current_value))
										))
										(get !tsFeaturesMap "rate_features")
									)
								)
							)
					)

					(assign (assoc
						initial_existing_progress
							(first (get
								(call !SingleReact (assoc
									context_features initial_progress_context_features
									context_values (unzip (zip features (last series_data)) initial_progress_context_features )
									action_features (list ".series_progress")
									;do not derive anything during this react
									derived_action_features (list)
									derived_context_features (list)
									;no details
									details (null)
									;prevent overvaluing the progress of case from the original sourced series by ignoring it
									ignore_case (last existing_series_cases)
									substitute_output substitute_output
									input_is_substituted input_is_substituted
									use_case_weights use_case_weights
									weight_feature weight_feature
									rand_seed rand_seed
									holdout_queries holdout_queries

									desired_conviction desired_conviction
									use_regional_residuals use_regional_residuals
									new_case_threshold new_case_threshold
									feature_bounds_map feature_bounds_map
									generate_new_cases "no"
								))
								"action_values"
							))
					))
					(assign (assoc
						total_progress initial_existing_progress
						track_progress (true)
					))
					(if (contains_index initial_features_map ".series_progress")
						(assign (assoc
							initial_features_map (set initial_features_map ".series_progress" initial_existing_progress)
						))
					)
				)
			)
		)
	)

	#!RetrieveTrainedSeriesData
	;params:
	;  id_values_map: assoc of series id feature name to id value
	;  exclusive_upper_time_bound: an upper bound time value that all retrieved cases must be before chronologically
	;  num_cases_needed: the number of cases to retrieve
	(contained_entities (append
		(map
			(lambda (query_equals (current_value) (get id_values_map (current_value))))
			(indices id_values_map)
		)
		;if a lower bound for time is provided, limit existing series cases to those before the specified initial time
		(if exclusive_upper_time_bound
			(list
				;using both query_less_or_equal_to and query_not_equals is same effect as 'query less than'
				(query_less_or_equal_to !tsTimeFeature exclusive_upper_time_bound)
				(query_not_equals  !tsTimeFeature exclusive_upper_time_bound)
			)
			(list)
		)
		;select the necessary count of previous cases to reference lags
		(query_max !tsTimeFeature num_cases_needed)
	))


	;Helper method for ReactSeries that synthesises action_features and derives derived_action_features to create a series case
	;and then tests it for uniqueness and retries as necessary until a unique case is created
	#!SynthAndDeriveSeriesCase
	(while do_uniqueness_check

		(assign (assoc
			max_order
				(apply "max"
					(map (lambda (get !featureAttributes [(current_value 1) "ts_order"])) action_features)
				)
		))

		;rate and delta features must not synth nulls at the start of a series where they are always nulls due to
		;not having previous data, allowing other features such as value lags and time lags to determine whether the
		;resulting value will output a value or a null.  If these rates/deltas were to remain null, the resulting value
		;would either be null or be generated without being conditioned properly resulting in unpredictable values being output.
		(assign (assoc
			modified_feature_bounds_map
				;force non null
				(if (< last_series_index max_order)
					(if (size feature_bounds_map)
						(append
							feature_bounds_map
							(zip
								action_features
								(map
									(lambda (let
										(assoc action_feature (get action_features (current_index 1)) )
										;only set allow_null to false for features that have a higher order than the series index
										(if (> (get !featureAttributes [action_feature "ts_order"]) last_series_index)
											;if there is a feature bound specified for this action feature, overwrite it
											(if (current_value)
												(set (current_value) "allow_null" (false))

												;else pull the bounds from !featureBoundsMap and overwrite those
												(set (or (get !featureBoundsMap action_feature) {}) "allow_null" (false) )
											)

											;else leave it as-is
											(current_value)
										)
									)
									(unzip feature_bounds_map action_features)
								))
							)
						)

						(filter (map
							(lambda
								(if (> (get !featureAttributes [(current_index 1) "ts_order"]) last_series_index)
									(set (or (get !featureBoundsMap (current_index)) {}) "allow_null" (false) )
								)
							)
							(zip action_features)
						))
					)

					;else synthing data for the rest of the cases in a series, don't allow nulls for features that have no nulls
					(let
						(assoc
							explicit_no_null_features
								(filter
									(lambda (or
										(= (false) (get !featureNullRatiosMap [(current_value 1) "has_nulls"]))
										;rate or delta feature whose 'parent' feature has no nulls
										(= (false) (get !featureNullRatiosMap [(get !derivedFeaturesMap (current_value 1)) "has_nulls"]))
									))
									action_features
								)
						)
						(if (size feature_bounds_map)
							(append
								feature_bounds_map
								(zip
									explicit_no_null_features
									(map
										(lambda
											(set
												(or (get feature_bounds_map (current_value)) {})
												"allow_null"
												(false)
											)
										)
										explicit_no_null_features
									)
								)
							)

							(map
								(lambda
									(set
										(or (get !featureBoundsMap (current_index)) {})
										"allow_null"
										(false)
									)
								)
								(zip explicit_no_null_features)
							)
						)
					)
				)
		))

		(assign (assoc
			react_output
				(call !SingleReact (assoc
					context_features react_context_features
					context_values (unzip current_case_map react_context_features)
					action_features action_features
					;do not derive anything during this react
					derived_action_features (list)
					derived_context_features (list)
					details (if output_details details)
					extra_features (append (if extra_features extra_features []) derived_action_features)
					substitute_output substitute_output
					input_is_substituted input_is_substituted
					use_case_weights use_case_weights
					weight_feature weight_feature
					rand_seed rand_seed

					desired_conviction desired_conviction
					use_regional_residuals use_regional_residuals
					feature_bounds_map
						(if modified_feature_bounds_map
							modified_feature_bounds_map
							feature_bounds_map
						)
					goal_features_map goal_features_map
					ordered_by_specified_features ordered_by_specified_features
					exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
					generate_new_cases "no"
					preserve_feature_values preserve_feature_values
					new_case_threshold new_case_threshold
					pre_generated_uniques_map pre_generated_uniques_map
					holdout_queries holdout_queries
				))
		))

		;overwrite the values for the action features in the current case map now that they have values
		(accum (assoc current_case_map (zip action_features (get react_output "action_values")) ))

		(if (size (keep feature_post_process_code_map action_features))
			;if any of the action features have a custom post_process, update their values using them
			(accum (assoc
				current_case_map
					(map
						(lambda
							(get_value
								(call_sandboxed (current_value) (assoc
									series_data
										;need to use series_data with the updated feature value
										(append
											(trunc series_data)
											[(unzip current_case_map features)]
										)
									series_row_index last_series_index
									feature_index_map feature_index_map
									!featureDateTimeMap !featureDateTimeMap
									!ConvertDateToEpoch !ConvertDateToEpoch
								) (* (size series_data) !sandboxedComputeLimit) !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit (false))
							)
						)
						(keep feature_post_process_code_map action_features)
					)
			))
		)

		;overwrite the last row in series data with the values from the updated current case
		(assign (assoc
			series_data
				(append
					(trunc series_data)
					[(unzip current_case_map features)]
				)
		))

		(if output_details
			(assign (assoc
				case_detail_values_map
					(map
						(lambda
							(append (current_value) (get react_output (current_index)))
						)
						case_detail_values_map
					)
			))
		)

		(if (size derived_action_features)
			(let
				(assoc
					derivation_failed
						(call !DeriveOrGenerateFeatures (assoc
							;create a list of context features with action_features with no dupes since we have action_values for action_features
							react_context_features (values (append react_context_features action_features) (true))
							derived_features
								;for initial case, may need to filter out derived action features whose values are already provided
								(if use_initial_context_features
									(filter (lambda (not (contains_index initial_features_map (current_value)))) derived_action_features)
									;else use all derived_action_features
									derived_action_features
								)
						))
				)

				;stop generating series if derivation_failed due to time feature being past max boundary;
				;remove current (last) row and stop
				(if derivation_failed
					(assign (assoc
						previous_row_failed (true)
						series_data (trunc series_data)
						case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
						done (true)
					))
				)
			)
		)

		(assign (assoc current_case_map (zip features (last series_data)) ))

		;unique test
		(if (and (not done) (!= "no" generate_new_cases) )
			(let
				(assoc
					dupe
						(call !CheckIsDuplicateSeries (assoc
							context_values (unzip current_case_map output_features_no_ids)
							context_features output_features_no_ids
							exclude_novel_nominals_from_uniqueness_check exclude_novel_nominals_from_uniqueness_check
						))
				)

				;if initial_features_map contains all the output_features that are used for uniqueness test this means the first case is
				;explicitly conditioned to output these initial values and they do not need to be checked for uniqueness
				(if (and dupe use_initial_context_features)
					(if (=
							(size (remove initial_features_map output_features_no_ids))
							(- (size initial_features_map) (size output_features_no_ids))
						)
						(assign (assoc dupe (false)))
					)
				)

				(if (not dupe)
					(assign (assoc do_uniqueness_check (false) ))

					;else duplicate case, retry to synth and derive a new case
					(seq
						(accum (assoc retries 1))

						;lower desired_conviction every 3 retries by a factor of 2
						(if (= 0 (mod retries 3))
							(assign (assoc desired_conviction (/ desired_conviction  2) ))
						)

						;failed to synth a unique series, stop retrying
						(if (> retries 15)
							(seq
								(assign (assoc do_uniqueness_check (false) ))

								;failed to synth series, regenerate entire series if able to
								(if regenerate_series
									(seq
										(accum (assoc series_generate_attempts 1))

										;after 4 full-series retries, remove current (last) row and stop
										(if (> series_generate_attempts 4)
											(assign (assoc
												done (true)
												series_data (trunc series_data)
												;reset case detail values
												case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
											))

											;else reset series_data and initial features and progress and index, to regenerate the series from the start
											(seq
												(call !InitializeInitialSeriesFeatures)

												;if there were existing rows, reset to just those existing rows
												(if num_existing_series_rows
													(assign (assoc
														total_progress initial_existing_progress
														series_data (trunc series_data num_existing_series_rows)
														last_series_index (- num_existing_series_rows 1)
														first_generated_row (true)
														current_case_map (assoc)
														;reset case detail values
														case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
													))

													(assign (assoc
														total_progress 0
														series_data (list)
														last_series_index -1
														first_generated_row (true)
														current_case_map (assoc)
														;reset case detail values
														case_detail_values_map (call !CreateCaseDetailValuesMapFromDetails (assoc details requested_details))
													))
												)
											)
										)
									)
								)
							)
						)
					)
				)
			)

			;else don't check for uniqueness if it's not necessary
			(assign (assoc do_uniqueness_check (false) ))
		)
	)
)