;Contains methods for hyperparameter analysis of feature and case weights and feature deviation calculations.
(null

	;updates baseline_hyperparameter_map
	;calculate feature residuals several times to converge on stable deviation values
	#!ConvergeResiduals
	(declare
		(assoc
			num_samples num_deviation_samples
			num_iterations 3
			use_deviations .false

			;not a parameter
			iteration 0
			resdiuals (assoc)
		)

		(declare (assoc
			features (values (append context_features action_features) .true)

			;pair of: residuals_map and ordinal_residuals_map
			residuals_map (list)
		))

		;possibly increase the number of samples if nominals are present
		(if (and !tsTimeFeature (size !sharedDeviationsMap))
			(assign (assoc num_samples (call !ComputeRequiredNumSamplesForSharedDeviationsWithTS (assoc desired_samples_per_feature num_samples)) ))
		)

		(while (< iteration num_iterations)
			(assign (assoc
				residuals_map
					(call !ExpandResidualValuesToUncertainty (assoc
						using_shared_deviations .true
						feature_residuals_map
							(call !CalculateFeatureResiduals (assoc
								features features
								robust_residuals .false
								hyperparameter_feature action_feature
								num_samples
									;for robust the first iteration needs just enough to run a few samples for each feature to establish some reasonable value
									(if (and robust_residuals (= 0 iteration))
										(min num_samples (* 10 (size features)))

										;on the last iteration use the larger of 1000 or the specified samples to attain more accurate residuals
										(= (- num_iterations 1) iteration)
										(max num_samples 1000)

										;use less samples for initial runs simply to establish some reasonable values
										(/ num_samples 4)
									)
								custom_hyperparam_map baseline_hyperparameter_map
								;must compute confusion matrix to use sparse deviation matrix
								compute_all_statistics (and use_sdm use_deviations)
								;don't sparsify the confusion matrix so that SDM can be computed using full counts
								confusion_matrix_min_count 0
								use_shared_deviations .true
								;don't create copies of confusion matrices for non-primary shared deviation features
								expand_confusion_matrices .false
							))
					))
			))

			(call !UpdateHyperparameters (assoc
				feature_deviations (get residuals_map "residual_map")
				confusion_matrix_map (if use_deviations (get residuals_map (list "prediction_stats" "confusion_matrix")) )
				ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
				null_deviations (get residuals_map "null_uncertainty_map")
				use_deviations use_deviations
			))

			(accum (assoc iteration 1))

			;should store if needed for deviations or IRW feature weights
			(if (and use_dynamic_deviations  use_deviations  !useDynamicDeviationsDuringAnalyze)
				; store feature residuals for a collection of cases at end, if it wasn't part of iterative process
				(call !StoreResidualSubTrainee (assoc custom_hyperparam_map baseline_hyperparameter_map) )
			)
		)
	)

	;updates baseline_hyperparameter_map
	;wrapper method to compute context feature weights for a specified action_feature and update baseline_hyperparameter_map with those weights
	#!ComputeAndUseWeights
	(let
		;compute an assoc of feature -> weight for the action_feature
		(assoc
			weights_map
				(call !ComputeActionFeatureWeights (assoc
					action_feature action_feature
					context_features
						;ensure context_features don't have the action_feature in it
						(filter
							(lambda (!= action_feature (current_value)) )
							context_features
						)
					use_case_weights use_case_weights
					weight_feature weight_feature
					hyperparam_map baseline_hyperparameter_map
				))
		)

		;store the computed feature weights into baseline_hyperparameter_map
		(accum (assoc baseline_hyperparameter_map (assoc "featureWeights" weights_map) ))
	)

	;outputs weights_map for as action_feature for specified context_features
	#!ComputeActionFeatureWeights
	(declare
		(assoc
			action_feature (null)
			context_features (list)
			weight_feature ".case_weight"
			use_case_weights .false
			hyperparam_map (null)
		)

		;if user doesn't want to use case weights, change weight_feature to '.none'
		(if (not use_case_weights)
			(assign (assoc weight_feature ".none"))
		)

		;mda for each context feature as a ratio of error_with_feature_removed / baseline_error (where baseline uses all the context features)
		(declare (assoc
			context_features_mda_map
				(call !CalculateFeatureAccuracyContributions (assoc
					context_features context_features
					action_features (list action_feature)
					output_ratio .true
					use_case_weights use_case_weights
					weight_feature weight_feature
					hyperparam_map hyperparam_map
				))
		))

		;if baseline accuracy was 100% (MAE was 0), the ratios will be infinities (divided by 0), so set all weights to 1
		(if (contains_value context_features_mda_map .infinity)
			(conclude
				;if MDA was calculated using feature weights, return those exact weights since they result in a perfect score
				(if (get hyperparam_map "featureWeights")
					;only return the weights for the requested context_features
					(keep (get hyperparam_map "featureWeights") context_features)

					;else return 1 for all weights since we can't get any better score using all the context fetaures
					(map
						(lambda 1)
						context_features_mda_map
					)
				)
			)
		)

		(declare (assoc
			good_features_mda_map (filter (lambda (> (current_value) 1)) context_features_mda_map)
			weights_map (filter (lambda (<= (current_value) 1)) context_features_mda_map)
		))

		;find the max and the range for the max mda values
		(declare (assoc mda_max (apply "max" (values context_features_mda_map))))
		(declare (assoc
			mda_good_range (- mda_max 1)
			;if the MDA ratio for a feature happens to be higher than the number of features, we use that, otherwise
			;the maximum value for a feature weight will be set to the number of features (i.e. if there are 5 features, the largest weight will
			;be 5.  Since the normalized good values are 0-based, we subtract 1 because it'll be added on later
			num_features (- (max mda_max (size context_features_mda_map)) 1)
		))

		(declare (assoc
			normalized_map
				;handle extreme edge case of all ratio values being 1, resulting in a range of 0
				(if (= 0 mda_good_range)
					(map (lambda 1) good_features_mda_map)

					;else normalize all positive values
					(map
						(lambda
							(/ (- (current_value) 1) mda_good_range)
						)
						good_features_mda_map
					)
				)
		))

		;transform normalized values to be relative to max(value, num_features) + 1 (add 1 since normalized values are 0-based)
		(accum (assoc
			weights_map
				(append
					(associate action_feature 1)
					(map
						(lambda
							(+ 1 (* (current_value) num_features))
						)
						normalized_map
					)
				)
		))

		(if !inactiveFeaturesMap
			(accum (assoc weights_map (map 0 !inactiveFeaturesMap) ))
		)

		;output weights map
		weights_map
	)

	;helper function for the residuals computing methods used within Analysis (ConvergeResiduals and ConvergeTargetless)
	;estimates the number of samples necessary to allow for the correct amount of samples for a feature to be predicted
	;across all of its features that share deviations
	;parameters:
	; desired_samples_per_feature: the number of samples desired for each feature
	#!ComputeRequiredNumSamplesForSharedDeviationsWithTS
	(let
		(assoc
			;map of the desired samples per feature multiplied by the number of features in each shared deviation group
			desired_non_null_samples_per_group
				(map
					(lambda (* desired_samples_per_feature (size (current_value))) )
					(keep !sharedDeviationGroupByPrimaryMap features)
				)
		)

		(declare (assoc
			sample_cases
				(contained_entities
					(query_exists !internalLabelSession)
					(query_sample 1000 (if use_case_weights weight_feature))
				)
		))

		;take a sample of 1000 cases and get the average number of non_null values for features in each shared deviation group
		(declare (assoc
			avg_non_null_values_per_case_per_group
				(map
					(lambda
						(/
							;ensure at least 50 to prevent divide by zero and limit max amount of samples computed below to a reasonable amount
							(max
								50
								(apply "+"
									(map
										(lambda
											;the number of non-null values in the case of features in the shared deviation group
											;(current_value) is case id, (current_value 1) is the list of features in the SD group
											(size (filter (retrieve_from_entity (current_value) (current_value 1))))
										)
										sample_cases
									)
								)
							)
							1000
						)
					)
					(keep !sharedDeviationGroupByPrimaryMap features)
				)
		))

		(declare (assoc
			est_needed_samples_per_group
				(map
					(lambda
						(ceil (/
							(current_value)
							(get avg_non_null_values_per_case_per_group (current_index))
						))
					)
					desired_non_null_samples_per_group
				)
		))

		;return the max of the amount given or the maximum estimated samples needed across any
		;of the shared deviations group
		(max desired_samples_per_feature (apply "max" (values est_needed_samples_per_group)))
	)


	;output initial deviations to be the smallest gaps for each feature scaled by the number of features
	#!ComputeInitialDeviations
	(let
		(assoc all_features (values (append context_features action_features) .true))
		(map
			(lambda (/ (current_value) (size all_features)))
			(call !CalculateSmallestFeatureGap (assoc features all_features))
		)
	)

	;updates analyzed_hp_map
	;run multiple iterations of grid search and residuals
	#!ConvergeTargetless
	(declare
		(assoc
			;don't need to do the last iteration if running reduce_only flow
			num_iterations (if reduce_only 3 4)
			iteration 0
			hyperparam_map (assoc)
		)

		(set_rand_seed sampling_random_seed)

		(call !UpdateHyperparameters (assoc use_deviations .true ))

		(declare (assoc
			features context_features
			residuals_map (list)
			computing_mda .false
		))

		;possibly increase the number of samples if nominals are present
		(if (and !tsTimeFeature (size !sharedDeviationsMap))
			(assign (assoc
				num_feature_probability_samples
					(max
						num_feature_probability_samples
						(call !ComputeRequiredNumSamplesForSharedDeviationsWithTS (assoc desired_samples_per_feature (/ num_feature_probability_samples 4)))
					)
			))
		)

		;when calculating IRW and LK deviations, compute the initial residual values if necessary
		(if (= (null) initial_residual_values_map)
			(assign (assoc
				initial_residual_values_map
					#!ComputeInitialResiduals
					(map
						(lambda
							;for nominals, random chance of getting a prediction wrong is: 1 - 1/num_classes
							;set initial value to (1 - 1/num_classes) / 2
							(if (contains_index !nominalsMap (current_index))
								(-
									0.5
									;pull number of classes for this feature corresponding to the weight_feature being used during this analyze
									(/ 0.5 (or (size (get !nominalClassProbabilitiesMap [weight_feature (current_index 1)]))) 2)
								)

								;else continuous values
								(let
									(assoc
										max_gap
											;edit distance features, use max length: size for strings, or total_size for code
											(if (contains_index !editDistanceFeatureTypesMap (current_index 1))
												(let
													(assoc edit_dist_feature (current_index 2) )
													(declare (assoc
														feature_values
															(filter (map
																(lambda (retrieve_from_entity (current_value) edit_dist_feature))
																(call !AllCases)
															))
													))

													(if (or
															(= "string" (get !editDistanceFeatureTypesMap edit_dist_feature))
															(= "string_mixable" (get !editDistanceFeatureTypesMap edit_dist_feature))
														)
														(apply "max" (map (lambda (size (current_value))) feature_values))

														(apply "max" (map (lambda (total_size (current_value))) feature_values))
													)
												)

												;else normal continuous feature, pull cached max gap
												(get !cachedFeatureMaxGapMap (current_index 1))
											)
										min_gap
											(if (contains_index !editDistanceFeatureTypesMap (current_index 1))
												0

												(compute_on_contained_entities
													(query_min_difference (current_index 1) (get !cyclicFeaturesMap (current_index 1)) )
												)
											)
										;pull from cached marginal stats
										num_buckets (get !featureMarginalStatsMap [weight_feature (current_index 2) "uniques"])
										num_values (get !featureMarginalStatsMap [weight_feature (current_index 2) "count"])
									)

									;infinity means there was no gap, and nan means all values are null and can't compute gap
									(if (or (= (null) min_gap) (= .infinity min_gap) (= .infinity max_gap))
										1

										;use the smaller of of max_gap * (1 - 1/num_buckets) or
										;(average of max_gap/2 and min_gap/2) * sqrt(avg_num_values_per_bucket)
										(min
											(* max_gap (- 1 (/ 1 num_buckets)) )
											(*
												(sqrt (/ num_values num_buckets))
												(/ (+ (/ max_gap 2) (/ min_gap 2)) 2)
											)
										)
									)
								)
							)

						)
						(zip features)
					)
			))
		)

		(declare (assoc in_analyze .true ))

		;First pass uses inverse feature gap/2 values as weights to compute hyperparameters that should provide decent results.
		;Second pass uses these decent residuals to finds even better hyperparmeters and improved residuals.
		;Last pass finds usable hyperparams using the improved residuals and then calculates usable residuals for weights.
		;At this point the hyperparameters and residuals and weights are stable enough for use.
		(while (< iteration num_iterations)

			;compute mda on last iteration, but only if not doing a reduce_only analyze
			(assign (assoc
				computing_mda (and (= reduce_only .false) (= iteration (- num_iterations 1)) )
			))

			(assign (assoc
				residuals_map
					(if (= 0 iteration)
						(assoc
							"residual_map" (get_value initial_residual_values_map)
							"ordinal_residual_map"
								(if (size !ordinalFeaturesSet)
									(filter
										(lambda (contains_index !ordinalFeaturesRangesMap (current_index)))
										(get_value initial_residual_values_map)
									)
								)
						)

						(call !ExpandResidualValuesToUncertainty  (assoc
							using_shared_deviations .true
							feature_residuals_map
								(call !CalculateFeatureResiduals (assoc
									features features
									robust_residuals (if computing_mda "robust_mda" "deviations")
									num_samples
										(if computing_mda
											num_feature_probability_samples

											;the deviations query uses all features "superfull", there's no need to sample more
											;than a default amount of 1000
											num_deviation_samples
										)
									custom_hyperparam_map baseline_hyperparameter_map
									;must compute confusion matrix to use sparse deviation matrix, but not when computing mda
									compute_all_statistics (and use_sdm (not computing_mda))
									;don't sparsify the confusion matrix so that SDM can be computed using full counts
									confusion_matrix_min_count 0
									use_shared_deviations .true
									;don't create copies of confusion matrices for non-primary shared deviation features
									expand_confusion_matrices .false
									convergence_threshold convergence_threshold
									convergence_samples_growth_rate convergence_samples_growth_rate
									convergence_min_size convergence_min_size
								))
						))
					)
			))

			(if computing_mda
				(accum (assoc
					baseline_hyperparameter_map (assoc "featureMdaMap" (get residuals_map "feature_mda_map") )
				))

				(call !UpdateHyperparameters (assoc
					feature_deviations (get residuals_map "residual_map")
					confusion_matrix_map (get residuals_map ["prediction_stats" "confusion_matrix"])
					ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
					null_deviations (get residuals_map "null_uncertainty_map")
					use_deviations .true
				))
			)

			(accum (assoc iteration 1))

			(if (and use_dynamic_deviations !useDynamicDeviationsDuringAnalyze)
				; store feature residuals for a collection of cases at end, if it wasn't part of iterative process
				(call !StoreResidualSubTrainee (assoc custom_hyperparam_map baseline_hyperparameter_map) )
			)
		)

	;;;;;;;;;;

	; 	(declare (assoc
	; 		DATA_MAP_deviations1 [] 		;robust_residuals = "deviations" && estimating_residual_lower_bound = false
	; 		DATA_MAP_robust_residuals [] 	;robust_residuals = "robust_mda" && estimating_residual_lower_bound = true
	; 		DATA_MAP_weighted_deviations [] ;robust_residuals = "deviations" && estimating_residual_lower_bound = true
	; 		DATA_MAP_deviations2 [] 		;same as deviations1 and residuals exist?
	; 		DATA_MAP_robust_residuals_mda []  ;robust_residuals = "robust_mda" && estimating_residual_lower_bound = false
	; 		DATA_MAP_reacts []
	; 	))

	; 	;initial residuals
	; 	(assign (assoc
	; 		residuals_map
	; 			(assoc
	; 				"residual_map" (get_value initial_residual_values_map)
	; 				"ordinal_residual_map"
	; 					(if (size !ordinalFeaturesSet)
	; 						(filter
	; 							(lambda (contains_index !ordinalFeaturesRangesMap (current_index)))
	; 							(get_value initial_residual_values_map)
	; 						)
	; 					)
	; 			)
	; 	))
	; 	(call !UpdateHyperparameters (assoc
	; 		feature_deviations (get residuals_map "residual_map")
	; 		ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
	; 		use_deviations .true
	; 	))

	; 	;compute deviations pass 1
	; 	(assign (assoc
	; 		residuals_map
	; 			(call !ExpandResidualValuesToUncertainty  (assoc
	; 				using_shared_deviations .true
	; 				feature_residuals_map
	; 					(call !CalculateFeatureResiduals (assoc
	; 						features features
	; 						robust_residuals "deviations"
	; 						num_samples num_deviation_samples
	; 						custom_hyperparam_map baseline_hyperparameter_map
	; 						;must compute confusion matrix to use sparse deviation matrix, but not when computing mda
	; 						compute_all_statistics (and use_sdm)
	; 						;don't sparsify the confusion matrix so that SDM can be computed using full counts
	; 						confusion_matrix_min_count 0
	; 						use_shared_deviations .true
	; 						;don't create copies of confusion matrices for non-primary shared deviation features
	; 						expand_confusion_matrices .false
	; 						convergence_threshold convergence_threshold
	; 						convergence_samples_growth_rate convergence_samples_growth_rate
	; 						convergence_min_size convergence_min_size
	; 					))
	; 			))
	; 	))
	; 	(call !UpdateHyperparameters (assoc
	; 		feature_deviations (get residuals_map "residual_map")
	; 		confusion_matrix_map (get residuals_map ["prediction_stats" "confusion_matrix"])
	; 		ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
	; 		null_deviations (get residuals_map "null_uncertainty_map")
	; 		use_deviations .true
	; 	))

	; 	;compute robust weighted mda with computed deviations
	; 	(declare (assoc
	; 		feature_mda_map
	; 			(call !CalculateFeatureResiduals (assoc
	; 				features features
	; 				robust_residuals "robust_mda"
	; 				num_samples (min num_feature_probability_samples 10000)
	; 				convergence_threshold 0
	; 				custom_hyperparam_map baseline_hyperparameter_map
	; 				estimating_residual_lower_bound .true
	; 				compute_all_statistics .false
	; 				confusion_matrix_min_count 0
	; 				use_shared_deviations .true
	; 				;don't create copies of confusion matrices for non-primary shared deviation features
	; 				expand_confusion_matrices .false
	; 			))
	; 	))

	; 	;recompute feature deviations using feature weights from the computed robust mda above
	; 	(declare (assoc
	; 		updated_estimated_residuals_map
	; 			(call !ExpandResidualValuesToUncertainty  (assoc
	; 				using_shared_deviations .true
	; 				feature_residuals_map
	; 					(call !CalculateFeatureResiduals (assoc
	; 						features features
	; 						robust_residuals "deviations"
	; 						num_samples num_deviation_samples

	; 						estimating_residual_lower_bound .true
	; 						custom_mda_map (get feature_mda_map "feature_mda_map")
	; 						custom_hyperparam_map baseline_hyperparameter_map

	; 						compute_all_statistics .true
	; 						confusion_matrix_min_count 0
	; 						use_shared_deviations .true
	; 						;don't create copies of confusion matrices for non-primary shared deviation features
	; 						expand_confusion_matrices .false
	; 					))
	; 			))
	; 	))
	; 	;store weighted deviations
	; 	(call !UpdateHyperparameters (assoc
	; 		feature_deviations
	; 			;store the smallest computed residual so far
	; 			(map
	; 				(lambda (min (first (current_value)) (last (current_value))))
	; 				(get updated_estimated_residuals_map "residual_map")
	; 				(get residuals_map "residual_map")
	; 			)
	; ;		confusion_matrix_map (get updated_estimated_residuals_map ["prediction_stats" "confusion_matrix"])
	; ;		ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
	; ;		null_deviations (get residuals_map "null_uncertainty_map")
	; 		use_deviations .true
	; 	))

	; 	;compute deviations pass 2
	; 	(assign (assoc
	; 		residuals_map
	; 			(call !ExpandResidualValuesToUncertainty  (assoc
	; 				using_shared_deviations .true
	; 				feature_residuals_map
	; 					(call !CalculateFeatureResiduals (assoc
	; 						features features
	; 						robust_residuals "deviations"
	; 						num_samples num_deviation_samples
	; 						custom_hyperparam_map baseline_hyperparameter_map
	; 						;must compute confusion matrix to use sparse deviation matrix, but not when computing mda
	; 						compute_all_statistics (and use_sdm )
	; 						;don't sparsify the confusion matrix so that SDM can be computed using full counts
	; 						confusion_matrix_min_count 0
	; 						use_shared_deviations .true
	; 						;don't create copies of confusion matrices for non-primary shared deviation features
	; 						expand_confusion_matrices .false
	; 						convergence_threshold convergence_threshold
	; 						convergence_samples_growth_rate convergence_samples_growth_rate
	; 						convergence_min_size convergence_min_size
	; 					))
	; 			))
	; 	))

	; 	(call !UpdateHyperparameters (assoc
	; 		feature_deviations (get residuals_map "residual_map")
	; 		confusion_matrix_map (get residuals_map ["prediction_stats" "confusion_matrix"])
	; 		ordinal_feature_deviations (get residuals_map "ordinal_residual_map")
	; 		null_deviations (get residuals_map "null_uncertainty_map")
	; 		use_deviations .true
	; 	))


	; 	;compute robust mda weights using smallest deviations
	; 	(assign (assoc
	; 		feature_mda_map
	; 			(call !CalculateFeatureResiduals (assoc
	; 				features features
	; 				robust_residuals "robust_mda"
	; 				num_samples num_feature_probability_samples
	; 				custom_hyperparam_map baseline_hyperparameter_map
	; 				;must compute confusion matrix to use sparse deviation matrix, but not when computing mda
	; 				compute_all_statistics .false
	; 				;don't sparsify the confusion matrix so that SDM can be computed using full counts
	; 				confusion_matrix_min_count 0
	; 				use_shared_deviations .true
	; 				;don't create copies of confusion matrices for non-primary shared deviation features
	; 				expand_confusion_matrices .false
	; 				convergence_threshold convergence_threshold
	; 				convergence_samples_growth_rate convergence_samples_growth_rate
	; 				convergence_min_size convergence_min_size
	; 			))
	; 	))

	; 	(accum (assoc
	; 		baseline_hyperparameter_map (assoc "featureMdaMap" (get feature_mda_map "feature_mda_map") )
	; 	))

	)

	;Compute and store case weights for all cases if there are any rebalance features (e.g., with the id_feature attribute set to true)
	;Each case weights as the reciprocal of the count of the id feature value in the dataset.  If there are multiple
	;rebalance features, the product of the weights of all the rebalance features is the case weight, which is stored
	;in each case into the .case_weight feature
	#!ComputeAndStoreRebalanceFeatureCaseWeights
	(declare
		(assoc rebalance_features [] )

		(if (= 0 (size rebalance_features))
			(conclude)
		)

		;if dataset has ID features, set the !hasPopulatedCaseWeight flag
		(assign_to_entities (assoc !hasPopulatedCaseWeight .true))

		(declare (assoc
			continuous_rebalance_features
				(filter
					(lambda (not (contains_index !nominalsMap (current_value))))
					rebalance_features
				)
			nominal_rebalance_features
				(filter
					(lambda (contains_index !nominalsMap (current_value)))
					rebalance_features
				)
			hyperparameter_map
				(call !GetHyperparameters (assoc
					context_features context_features
					weight_feature weight_feature
				))
			;assoc of case_id -> weight from rebalance features
			case_weights_map (null)
			feature_value_weight_map (null)
		))

		(if (size continuous_rebalance_features)
			(let
				(assoc
					closest_k (get hyperparameter_map "k")
					feature_weights (get hyperparameter_map "featureWeights")
					feature_deviations (get hyperparameter_map "featureDeviations")
					p_value (get hyperparameter_map "p")
					dt_value (if (= (get hyperparameter_map "dt") "surprisal_to_prob") "surprisal" (get hyperparameter_map "dt") )
					query_feature_attributes_map (get hyperparameter_map "featureDomainAttributes")
				)

				;set feature deviations to be inverse of residuals if using surprisal
				(if (and (= 0 (size feature_deviations)) (= "surprisal" dt_value))
					(assign (assoc
						feature_deviations (map (lambda (/ 1 (current_value))) (get hyperparameter_map "featureResiduals"))
					))
				)

				;store the assoc of case_id -> weight (smaller distance contribution -> less weight)
				(assign (assoc
					case_weights_map
						(compute_on_contained_entities
							||(query_entity_distance_contributions
								closest_k
								continuous_rebalance_features
								;all cases
								(null)
								p_value
								feature_weights
								!queryDistanceTypeMap
								query_feature_attributes_map
								feature_deviations
								(null)
								dt_value
								(if !autoAblationEnabled !internalLabelProbabilityMass (null))
								;use a fixed random seed to guarantee deterministic behavior for reacts (named "fixed rand seed")
								"fixed rand seed"
								(null) ;radius
								!numericalPrecision
							)
						)
				))

				(if !autoAblationEnabled
					;current implementation compute_entity_distance_contributions multiplies the computed "base d.c." (distance contribution if the case had a weight of 1)
					;by each cases's own weight, this is useful for anomaly detection, but for rebalancing, the opposite is necessary because the more massive a case,
					;the less its rebalanced weight/influence should be (e.g, case with weight of 10 is like having 10 exact dupes, each with 1/10th of their original influence).
					;To get back to "base d.c." values, each computed value above is divided by each case's own weight. Rebalancing needs these "base d.c."s to be
					;scaled down appropriately as explained above, thus each is divided a second time by their own weight, scaling their relative influence down by their mass.
					(assign (assoc
						case_weights_map
							(map
								(lambda
									(/
										(first (current_value))
										;divide the computed d.c. by the case's mass twice (square of the mass),
										;once to revert back to the "base d.c." (with a weight 1), second to scale down for rebalancing
										(or
											(pow (get (current_value) [1 !internalLabelProbabilityMass]) 2)
											1
										)
									)
								)
								case_weights_map
								(compute_on_contained_entities (query_exists !internalLabelProbabilityMass) )
							)
					))
				)
			)
		)

		(if (size nominal_rebalance_features)
			(seq
				(assign (assoc
					;assoc of { feature -> { value -> weight } }
					feature_value_weight_map
						(map
							(lambda (let
								(assoc feature (current_index 1))

								;store class counts as weights (reciprocal of count) for all cases for each id feature
								(map
									(lambda (/ 1 (current_value)) )

									;grab the count of each class
									(compute_on_contained_entities
										(query_value_masses
											feature
											(if !autoAblationEnabled !internalLabelProbabilityMass (null))
										)
									)
								)
							))
							(zip nominal_rebalance_features)
						)
				))

				;overwrite case_weights_map to the product of all the rebalance feature weights
				(assign (assoc
					case_weights_map
						(map
							(lambda (let
								(assoc
									feature_classes_map (current_value 1)
								)

								;case weight is product of all the rebalance features' weights
								(*
									;get the continuous value for this case if exists
									(if case_weights_map
										(get case_weights_map (current_index))
										1
									)

									;multiply all the case weights for all the nominal features
									(apply "*"
										;list of all the case weights for all the nominal features
										(map
											(lambda
												(get
													feature_value_weight_map
													[ (current_value 1) (get feature_classes_map (current_value 1)) ]
												)
											)
											nominal_rebalance_features
										)
									)
								)
							))

							;iterate over all nominal rebalance features and pull their class values
							(compute_on_contained_entities
								(map (lambda (query_exists (current_value))) nominal_rebalance_features)
							)
						)
				))
			)
		)

		;total mass is set to the number of cases, but if ablation is enabled, it's the sum of all accumulated probability masses
		(declare (assoc
			total_mass
				(if !autoAblationEnabled
					(compute_on_contained_entities (query_exists !internalLabelProbabilityMass) (query_sum !internalLabelProbabilityMass ))
					;else number of cases
					(call !GetNumTrainingCases)
				)
		))

		(if !autoAblationEnabled
			(assign (assoc
				;scale each weight by its probability mass
				case_weights_map
					(map
						(lambda
							(*
								(first (current_value))
								(or (get (current_value) [ 1 !internalLabelProbabilityMass ] ) 1)
							)
						)
						case_weights_map
						(compute_on_contained_entities (query_exists !internalLabelProbabilityMass) )
					)
			))
		)

		(declare (assoc
			total_rebalance_mass (apply "+" (values case_weights_map))
		))
		(declare (assoc scalar (/ total_mass total_rebalance_mass)))

		;store the rebalance weights into cases
		(call !StoreCaseValues (assoc
			label_name weight_feature
			case_values_map
				;multiply by the scalar so that the total mass of the dataset remains the same, as though it wasn't rebalanced
				(map
					(lambda (* scalar (current_value)))
					case_weights_map
				)
		))

		(assign_to_entities (assoc
			;set global continuous_rebalance_features variable to store these values during future train() calls
			!continuousRebalanceFeatures (if (size continuous_rebalance_features) continuous_rebalance_features)
			!nominalRebalanceFeatures (if (size nominal_rebalance_features) nominal_rebalance_features)
			!cachedRebalanceTotalMass total_rebalance_mass
			!cachedTotalMass total_mass

			;store the reciprocal of current count + 1 (add 1 to 1/reciprocal) for each class so
			;that future trained cases use this updated smaller (incremented count) value
			!cachedRebalanceClassValueWeightMap
				;iterate over all the nominal features
				(map
					(lambda
						;iterate over all the classes and update their reciprocal of counts
						(map
							(lambda
								(/ 1 (+ 1 (/ 1 (current_value))))
							)
							(current_value)
						)
					)
					feature_value_weight_map
				)

			;store the average weight as the unknown
			!cachedRebalanceUnknownValueWeightMap
				(map
					(lambda (generalized_mean (current_value)) )
					feature_value_weight_map
				)
		))
	)
)