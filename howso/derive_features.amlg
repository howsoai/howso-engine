;Contains methods to derive features or feature values as defined by feature attributes.
(null

	;Derived during train features should have a feature attribute of 'auto_derive_on_train', an asoc defining how to derive the feature with the
	; following attributes:
	;
	;	derive_type: string attribute defining the type of derivation, one of 'custom', 'start', 'end'.  Each derive_type has its own attribute set.
	;
	;		'derive_type' : "custom" -
	;			This feature is derived using the specified 'code'. For each series, where each series is defined by "series_id_features",
	;			the rows are processed in order, after being sorted by "ordered_by_features". If series is not specified, processes the entire
	;			dataset. Referencing data in rows uses 0-based indexing, where the current row index is 0, the previous row's is 1, etc.
	;			Specified code may do simple logic and numeric operations on feature values referenced via feature name and row offset.
	;			Examples:
	;				"(call value {feature "x" lag 1})" - Use the value for feature 'x' from the previously processed row (offset of 1, one lag value).
	;				"(- (call value {feature "y" lag 0}) (call value {feature "x" lag 1}))" - Feature 'y' value from current (offset 0) row  minus feature 'x' value from previous (offest 1) row.
	;		'code': string, Code describing how feature could be derived.
	;				Same format as 'derived_feature_code' as defined in attributes. Example: "(- (call value {feature \"y\"})  (call value {feature \"x\" lag 1}) )"
	;		'series_id_features' : (optional) list of feature name(s) of series for which to derive this feature. A series is the conjunction of all
	;			the features specified by this attribute.
	;		'ordered_by_features' : (optional) list of fature name(s) by which to order the series specified by "series_id_features". Series values
	;			are order by the order of feature names specified by this attribute.
	;
	;		'series_id_features' : list of feature name(s) of series for which to derive this feature. A series is the conjunction of all
	;			the features specified by this attribute.
	;

	;At the end of train, derive features using the existing dataset, provided a list of features to derive. Creates and populates the specified
	;features to the dataset.
	;
	;parameters:
	; features: list of features the dataset was trained with originally
	; derived_features: list of features to derive, in the specified order.
	; case_ids: list of case ids for which to derive features
	; separate_delta_and_rates: flag, if true will create delta and rate features separately.
	;							used by migrations in situations where old cases may already have rates but not deltas.
	#!DeriveTrainFeatures
	(declare
		(assoc
			features (list)
			derived_features (list)
			case_ids (null)
		)

		(declare (assoc
			lag_features
				(filter
					(lambda (and
						(= "lag"  (get !featureAttributes (list (current_value 1) "ts_type")) )
						(= "custom" (get !featureAttributes (list (current_value 1) "auto_derive_on_train" "derive_type")) )
					))
					derived_features
				)
			time_feature_delta (concat "." !tsTimeFeature "_delta_1")

			has_reduced (size (contained_entities (query_not_equals !autoAblationWeightFeature 1.0)))
		))

		(if !tsTimeFeature
			(seq
				;create series index features
				(call !CreateSeriesIndexFeatures (assoc
					series_id_features (get !tsFeaturesMap "series_id_features")
					new_case_ids case_ids
				))

				;derive all the lag features in one pass
				(call !DeriveLagFeatures (assoc
					features features
					lag_features lag_features
					new_case_ids case_ids
				))
			)
		)

		;derive all the non-lag features below:
		(assign (assoc
			derived_features (filter (lambda (not (contains_value lag_features (current_value)))) derived_features)
		))


		;derive time feature delta before any of the other derived features
		(if (contains_value derived_features time_feature_delta)
			(call !CreateCustomFeaturesFromCode (assoc
				features features
				derived_features [time_feature_delta]
				new_case_ids case_ids
			))
		)

		(if !tsTimeFeature
			;In datasets with no synchonous cases, this method will early-out and store
			;zeros for all cases' synchronous counters (making it a inactive feature)
			(call !CreateSynchronousCounterFeature (assoc
				time_feature !tsTimeFeature
				time_feature_delta time_feature_delta
				series_ordered_by_features [!tsTimeFeature !internalLabelSessionTrainingIndex]
				series_id_features (get !tsFeaturesMap "series_id_features")
				new_case_ids case_ids
			))
		)

		;keep only features that have a custom derivation specified and aren't time_feature_delta which was derived above
		(assign (assoc
			derived_features
				(filter
					(lambda (and
						(!= time_feature_delta (current_value))
						(= "custom" (get !featureAttributes [(current_value 1) "auto_derive_on_train" "derive_type"]))
					))
					derived_features
				)
		))

		;features whose attributes were not set by the default set_feature_attributes flow and were specified by a user
		;may have a custom sort order or different series id features and must be created one at a time
		(declare (assoc
			non_default_order_derived_features
				(filter
					(lambda (or
						(!= (null) (get !featureAttributes [(current_value 1) "auto_derive_on_train" "ordered_by_features"]))
						(!= (null) (get !featureAttributes [(current_value 1) "auto_derive_on_train" "series_id_features"]))
					))
					derived_features
				)
		))

		;remove any non default features from derived features
		(if (size non_default_order_derived_features)
			(assign (assoc
				derived_features
					(filter (lambda (not (contains_value non_default_order_derived_features (current_value)))) derived_features)
			))
		)

		;compute the maximum order of rate or deltas needed, since higher orders depend on lower ones and need to be derived sequentially
		;e.g., 1st order for a rate feature needs to be derived before the 2nd order rate feature, etc.
		(declare (assoc
			max_order
				(apply "max"
					(map (lambda (get !featureAttributes [(current_value 1) "ts_order"])) derived_features)
				)
		))

		;create all derived_features (delta and rates) for each order in one pass, starting with 1st order.
		(if (size derived_features)
			(if separate_delta_and_rates
				(seq
					;deltas first, then rates
					(range
						(lambda (let
							(assoc order (current_index 1))
							(call !CreateCustomFeaturesFromCode (assoc
								features features
								derived_features
									(filter
										(lambda (and
											(= order (get !featureAttributes [(current_value 1) "ts_order"]))
											(= "delta" (get !featureAttributes [(current_value 1) "ts_type"]))
										))
										derived_features
									)
								new_case_ids case_ids
							))
						))
						1 max_order 1
					)

					(range
						(lambda (let
							(assoc order (current_index 1))
							(call !CreateCustomFeaturesFromCode (assoc
								features features
								derived_features
									(filter
										(lambda  (and
											(= order (get !featureAttributes [(current_value 1) "ts_order"]))
											(= "rate" (get !featureAttributes [(current_value 1) "ts_type"]))
										))
										derived_features
									)
								new_case_ids case_ids
							))
						))
						1 max_order 1
					)
				)

				;else do both deltas and rates in one pass
				(range
					(lambda (let
						(assoc order (current_index 1))
						(call !CreateCustomFeaturesFromCode (assoc
							features features
							derived_features
								(filter
									(lambda (= order (get !featureAttributes [(current_value 1) "ts_order"])))
									derived_features
								)
							new_case_ids case_ids
						))
					))
					1 max_order 1
				)
			)
		)

		;create any non default features last, one at a time
		(if (size non_default_order_derived_features)
			(map
				(lambda (let
					(assoc feature (current_value 1) )
					(call !CreateCustomFeaturesFromCode (assoc
						features features
						derived_features [feature]
						feature_attribute_map (get !featureAttributes [feature "auto_derive_on_train"])
					))
				))
				non_default_order_derived_features
			)
		)
	)

	;Derive feature value for the last row in series_data.
	; returns true and updates series_data in place if derived value within allowed bounds.
	; returns false without updating series_data if out derived value of bounds or it references na an invalid row offset.
	; returns (null) without updating series_data if a time feature exceeds its feature max boundary
	;
	;parameters:
	; derived_feature: feature name for which to derive value
	; feature_index_map: map of feature -> index of column in series_data corresponding to the feature
	; series_data: list of lists (a matrix) of series values, where the last list (row) is the one being updated
	; last_series_index: index of the last row in series_data
	#!DeriveSeriesValue
	(declare
		(assoc
			derived_feature (null)
			feature_index_map (assoc)
			last_series_index 0
		)

		(if (= (null) derived_feature)
			(conclude .false)
		)
		(declare (assoc derived_value_index (get feature_index_map derived_feature) ))
		;pull the max row lag for this derived_feature
		(declare (assoc max_row_lag  (get !featureAttributes (list derived_feature "max_row_lag")) ))

		;if max value > last_series_index, this feature needs to be generated because it references a row offset
		;that isn't in this series, return false because this value can't be derived
		(if (> max_row_lag last_series_index)
			(conclude .false)
		)

		(declare (assoc
			new_feature_transform_processed (get !featureCustomDerivedMethods (list derived_feature "series_react"))
		))

		(declare (assoc
			derived_feature_value
				(get_value
					(call_sandboxed new_feature_transform_processed (assoc
						series_data series_data
						series_row_index last_series_index
						feature_index_map feature_index_map
						!featureDateTimeMap !featureDateTimeMap
						!ConvertDateToEpoch !ConvertDateToEpoch
					) (* (size series_data) !sandboxedComputeLimit) !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit .false)
				)
		))

		(if (contains_index feature_post_process_code_map derived_feature)
			;if custom post process is defined, update derived feature value with it
			(assign (assoc
				derived_feature_value
					(get_value
						(call_sandboxed (get feature_post_process_code_map derived_feature) (assoc
							series_data
								;need to use series_data with the updated feature value
								;this is equivalent to the following:
								; [(set (last series_data) (get feature_index_map derived_feature) derived_feature_value) ]
								;but is much more memory efficient
								(append
									(trunc series_data)
									[ (append
										(if derived_value_index (trunc (last series_data) derived_value_index) [])
										derived_feature_value
										(tail (last series_data) (- (+ 1 derived_value_index)))
									) ]
								)
							series_row_index last_series_index
							feature_index_map feature_index_map
							!featureDateTimeMap !featureDateTimeMap
							!ConvertDateToEpoch !ConvertDateToEpoch
						) (* (size series_data) !sandboxedComputeLimit) !sandboxedMemoryLimit !sandboxedOpcodeDepthLimit .false)
					)
			))
		)

		(declare (assoc
			bounds_map
				;if specific bounds were passed in, use those, else use globally specified feature bounds
				(if (contains_index feature_bounds_map derived_feature)
					(get feature_bounds_map derived_feature)

					(get !featureBoundsMap derived_feature)
				)
			valid_value .true
			is_datetime (contains_index !featureDateTimeMap derived_feature)

		))

		;check bounds if they are specified
		(if (size bounds_map)
			(seq
				;invalid if generated a null and nulls are not allowed
				(if (and (= (null) derived_feature_value) (= (get bounds_map "allow_null") .false))
					(conclude (assign (assoc valid_value .false)))

					;else this is a nominal that has an allowed list, check if it's in the list
					(contains_index bounds_map "allowed")
					(conclude (assign (assoc valid_value (contains_value (get bounds_map "allowed") derived_feature_value) )))
				)

				(let
					(assoc
						cycle_length (get !cyclicFeaturesMap derived_feature)
						boundaries_tuple (null)
						boundary_min (null)
						boundary_max (null)
					)

					(assign (assoc
						boundaries_tuple
							(call !ConstrainBoundariesForFeature (assoc
								bounds_map bounds_map
								feature derived_feature
								is_datetime is_datetime
								cycle_length cycle_length
							))
					))

					(assign (assoc
						boundary_min (first boundaries_tuple)
						boundary_max (last boundaries_tuple)
					))

					(assign (assoc
						valid_value
							(if (and cycle_length (>= boundary_min boundary_max))
								;for cyclic, exclusionary bounds mean the value has to be less than max or more than min
								(or (<= derived_feature_value boundary_max) (>= derived_feature_value boundary_min))

								;normal bounds check, if bound specified, value must be either more than min or less than max, respectively
								(and
									(or (= (null) boundary_min) (>= derived_feature_value boundary_min))
									(or (= (null) boundary_max) (<= derived_feature_value boundary_max))
								)
							)
					))

					(if (get !featureAttributes (list derived_feature "time_series" "time_feature"))
						;if time feature exceeds the feature boundary max, stop generating the series by setting valid_value to 0
						;instead of .false, as long as other rows exist (this isn't the first row being generated)
						(if (and (not valid_value) (> derived_feature_value boundary_max) (> (size series_data) 1))
							(assign (assoc valid_value (null)))
						)
					)
				)
			)
		)

		;failed bounds check, return the invalid value
		(if (not valid_value)
			(conclude valid_value)
		)

		;convert epoch value back to string date or round it as necessary
		(if (!= (null) derived_feature_value)
			(if is_datetime
				(assign (assoc
					derived_feature_value
						(format
							derived_feature_value
							"number"
							(get !featureDateTimeMap (list derived_feature "date_time_format"))
							(null)
							{
								"locale" (get !featureDateTimeMap [ derived_feature "locale" ] )
								"time_zone" (get !featureDateTimeMap [ derived_feature "default_time_zone" ] )
							}
						)
				))

				(contains_index !featureRoundingMap derived_feature)
				(seq
					(assign (assoc
						derived_feature_value
							;generate a statement in the format of (round <value> <significant_digits> <decimal_points>)
							(apply "round" (append derived_feature_value (get !featureRoundingMap derived_feature)) )
					))

					(if (contains_index !cyclicFeaturesMap derived_feature)
						(assign (assoc
							derived_feature_value (mod derived_feature_value (get !cyclicFeaturesMap derived_feature))
						))
					)
				)
			)
		)

		;edit series_data in place, updating the last row, the column matching the derived_feature with the derived_feature_value
		(assign (assoc
			series_data
				(append
					(trunc series_data)
					;recreate the last row here with the properly placed derived_feature_value instead of doing
					; [(set (last series_data) (get feature_index_map derived_feature) derived_feature_value) ]
					;so it's only making copies of the data that need to be changed, whereas set would make a full copy and be slower
					[ (append
						(if derived_value_index (trunc (last series_data) derived_value_index) [])
						derived_feature_value
						(tail (last series_data) (- (+ 1 derived_value_index)))
					) ]
				)
		))

		;return true upon completion
		.true
	)

	;helper method to derive all the lag features for all the series in one pass
	;parameters:
	; features: list of features the dataset was trained with originally
	; lag_features: list of lag features that need to be derived
	#!DeriveLagFeatures
	(declare
		(assoc
			features (list)
			lag_features (list)
			new_case_ids (list)
		)

		(if (= 0 (size lag_features))
			(conclude)
		)

		(declare (assoc
			series_id_features (get !tsFeaturesMap "series_id_features")
			series_ordered_by_features [!tsTimeFeature !internalLabelSessionTrainingIndex]
		))
		(declare (assoc
			;list of features that are necessary to be able to derive the specified lag features, i.e., the original non-lagged features
			necessary_features
				(values
					(append
						series_ordered_by_features
						(apply "append"
							(map
								(lambda
									(get !featureAttributes [(current_value 1) "auto_derive_on_train" "code_features"])
								)
								lag_features
							)
						)
					)
					.true
				)
			ts_series_length_limit (retrieve_from_entity "!tsSeriesLimitLength")
		))

		;process each series individually
		;pull all the values for the necessary_features, sort them, and then derive this feature based on the specified code
		(map
			(lambda (let
				;(current_value) is in the format of (list (query_equals "series_feature_name" value) ... ) for all series_feature_name
				(assoc series_case_ids (contained_entities (current_value 1)) )

				;now that we know how long each new series is, ensure that ts_series_length_limit is e*(longest series)
				(if (> (* 2.718281828459 (size series_case_ids)) ts_series_length_limit)
					(assign (assoc ts_series_length_limit (* 2.718281828459 (size series_case_ids)) ))
				)

				(if has_reduced
					(seq
						(declare (assoc
							num_cases_prev_trained
								(+
									1
									(retrieve_from_entity
										(first (contained_entities
											(query_in_entity_list series_case_ids)
											(query_not_in_entity_list new_case_ids)
											(query_max ".series_index" 1 .true)
										))
										".series_index"
									)
								)
							num_cases_trained
								(+
									1
									(retrieve_from_entity
										(first (contained_entities
											(query_in_entity_list series_case_ids)
											(query_equals ".reverse_series_index" 0 .true)
										))
										".series_index"
									)
								)
						))


						(declare (assoc
							is_missing_cases
								;if the number of old series cases is less
								;than indicated by the largest series index of an old series case
								(and
									;this value will be null if there are no previous cases trained before this derivation
									num_cases_prev_trained
									(!=
										(size (contained_entities
											(query_in_entity_list series_case_ids)
											(query_not_in_entity_list new_case_ids)
										))
										num_cases_prev_trained
									)
								)
						))
					)
				)

				(declare (assoc
					;series_data is all the necessary_features's values along with the case_id appended as the last column
					series_data
						(map
							(lambda (append (retrieve_from_entity (current_value) necessary_features) (current_value)))
							series_case_ids
						)
				))

				;sort the series data according to the specified features if ordering has been provided
				(if (size series_ordered_by_features)
					(assign (assoc
						series_data
							(if is_missing_cases
								;cases have been removed from the series at some point, we must sort by series index, leaving nulls where appropriate
								(let
									(assoc
										series_index_to_data_map
											(zip
												(map (lambda (retrieve_from_entity (current_value) ".series_index")) series_case_ids)
												series_data
											)
									)

									(unzip
										series_index_to_data_map
										(range 0 (- num_cases_trained 1) 1)
									)
								)

								;just sort by the sorting features
								(call !MultiSortList (assoc
									data series_data
									column_order_indices (unzip (zip necessary_features (indices necessary_features)) series_ordered_by_features)
								))
							)
					))
				)

				;store the case ids in the new sorted order of series_data
				(assign (assoc
					series_case_ids
						(map
							(lambda (last (current_value)))
							series_data
						)
				))

				(if is_missing_cases
					(seq
						(declare (assoc
							case_id_to_idx_map
								(zip
									series_case_ids
									(indices series_case_ids)
								)
						))
						(declare (assoc
							new_series_case_ids (indices (keep case_id_to_idx_map new_case_ids))
						))
					)
				)

				;remove the case_id column from series_data
				(assign (assoc
					series_data
						(map
							(lambda (trunc (current_value)))
							series_data
						)
				))

				;overwrite series data with the new generated series values
				(assign (assoc
					series_data
						(call !AddDerivedIndependentCodeFeatures (assoc
							derived_features lag_features
							features necessary_features
							series_data series_data
						))
				))

				;since all lag features are being created in bulk, we only need to check if one exists
				;to decide whether they all exist or none exist
				(declare (assoc first_lag_feature (first lag_features) ))

				;map over the case ids and assign the derived values (still with nulls if so)
				(map
					(lambda (let
						(assoc case_id (current_index 1) )
						(if (contains_label case_id first_lag_feature)
							(assign_to_entities
								case_id
								(zip lag_features (current_value))
							)
							;else these labels don't exist yet, need to append them to the entity
							(accum_entity_roots
								case_id
								(zip_labels lag_features (current_value))
							)
						)
					))
					(if is_missing_cases
						;only update the values for the new cases
						(map
							(lambda (get series_data (current_value)) )
							(keep case_id_to_idx_map new_series_case_ids)
						)

						;can do all series cases
						(zip series_case_ids series_data)
					)
				)
			))

			;generates a list of queries for each unique series id (where each series id may be a conjuction of several features)
			;NOTE: this will only return queries for series that have had new cases trained.
			(call !GenerateUniqueSeriesQueries (assoc
				series_id_features series_id_features
				case_ids new_case_ids
			))
		)

		;if ts_series_length_limit has been been updated to a larger value in the loop above, update the dataset with this new value
		(if (> ts_series_length_limit !tsSeriesLimitLength)
			(assign_to_entities (assoc !tsSeriesLimitLength ts_series_length_limit ))
		)
	)
)
